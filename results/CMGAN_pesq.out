Starting training:
without SE:
Namespace(batch_size=4, cut_len=32000, data_dir='/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/DEMAND_16KHz', decay_epoch=12, epochs=60, init_lr=0.0005, log_interval=500, loss_weights=[0.1, 0.9, 0.2, 0.05], save_model_dir='./saved_models_log/saved_models_20250717_VoiceDEMAND_16khz')
['NVIDIA A100-SXM4-80GB']
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
TSCNet                                             [1, 1, 321, 201]          --
├─DenseEncoder: 1-1                                [1, 64, 321, 101]         --
│    └─Sequential: 2-1                             [1, 64, 321, 201]         --
│    │    └─Conv2d: 3-1                            [1, 64, 321, 201]         256
│    │    └─InstanceNorm2d: 3-2                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-3                             [1, 64, 321, 201]         64
│    └─DilatedDenseNet: 2-2                        [1, 64, 321, 201]         --
│    │    └─ConstantPad2d: 3-4                     [1, 64, 322, 203]         --
│    │    └─Conv2d: 3-5                            [1, 64, 321, 201]         24,640
│    │    └─InstanceNorm2d: 3-6                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-7                             [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-8                     [1, 128, 323, 203]        --
│    │    └─Conv2d: 3-9                            [1, 64, 321, 201]         49,216
│    │    └─InstanceNorm2d: 3-10                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-11                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-12                    [1, 192, 325, 203]        --
│    │    └─Conv2d: 3-13                           [1, 64, 321, 201]         73,792
│    │    └─InstanceNorm2d: 3-14                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-15                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-16                    [1, 256, 329, 203]        --
│    │    └─Conv2d: 3-17                           [1, 64, 321, 201]         98,368
│    │    └─InstanceNorm2d: 3-18                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-19                            [1, 64, 321, 201]         64
│    └─Sequential: 2-3                             [1, 64, 321, 101]         --
│    │    └─Conv2d: 3-20                           [1, 64, 321, 101]         12,352
│    │    └─InstanceNorm2d: 3-21                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-22                            [1, 64, 321, 101]         64
├─TSCB: 1-2                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-4                         [101, 321, 64]            --
│    │    └─Scale: 3-23                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-24                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-25              [101, 321, 64]            29,376
│    │    └─Scale: 3-26                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-27                        [101, 321, 64]            128
│    └─ConformerBlock: 2-5                         [321, 101, 64]            --
│    │    └─Scale: 3-28                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-29                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-30              [321, 101, 64]            29,376
│    │    └─Scale: 3-31                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-32                        [321, 101, 64]            128
├─TSCB: 1-3                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-6                         [101, 321, 64]            --
│    │    └─Scale: 3-33                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-34                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-35              [101, 321, 64]            29,376
│    │    └─Scale: 3-36                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-37                        [101, 321, 64]            128
│    └─ConformerBlock: 2-7                         [321, 101, 64]            --
│    │    └─Scale: 3-38                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-39                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-40              [321, 101, 64]            29,376
│    │    └─Scale: 3-41                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-42                        [321, 101, 64]            128
├─TSCB: 1-4                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-8                         [101, 321, 64]            --
│    │    └─Scale: 3-43                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-44                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-45              [101, 321, 64]            29,376
│    │    └─Scale: 3-46                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-47                        [101, 321, 64]            128
│    └─ConformerBlock: 2-9                         [321, 101, 64]            --
│    │    └─Scale: 3-48                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-49                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-50              [321, 101, 64]            29,376
│    │    └─Scale: 3-51                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-52                        [321, 101, 64]            128
├─TSCB: 1-5                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-10                        [101, 321, 64]            --
│    │    └─Scale: 3-53                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-54                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-55              [101, 321, 64]            29,376
│    │    └─Scale: 3-56                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-57                        [101, 321, 64]            128
│    └─ConformerBlock: 2-11                        [321, 101, 64]            --
│    │    └─Scale: 3-58                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-59                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-60              [321, 101, 64]            29,376
│    │    └─Scale: 3-61                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-62                        [321, 101, 64]            128
├─MaskDecoder: 1-6                                 [1, 1, 321, 201]          --
│    └─DilatedDenseNet: 2-12                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-63                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-64                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-65                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-66                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-67                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-68                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-69                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-70                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-71                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-72                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-73                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-74                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-75                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-76                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-77                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-78                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-13                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-79                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-80                           [1, 128, 321, 101]        24,704
│    └─Conv2d: 2-14                                [1, 1, 321, 201]          129
│    └─InstanceNorm2d: 2-15                        [1, 1, 321, 201]          2
│    └─PReLU: 2-16                                 [1, 1, 321, 201]          1
│    └─Conv2d: 2-17                                [1, 1, 321, 201]          2
│    └─PReLU: 2-18                                 [1, 201, 321]             201
├─ComplexDecoder: 1-7                              [1, 2, 321, 201]          --
│    └─DilatedDenseNet: 2-19                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-81                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-82                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-83                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-84                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-85                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-86                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-87                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-88                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-89                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-90                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-91                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-92                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-93                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-94                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-95                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-96                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-20                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-97                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-98                           [1, 128, 321, 101]        24,704
│    └─InstanceNorm2d: 2-21                        [1, 64, 321, 202]         128
│    └─PReLU: 2-22                                 [1, 64, 321, 202]         64
│    └─Conv2d: 2-23                                [1, 2, 321, 201]          258
====================================================================================================
Total params: 1,834,833
Trainable params: 1,834,833
Non-trainable params: 0
Total mult-adds (G): 41.56
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 4856.40
Params size (MB): 7.34
Estimated Total Size (MB): 4864.25
====================================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Discriminator                            [1, 1]                    --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Conv2d: 2-1                       [1, 16, 100, 160]         512
│    └─InstanceNorm2d: 2-2               [1, 16, 100, 160]         32
│    └─PReLU: 2-3                        [1, 16, 100, 160]         16
│    └─Conv2d: 2-4                       [1, 32, 50, 80]           8,192
│    └─InstanceNorm2d: 2-5               [1, 32, 50, 80]           64
│    └─PReLU: 2-6                        [1, 32, 50, 80]           32
│    └─Conv2d: 2-7                       [1, 64, 25, 40]           32,768
│    └─InstanceNorm2d: 2-8               [1, 64, 25, 40]           128
│    └─PReLU: 2-9                        [1, 64, 25, 40]           64
│    └─Conv2d: 2-10                      [1, 128, 12, 20]          131,072
│    └─InstanceNorm2d: 2-11              [1, 128, 12, 20]          256
│    └─PReLU: 2-12                       [1, 128, 12, 20]          128
│    └─AdaptiveMaxPool2d: 2-13           [1, 128, 1, 1]            --
│    └─Flatten: 2-14                     [1, 128]                  --
│    └─Linear: 2-15                      [1, 64]                   8,256
│    └─Dropout: 2-16                     [1, 64]                   --
│    └─PReLU: 2-17                       [1, 64]                   64
│    └─Linear: 2-18                      [1, 1]                    65
│    └─LearnableSigmoid: 2-19            [1, 1]                    1
==========================================================================================
Total params: 181,650
Trainable params: 181,650
Non-trainable params: 0
Total mult-adds (M): 19.67
==========================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 11.49
Params size (MB): 0.73
Estimated Total Size (MB): 12.73
==========================================================================================
/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/CMGAN_src/data/dataloader.py:52: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")         # in linux
INFO:root:Epoch 0, Step 500, loss: 0.1970152109861374, disc_loss: 0.006073162890970707
INFO:root:Epoch 0, Step 1000, loss: 0.1395254284143448, disc_loss: 0.016772398725152016
INFO:root:Epoch 0, Step 1500, loss: 0.2458725869655609, disc_loss: 0.0028305340092629194
INFO:root:Epoch 0, Step 2000, loss: 0.18669238686561584, disc_loss: 0.025852205231785774
INFO:root:Epoch 0, Step 2500, loss: 0.1327778398990631, disc_loss: 0.0068233925849199295
INFO:root:Generator loss: 0.08196567006192161, Discriminator loss: 0.00815862504207615
INFO:root:Epoch 1, Step 500, loss: 0.14085519313812256, disc_loss: 0.00675684679299593
INFO:root:Epoch 1, Step 1000, loss: 0.08802536129951477, disc_loss: 0.0023829848505556583
INFO:root:Epoch 1, Step 1500, loss: 0.08418110758066177, disc_loss: 0.013877102173864841
INFO:root:Epoch 1, Step 2000, loss: 0.10508177429437637, disc_loss: 0.006175209768116474
INFO:root:Epoch 1, Step 2500, loss: 0.12351362407207489, disc_loss: 0.004477526061236858
INFO:root:Generator loss: 0.07834757638426082, Discriminator loss: 0.006798262275852607
INFO:root:Epoch 2, Step 500, loss: 0.10613063722848892, disc_loss: 0.007029988337308168
INFO:root:Epoch 2, Step 1000, loss: 0.13225607573986053, disc_loss: 0.020639995113015175
INFO:root:Epoch 2, Step 1500, loss: 0.18774114549160004, disc_loss: 0.0016051154816523194
INFO:root:Epoch 2, Step 2000, loss: 0.090894915163517, disc_loss: 0.00493899779394269
INFO:root:Epoch 2, Step 2500, loss: 0.128133162856102, disc_loss: 0.0013332711532711983
INFO:root:Generator loss: 0.0731838096150206, Discriminator loss: 0.006460553807804352
INFO:root:Epoch 3, Step 500, loss: 0.16534554958343506, disc_loss: 0.00898960791528225
INFO:root:Epoch 3, Step 1000, loss: 0.10003513097763062, disc_loss: 0.00139538012444973
INFO:root:Epoch 3, Step 1500, loss: 0.08242376893758774, disc_loss: 0.016401607543230057
INFO:root:Epoch 3, Step 2000, loss: 0.1081310287117958, disc_loss: 0.003850107081234455
INFO:root:Epoch 3, Step 2500, loss: 0.11909102648496628, disc_loss: 0.008158285170793533
INFO:root:Generator loss: 0.07519807243376102, Discriminator loss: 0.005191461117717763
INFO:root:Epoch 4, Step 500, loss: 0.06642311811447144, disc_loss: 0.00475554633885622
INFO:root:Epoch 4, Step 1000, loss: 0.11978158354759216, disc_loss: 0.001170869916677475
INFO:root:Epoch 4, Step 1500, loss: 0.06856066733598709, disc_loss: 0.0005632637185044587
INFO:root:Epoch 4, Step 2000, loss: 0.08527210354804993, disc_loss: 0.01924407109618187
INFO:root:Epoch 4, Step 2500, loss: 0.0631781741976738, disc_loss: 0.01436125859618187
INFO:root:Generator loss: 0.0728288133746212, Discriminator loss: 0.006342160356970215
INFO:root:Epoch 5, Step 500, loss: 0.07519073784351349, disc_loss: 0.03809191286563873
INFO:root:Epoch 5, Step 1000, loss: 0.10373044013977051, disc_loss: 0.003672773716971278
INFO:root:Epoch 5, Step 1500, loss: 0.07907489687204361, disc_loss: 0.007239188998937607
INFO:root:Epoch 5, Step 2000, loss: 0.09621672332286835, disc_loss: 0.002774296561256051
INFO:root:Epoch 5, Step 2500, loss: 0.07670308649539948, disc_loss: 0.0016064741648733616
INFO:root:Generator loss: 0.06826720187820277, Discriminator loss: 0.003920786065225788
INFO:root:Epoch 6, Step 500, loss: 0.0639057606458664, disc_loss: 0.004268004093319178
INFO:root:Epoch 6, Step 1000, loss: 0.05931926146149635, disc_loss: 0.0007514697499573231
INFO:root:Epoch 6, Step 1500, loss: 0.13343699276447296, disc_loss: 0.0021100607700645924
INFO:root:Epoch 6, Step 2000, loss: 0.08175511658191681, disc_loss: 0.0066612218506634235
INFO:root:Epoch 6, Step 2500, loss: 0.05942055583000183, disc_loss: 0.0014294736320152879
INFO:root:Generator loss: 0.06906891156675167, Discriminator loss: 0.006201409624869148
INFO:root:Epoch 7, Step 500, loss: 0.11753040552139282, disc_loss: 0.004296787548810244
INFO:root:Epoch 7, Step 1000, loss: 0.11018099635839462, disc_loss: 0.00495547940954566
INFO:root:Epoch 7, Step 1500, loss: 0.0844547376036644, disc_loss: 0.003505837172269821
INFO:root:Epoch 7, Step 2000, loss: 0.06965573877096176, disc_loss: 0.0021166426595300436
INFO:root:Epoch 7, Step 2500, loss: 0.0662173479795456, disc_loss: 0.00032677818671800196
INFO:root:Generator loss: 0.06791466318107056, Discriminator loss: 0.00800336303263004
INFO:root:Epoch 8, Step 500, loss: 0.09275682270526886, disc_loss: 0.0016550598666071892
INFO:root:Epoch 8, Step 1000, loss: 0.11585121601819992, disc_loss: 0.005600235890597105
INFO:root:Epoch 8, Step 1500, loss: 0.12896504998207092, disc_loss: 0.002924329834058881
INFO:root:Epoch 8, Step 2000, loss: 0.12447842955589294, disc_loss: 0.00014818944327998906
INFO:root:Epoch 8, Step 2500, loss: 0.10917580872774124, disc_loss: 0.00040633228491060436
INFO:root:Generator loss: 0.06580305594987082, Discriminator loss: 0.007796427476950537
INFO:root:Epoch 9, Step 500, loss: 0.10485406219959259, disc_loss: 0.0007092335727065802
INFO:root:Epoch 9, Step 1000, loss: 0.06583879888057709, disc_loss: 0.0022647306323051453
INFO:root:Epoch 9, Step 1500, loss: 0.0921187549829483, disc_loss: 0.0014385852264240384
INFO:root:Epoch 9, Step 2000, loss: 0.1110769733786583, disc_loss: 0.0040547167882323265
INFO:root:Epoch 9, Step 2500, loss: 0.10555683076381683, disc_loss: 0.000589134288020432
INFO:root:Generator loss: 0.06473577401410897, Discriminator loss: 0.005517395930811175
INFO:root:Epoch 10, Step 500, loss: 0.18181473016738892, disc_loss: 0.00240890309214592
INFO:root:Epoch 10, Step 1000, loss: 0.0856894701719284, disc_loss: 0.0006780210533179343
INFO:root:Epoch 10, Step 1500, loss: 0.10206831991672516, disc_loss: 0.0034407987259328365
INFO:root:Epoch 10, Step 2000, loss: 0.11364683508872986, disc_loss: 0.0036279952619224787
INFO:root:Epoch 10, Step 2500, loss: 0.08349590748548508, disc_loss: 0.0024094791151583195
INFO:root:Generator loss: 0.0620115158120984, Discriminator loss: 0.008366901780709226
INFO:root:Epoch 11, Step 500, loss: 0.09809480607509613, disc_loss: 0.0012040574802085757
INFO:root:Epoch 11, Step 1000, loss: 0.05353105068206787, disc_loss: 0.002653847448527813
INFO:root:Epoch 11, Step 1500, loss: 0.08181795477867126, disc_loss: 0.0006710648885928094
INFO:root:Epoch 11, Step 2000, loss: 0.11432601511478424, disc_loss: 0.0043036360293626785
INFO:root:Epoch 11, Step 2500, loss: 0.11694145202636719, disc_loss: 0.0008464807760901749
INFO:root:Generator loss: 0.0631695665889284, Discriminator loss: 0.005927523518675142
INFO:root:Epoch 12, Step 500, loss: 0.08180008083581924, disc_loss: 0.0007230708724819124
INFO:root:Epoch 12, Step 1000, loss: 0.09425613284111023, disc_loss: 0.002353733405470848
INFO:root:Epoch 12, Step 1500, loss: 0.055788807570934296, disc_loss: 0.0002347740955883637
INFO:root:Epoch 12, Step 2000, loss: 0.06693561375141144, disc_loss: 0.0011838957434520125
INFO:root:Epoch 12, Step 2500, loss: 0.0871497392654419, disc_loss: 0.0007679073023609817
INFO:root:Generator loss: 0.06558975779894487, Discriminator loss: 0.006793417899264136
INFO:root:Epoch 13, Step 500, loss: 0.07765547931194305, disc_loss: 0.0010865721851587296
INFO:root:Epoch 13, Step 1000, loss: 0.05247333645820618, disc_loss: 0.005190569441765547
INFO:root:Epoch 13, Step 1500, loss: 0.097303606569767, disc_loss: 0.0021908716298639774
INFO:root:Epoch 13, Step 2000, loss: 0.06540828943252563, disc_loss: 0.003303783480077982
INFO:root:Epoch 13, Step 2500, loss: 0.055355072021484375, disc_loss: 0.002676958916708827
INFO:root:Generator loss: 0.05997918074209135, Discriminator loss: 0.004158982811187669
INFO:root:Epoch 14, Step 500, loss: 0.08452142030000687, disc_loss: 0.000701604993082583
INFO:root:Epoch 14, Step 1000, loss: 0.10933668911457062, disc_loss: 0.001033687382005155
INFO:root:Epoch 14, Step 1500, loss: 0.06536922603845596, disc_loss: 0.0005640205927193165
INFO:root:Epoch 14, Step 2000, loss: 0.07244941592216492, disc_loss: 0.0005668647936545312
INFO:root:Epoch 14, Step 2500, loss: 0.10015945881605148, disc_loss: 0.0015147710219025612
INFO:root:Generator loss: 0.06093479984991469, Discriminator loss: 0.006063580501274188
INFO:root:Epoch 15, Step 500, loss: 0.06328274309635162, disc_loss: 0.0006982499035075307
INFO:root:Epoch 15, Step 1000, loss: 0.063322514295578, disc_loss: 0.0028095010202378035
INFO:root:Epoch 15, Step 1500, loss: 0.0906713604927063, disc_loss: 0.003145607654005289
INFO:root:Epoch 15, Step 2000, loss: 0.06745138019323349, disc_loss: 0.001182453241199255
INFO:root:Epoch 15, Step 2500, loss: 0.08342212438583374, disc_loss: 0.0012223065132275224
INFO:root:Generator loss: 0.06004844525449195, Discriminator loss: 0.00828639852741758
INFO:root:Epoch 16, Step 500, loss: 0.08176449686288834, disc_loss: 0.0008283168426714838
INFO:root:Epoch 16, Step 1000, loss: 0.09831586480140686, disc_loss: 0.0020659894216805696
INFO:root:Epoch 16, Step 1500, loss: 0.08949402719736099, disc_loss: 0.0033402973785996437
INFO:root:Epoch 16, Step 2000, loss: 0.05512865632772446, disc_loss: 0.0024878820404410362
INFO:root:Epoch 16, Step 2500, loss: 0.062124572694301605, disc_loss: 0.0012292718747630715
INFO:root:Generator loss: 0.0599399523050027, Discriminator loss: 0.004918897141110789
INFO:root:Epoch 17, Step 500, loss: 0.09156759083271027, disc_loss: 0.0009654283639974892
INFO:root:Epoch 17, Step 1000, loss: 0.10604079067707062, disc_loss: 0.00445093959569931
INFO:root:Epoch 17, Step 1500, loss: 0.10573074221611023, disc_loss: 0.0008567790500819683
INFO:root:Epoch 17, Step 2000, loss: 0.09309784322977066, disc_loss: 0.001054801745340228
INFO:root:Epoch 17, Step 2500, loss: 0.08374399691820145, disc_loss: 0.0003168182447552681
INFO:root:Generator loss: 0.05968061755908635, Discriminator loss: 0.005102011877170298
INFO:root:Epoch 18, Step 500, loss: 0.07796063274145126, disc_loss: 0.0015759713714942336
INFO:root:Epoch 18, Step 1000, loss: 0.0487997904419899, disc_loss: 0.0010161425452679396
INFO:root:Epoch 18, Step 1500, loss: 0.062053244560956955, disc_loss: 0.0005191683303564787
INFO:root:Epoch 18, Step 2000, loss: 0.07941590249538422, disc_loss: 0.0008689676178619266
INFO:root:Epoch 18, Step 2500, loss: 0.07113998383283615, disc_loss: 0.0008607827476225793
INFO:root:Generator loss: 0.05971690468960306, Discriminator loss: 0.006743572844550161
INFO:root:Epoch 19, Step 500, loss: 0.0853935107588768, disc_loss: 0.0015834119403734803
INFO:root:Epoch 19, Step 1000, loss: 0.11800417304039001, disc_loss: 0.00020145421149209142
INFO:root:Epoch 19, Step 1500, loss: 0.08315025269985199, disc_loss: 0.0013235032092779875
INFO:root:Epoch 19, Step 2000, loss: 0.08811125159263611, disc_loss: 0.0014821646036580205
INFO:root:Epoch 19, Step 2500, loss: 0.0946803092956543, disc_loss: 0.0001308900973526761
INFO:root:Generator loss: 0.06031911214361492, Discriminator loss: 0.007921840649059165
INFO:root:Epoch 20, Step 500, loss: 0.061540309339761734, disc_loss: 0.0023500847164541483
INFO:root:Epoch 20, Step 1000, loss: 0.12367275357246399, disc_loss: 0.0013105269754305482
INFO:root:Epoch 20, Step 1500, loss: 0.07504124194383621, disc_loss: 0.0006985031650401652
INFO:root:Epoch 20, Step 2000, loss: 0.07606178522109985, disc_loss: 0.003067463170737028
INFO:root:Epoch 20, Step 2500, loss: 0.08361010998487473, disc_loss: 0.001360424212180078
INFO:root:Generator loss: 0.0600318846482675, Discriminator loss: 0.006118330859359596
INFO:root:Epoch 21, Step 500, loss: 0.08528764545917511, disc_loss: 0.004932021722197533
INFO:root:Epoch 21, Step 1000, loss: 0.10686654597520828, disc_loss: 0.0036023843567818403
INFO:root:Epoch 21, Step 1500, loss: 0.12728610634803772, disc_loss: 0.00031080085318535566
INFO:root:Epoch 21, Step 2000, loss: 0.09213884174823761, disc_loss: 0.0026642982847988605
INFO:root:Epoch 21, Step 2500, loss: 0.10116095840930939, disc_loss: 0.0016213365597650409
INFO:root:Generator loss: 0.05958851272222197, Discriminator loss: 0.007664237263915073
INFO:root:Epoch 22, Step 500, loss: 0.07958314567804337, disc_loss: 0.004186944104731083
INFO:root:Epoch 22, Step 1000, loss: 0.08238475769758224, disc_loss: 0.0017550487536936998
INFO:root:Epoch 22, Step 1500, loss: 0.09268387407064438, disc_loss: 0.003532195696607232
INFO:root:Epoch 22, Step 2000, loss: 0.08977743238210678, disc_loss: 0.0017836731858551502
INFO:root:Epoch 22, Step 2500, loss: 0.07129719108343124, disc_loss: 0.0014401096850633621
INFO:root:Generator loss: 0.058202543015618925, Discriminator loss: 0.004203763215557346
INFO:root:Epoch 23, Step 500, loss: 0.07483959197998047, disc_loss: 0.00048234008136205375
INFO:root:Epoch 23, Step 1000, loss: 0.11165650933980942, disc_loss: 0.0018317913636565208
INFO:root:Epoch 23, Step 1500, loss: 0.09311223030090332, disc_loss: 0.0017202493036165833
INFO:root:Epoch 23, Step 2000, loss: 0.07489369064569473, disc_loss: 0.0005294884904287755
INFO:root:Epoch 23, Step 2500, loss: 0.10083143413066864, disc_loss: 0.0016286963364109397
INFO:root:Generator loss: 0.06114811413170933, Discriminator loss: 0.00732235568713663
INFO:root:Epoch 24, Step 500, loss: 0.0378258153796196, disc_loss: 4.805791104445234e-05
INFO:root:Epoch 24, Step 1000, loss: 0.048532482236623764, disc_loss: 0.0022313492372632027
INFO:root:Epoch 24, Step 1500, loss: 0.06586343050003052, disc_loss: 0.0016081517096608877
INFO:root:Epoch 24, Step 2000, loss: 0.10033809393644333, disc_loss: 0.0011976166861131787
INFO:root:Epoch 24, Step 2500, loss: 0.057644497603178024, disc_loss: 0.0021851379424333572
INFO:root:Generator loss: 0.05889200071976023, Discriminator loss: 0.004410431328518455
INFO:root:Epoch 25, Step 500, loss: 0.08701639622449875, disc_loss: 0.002296759746968746
INFO:root:Epoch 25, Step 1000, loss: 0.07788490504026413, disc_loss: 0.0007809675298631191
INFO:root:Epoch 25, Step 1500, loss: 0.05300521105527878, disc_loss: 0.0004116105264984071
INFO:root:Epoch 25, Step 2000, loss: 0.047718826681375504, disc_loss: 0.001405155984684825
INFO:root:Epoch 25, Step 2500, loss: 0.09109234809875488, disc_loss: 0.0571211539208889
INFO:root:Generator loss: 0.05802698184745115, Discriminator loss: 0.005832895652911777
INFO:root:Epoch 26, Step 500, loss: 0.09363451600074768, disc_loss: 0.001483181957155466
INFO:root:Epoch 26, Step 1000, loss: 0.060515161603689194, disc_loss: 0.0026973015628755093
INFO:root:Epoch 26, Step 1500, loss: 0.06826229393482208, disc_loss: 0.0007293210364878178
INFO:root:Epoch 26, Step 2000, loss: 0.060103289783000946, disc_loss: 0.002726201433688402
INFO:root:Epoch 26, Step 2500, loss: 0.07857713103294373, disc_loss: 0.01694677211344242
INFO:root:Generator loss: 0.058068092858183734, Discriminator loss: 0.005065325585252422
INFO:root:Epoch 27, Step 500, loss: 0.06793069839477539, disc_loss: 0.00044638910912908614
INFO:root:Epoch 27, Step 1000, loss: 0.08073458075523376, disc_loss: 0.0004944819957017899
INFO:root:Epoch 27, Step 1500, loss: 0.07683801651000977, disc_loss: 0.0008785913232713938
INFO:root:Epoch 27, Step 2000, loss: 0.061117492616176605, disc_loss: 0.003410692559555173
INFO:root:Epoch 27, Step 2500, loss: 0.08180651813745499, disc_loss: 0.0007096767076291144
INFO:root:Generator loss: 0.058305207856939836, Discriminator loss: 0.004708877184896761
INFO:root:Epoch 28, Step 500, loss: 0.10298948734998703, disc_loss: 0.0013378714211285114
INFO:root:Epoch 28, Step 1000, loss: 0.0878354012966156, disc_loss: 0.0012564943172037601
INFO:root:Epoch 28, Step 1500, loss: 0.09923340380191803, disc_loss: 0.001669042743742466
INFO:root:Epoch 28, Step 2000, loss: 0.06449229270219803, disc_loss: 0.00043964441283605993
INFO:root:Epoch 28, Step 2500, loss: 0.047039974480867386, disc_loss: 0.002116310643032193
INFO:root:Generator loss: 0.0585518051933461, Discriminator loss: 0.006568399462885635
INFO:root:Epoch 29, Step 500, loss: 0.11575488746166229, disc_loss: 0.0008034852216951549
INFO:root:Epoch 29, Step 1000, loss: 0.08637715131044388, disc_loss: 0.001927323522977531
INFO:root:Epoch 29, Step 1500, loss: 0.06953611969947815, disc_loss: 0.0011214748956263065
INFO:root:Epoch 29, Step 2000, loss: 0.08606342226266861, disc_loss: 0.0015507991192862391
INFO:root:Epoch 29, Step 2500, loss: 0.06754274666309357, disc_loss: 0.0013340890873223543
INFO:root:Generator loss: 0.05837461916567052, Discriminator loss: 0.0039471475829486735
INFO:root:Epoch 30, Step 500, loss: 0.057603903114795685, disc_loss: 0.001093310653232038
INFO:root:Epoch 30, Step 1000, loss: 0.08262035250663757, disc_loss: 0.004686867352575064
INFO:root:Epoch 30, Step 1500, loss: 0.04949108138680458, disc_loss: 0.0011950163170695305
INFO:root:Epoch 30, Step 2000, loss: 0.08271274715662003, disc_loss: 0.00040620926301926374
INFO:root:Epoch 30, Step 2500, loss: 0.07861592620611191, disc_loss: 0.0028782885055989027
INFO:root:Generator loss: 0.05805098806119081, Discriminator loss: 0.005163871001076966
INFO:root:Epoch 31, Step 500, loss: 0.05049869418144226, disc_loss: 0.0003721791144926101
INFO:root:Epoch 31, Step 1000, loss: 0.04805412515997887, disc_loss: 0.002032565651461482
INFO:root:Epoch 31, Step 1500, loss: 0.06916020810604095, disc_loss: 0.0006217075861059129
INFO:root:Epoch 31, Step 2000, loss: 0.09296153485774994, disc_loss: 0.000837162951938808
INFO:root:Epoch 31, Step 2500, loss: 0.0780426487326622, disc_loss: 0.0016127837589010596
INFO:root:Generator loss: 0.05935996962548459, Discriminator loss: 0.004716031097787776
INFO:root:Epoch 32, Step 500, loss: 0.08231189846992493, disc_loss: 0.0018855644157156348
INFO:root:Epoch 32, Step 1000, loss: 0.07599560916423798, disc_loss: 0.0012836962705478072
INFO:root:Epoch 32, Step 1500, loss: 0.06117435544729233, disc_loss: 0.0012709439033642411
INFO:root:Epoch 32, Step 2000, loss: 0.08338792622089386, disc_loss: 0.0010306673357263207
INFO:root:Epoch 32, Step 2500, loss: 0.09339071810245514, disc_loss: 0.001475958852097392
INFO:root:Generator loss: 0.060167466398798726, Discriminator loss: 0.005437357244905462
INFO:root:Epoch 33, Step 500, loss: 0.07704751193523407, disc_loss: 0.0018325400305911899
INFO:root:Epoch 33, Step 1000, loss: 0.12205097079277039, disc_loss: 0.00031013163970783353
INFO:root:Epoch 33, Step 1500, loss: 0.07782473415136337, disc_loss: 0.0025238378439098597
INFO:root:Epoch 33, Step 2000, loss: 0.049667295068502426, disc_loss: 0.002275644103065133
INFO:root:Epoch 33, Step 2500, loss: 0.08493343740701675, disc_loss: 0.001267008832655847
INFO:root:Generator loss: 0.05818011913701747, Discriminator loss: 0.0037418401434037665
INFO:root:Epoch 34, Step 500, loss: 0.08502315729856491, disc_loss: 0.0028609363362193108
INFO:root:Epoch 34, Step 1000, loss: 0.06558872759342194, disc_loss: 0.0004628046590369195
INFO:root:Epoch 34, Step 1500, loss: 0.06331036984920502, disc_loss: 0.0013178252847865224
INFO:root:Epoch 34, Step 2000, loss: 0.14208625257015228, disc_loss: 0.0007367953658103943
INFO:root:Epoch 34, Step 2500, loss: 0.12357154488563538, disc_loss: 0.0019004222704097629
INFO:root:Generator loss: 0.057311793156329865, Discriminator loss: 0.005563410798132078
INFO:root:Epoch 35, Step 500, loss: 0.09642688184976578, disc_loss: 0.0006114960415288806
INFO:root:Epoch 35, Step 1000, loss: 0.08682207763195038, disc_loss: 0.0003139158943668008
INFO:root:Epoch 35, Step 1500, loss: 0.08249296993017197, disc_loss: 0.0007428482640534639
INFO:root:Epoch 35, Step 2000, loss: 0.08192649483680725, disc_loss: 0.0017284612404182553
INFO:root:Epoch 35, Step 2500, loss: 0.06824338436126709, disc_loss: 0.001762091531418264
INFO:root:Generator loss: 0.05865759888067118, Discriminator loss: 0.005598817487927449
INFO:root:Epoch 36, Step 500, loss: 0.08920561522245407, disc_loss: 0.001447591814212501
INFO:root:Epoch 36, Step 1000, loss: 0.08550821989774704, disc_loss: 0.0009473695536144078
INFO:root:Epoch 36, Step 1500, loss: 0.062350500375032425, disc_loss: 0.001456910977140069
INFO:root:Epoch 36, Step 2000, loss: 0.048728108406066895, disc_loss: 0.002175839152187109
INFO:root:Epoch 36, Step 2500, loss: 0.08608492463827133, disc_loss: 0.00019670244364533573
INFO:root:Generator loss: 0.05794317943487063, Discriminator loss: 0.004340588093009942
INFO:root:Epoch 37, Step 500, loss: 0.048534031957387924, disc_loss: 0.0008617404964752495
INFO:root:Epoch 37, Step 1000, loss: 0.0760975182056427, disc_loss: 0.00034914363641291857
INFO:root:Epoch 37, Step 1500, loss: 0.06885319203138351, disc_loss: 0.002369318623095751
INFO:root:Epoch 37, Step 2000, loss: 0.07290474325418472, disc_loss: 0.0020568030886352062
INFO:root:Epoch 37, Step 2500, loss: 0.09923672676086426, disc_loss: 0.0006372295320034027
INFO:root:Generator loss: 0.05751417183036943, Discriminator loss: 0.005071575871925322
INFO:root:Epoch 38, Step 500, loss: 0.08497840166091919, disc_loss: 0.0014600632712244987
INFO:root:Epoch 38, Step 1000, loss: 0.1051321029663086, disc_loss: 0.0009193681762553751
INFO:root:Epoch 38, Step 1500, loss: 0.05849811062216759, disc_loss: 0.003966261632740498
INFO:root:Epoch 38, Step 2000, loss: 0.08308561146259308, disc_loss: 0.0002538782136980444
INFO:root:Epoch 38, Step 2500, loss: 0.08569829165935516, disc_loss: 0.002977877389639616
INFO:root:Generator loss: 0.05752016796540577, Discriminator loss: 0.0046302906109295045
INFO:root:Epoch 39, Step 500, loss: 0.08495912700891495, disc_loss: 0.001032068394124508
INFO:root:Epoch 39, Step 1000, loss: 0.08155640959739685, disc_loss: 0.0024363002739846706
INFO:root:Epoch 39, Step 1500, loss: 0.03989103436470032, disc_loss: 0.0011589375790208578
INFO:root:Epoch 39, Step 2000, loss: 0.07699713110923767, disc_loss: 0.0006718876538798213
INFO:root:Epoch 39, Step 2500, loss: 0.07135900855064392, disc_loss: 0.0023445410188287497
INFO:root:Generator loss: 0.05885954486043418, Discriminator loss: 0.005264209703702222
INFO:root:Epoch 40, Step 500, loss: 0.060067083686590195, disc_loss: 0.0007975507760420442
INFO:root:Epoch 40, Step 1000, loss: 0.07896662503480911, disc_loss: 0.001624757656827569
INFO:root:Epoch 40, Step 1500, loss: 0.06844370812177658, disc_loss: 0.0011987013276666403
INFO:root:Epoch 40, Step 2000, loss: 0.1414691060781479, disc_loss: 0.0009597240714356303
INFO:root:Epoch 40, Step 2500, loss: 0.06700783222913742, disc_loss: 0.0006983370985835791
INFO:root:Generator loss: 0.0589930991126785, Discriminator loss: 0.005741912124930537
INFO:root:Epoch 41, Step 500, loss: 0.07454432547092438, disc_loss: 0.0017513221828266978
INFO:root:Epoch 41, Step 1000, loss: 0.07751959562301636, disc_loss: 0.0008285098592750728
INFO:root:Epoch 41, Step 1500, loss: 0.08014395087957382, disc_loss: 0.0006905529880896211
INFO:root:Epoch 41, Step 2000, loss: 0.08383411169052124, disc_loss: 0.0009764425922185183
INFO:root:Epoch 41, Step 2500, loss: 0.055065952241420746, disc_loss: 0.0003725280403159559
INFO:root:Generator loss: 0.05844476579426272, Discriminator loss: 0.005043640713056536
INFO:root:Epoch 42, Step 500, loss: 0.1000412330031395, disc_loss: 0.0021439683623611927
INFO:root:Epoch 42, Step 1000, loss: 0.06513307243585587, disc_loss: 0.0010800919262692332
INFO:root:Epoch 42, Step 1500, loss: 0.061680085957050323, disc_loss: 0.0007101568626239896
INFO:root:Epoch 42, Step 2000, loss: 0.06793452054262161, disc_loss: 0.0007907008985057473
INFO:root:Epoch 42, Step 2500, loss: 0.05488523095846176, disc_loss: 0.0028614955954253674
INFO:root:Generator loss: 0.058654133411287106, Discriminator loss: 0.006151009400710588
INFO:root:Epoch 43, Step 500, loss: 0.08206571638584137, disc_loss: 0.0013660714030265808
INFO:root:Epoch 43, Step 1000, loss: 0.08542446047067642, disc_loss: 0.00259765749797225
INFO:root:Epoch 43, Step 1500, loss: 0.09826094657182693, disc_loss: 0.0011960631236433983
INFO:root:Epoch 43, Step 2000, loss: 0.058014508336782455, disc_loss: 0.0011603855527937412
INFO:root:Epoch 43, Step 2500, loss: 0.06560473144054413, disc_loss: 0.002057468518614769
INFO:root:Generator loss: 0.057610682148522545, Discriminator loss: 0.00443926047168116
INFO:root:Epoch 44, Step 500, loss: 0.08943021297454834, disc_loss: 0.002221145201474428
INFO:root:Epoch 44, Step 1000, loss: 0.08100613206624985, disc_loss: 0.0010524224489927292
INFO:root:Epoch 44, Step 1500, loss: 0.07365334033966064, disc_loss: 0.0015217000618577003
INFO:root:Epoch 44, Step 2000, loss: 0.06279624998569489, disc_loss: 0.00018049965729005635
INFO:root:Epoch 44, Step 2500, loss: 0.09140719473361969, disc_loss: 0.0004655656812246889
INFO:root:Generator loss: 0.05789148503715552, Discriminator loss: 0.0045293790887087895
INFO:root:Epoch 45, Step 500, loss: 0.07097301632165909, disc_loss: 0.0001302097225561738
INFO:root:Epoch 45, Step 1000, loss: 0.055753543972969055, disc_loss: 0.0003862561425194144
INFO:root:Epoch 45, Step 1500, loss: 0.10076815634965897, disc_loss: 0.0032269051298499107
INFO:root:Epoch 45, Step 2000, loss: 0.06701981276273727, disc_loss: 0.0027853623032569885
INFO:root:Epoch 45, Step 2500, loss: 0.06221277266740799, disc_loss: 0.0009684493415988982
INFO:root:Generator loss: 0.05701390016389993, Discriminator loss: 0.0037734831611779
INFO:root:Epoch 46, Step 500, loss: 0.053964197635650635, disc_loss: 0.0016667965101078153
INFO:root:Epoch 46, Step 1000, loss: 0.08886762708425522, disc_loss: 0.002280964981764555
INFO:root:Epoch 46, Step 1500, loss: 0.0902266651391983, disc_loss: 0.000260418833931908
INFO:root:Epoch 46, Step 2000, loss: 0.06275220215320587, disc_loss: 0.05854484811425209
INFO:root:Epoch 46, Step 2500, loss: 0.051305271685123444, disc_loss: 0.001393742160871625
INFO:root:Generator loss: 0.05678344508904277, Discriminator loss: 0.003620173058611594
INFO:root:Epoch 47, Step 500, loss: 0.06702262908220291, disc_loss: 0.0002770198625512421
INFO:root:Epoch 47, Step 1000, loss: 0.0487549789249897, disc_loss: 0.0011746681993827224
INFO:root:Epoch 47, Step 1500, loss: 0.07852292060852051, disc_loss: 0.000862836663145572
INFO:root:Epoch 47, Step 2000, loss: 0.08440804481506348, disc_loss: 0.0005828855209983885
INFO:root:Epoch 47, Step 2500, loss: 0.0825403705239296, disc_loss: 0.0008077633683569729
INFO:root:Generator loss: 0.057694546091686755, Discriminator loss: 0.004303106760099819
INFO:root:Epoch 48, Step 500, loss: 0.07392559945583344, disc_loss: 0.000785744225140661
INFO:root:Epoch 48, Step 1000, loss: 0.10566987097263336, disc_loss: 0.00026278747827745974
INFO:root:Epoch 48, Step 1500, loss: 0.07347826659679413, disc_loss: 0.05325945094227791
INFO:root:Epoch 48, Step 2000, loss: 0.0843663215637207, disc_loss: 0.000693312962539494
INFO:root:Epoch 48, Step 2500, loss: 0.04892163351178169, disc_loss: 0.0013286905596032739
INFO:root:Generator loss: 0.057684524491139984, Discriminator loss: 0.004890537810866785
INFO:root:Epoch 49, Step 500, loss: 0.07218518108129501, disc_loss: 4.709799395641312e-05
INFO:root:Epoch 49, Step 1000, loss: 0.07222380489110947, disc_loss: 0.00043257002835161984
INFO:root:Epoch 49, Step 1500, loss: 0.062101367861032486, disc_loss: 0.0006510262028314173
INFO:root:Epoch 49, Step 2000, loss: 0.10026006400585175, disc_loss: 0.0005864513223059475
INFO:root:Epoch 49, Step 2500, loss: 0.0645238608121872, disc_loss: 0.0004341074381954968
INFO:root:Generator loss: 0.05715046648514792, Discriminator loss: 0.003996843473182752
INFO:root:Epoch 50, Step 500, loss: 0.07223117351531982, disc_loss: 0.0008643416804261506
INFO:root:Epoch 50, Step 1000, loss: 0.07214551419019699, disc_loss: 0.0005282132769934833
INFO:root:Epoch 50, Step 1500, loss: 0.06445907801389694, disc_loss: 0.0005838496144860983
INFO:root:Epoch 50, Step 2000, loss: 0.08328568190336227, disc_loss: 0.0014152132207527757
INFO:root:Epoch 50, Step 2500, loss: 0.07255061715841293, disc_loss: 0.0007257259567268193
INFO:root:Generator loss: 0.05807726623183026, Discriminator loss: 0.004161293160596137
INFO:root:Epoch 51, Step 500, loss: 0.07976683974266052, disc_loss: 0.0008059230749495327
INFO:root:Epoch 51, Step 1000, loss: 0.07387825101613998, disc_loss: 0.0017773981671780348
INFO:root:Epoch 51, Step 1500, loss: 0.07408134639263153, disc_loss: 0.0010433901334181428
INFO:root:Epoch 51, Step 2000, loss: 0.07251494377851486, disc_loss: 0.00017494155326858163
INFO:root:Epoch 51, Step 2500, loss: 0.07063036412000656, disc_loss: 0.00286575173959136
INFO:root:Generator loss: 0.05749895529441752, Discriminator loss: 0.005711009283083857
INFO:root:Epoch 52, Step 500, loss: 0.07634013146162033, disc_loss: 0.002106781117618084
INFO:root:Epoch 52, Step 1000, loss: 0.07558713108301163, disc_loss: 0.0008600072469562292
INFO:root:Epoch 52, Step 1500, loss: 0.0796816498041153, disc_loss: 0.0007994465995579958
INFO:root:Epoch 52, Step 2000, loss: 0.074086993932724, disc_loss: 0.00039950766949914396
INFO:root:Epoch 52, Step 2500, loss: 0.07599493116140366, disc_loss: 0.0007759897271171212
INFO:root:Generator loss: 0.05727255389600703, Discriminator loss: 0.005340685938472675
INFO:root:Epoch 53, Step 500, loss: 0.08180800080299377, disc_loss: 0.00037528405664488673
INFO:root:Epoch 53, Step 1000, loss: 0.1063523143529892, disc_loss: 0.0009055830887518823
INFO:root:Epoch 53, Step 1500, loss: 0.08253981173038483, disc_loss: 0.00020555159426294267
INFO:root:Epoch 53, Step 2000, loss: 0.05671290308237076, disc_loss: 0.001029773149639368
INFO:root:Epoch 53, Step 2500, loss: 0.05402005836367607, disc_loss: 0.00059057108592242
INFO:root:Generator loss: 0.057802320349491336, Discriminator loss: 0.0037386637376788075
INFO:root:Epoch 54, Step 500, loss: 0.08219493925571442, disc_loss: 0.0007692180224694312
INFO:root:Epoch 54, Step 1000, loss: 0.0845470204949379, disc_loss: 0.0015376732917502522
INFO:root:Epoch 54, Step 1500, loss: 0.08050860464572906, disc_loss: 0.0005280040786601603
INFO:root:Epoch 54, Step 2000, loss: 0.09136743098497391, disc_loss: 0.04320168122649193
INFO:root:Epoch 54, Step 2500, loss: 0.07240461558103561, disc_loss: 0.0013873112620785832
INFO:root:Generator loss: 0.0572649153329215, Discriminator loss: 0.006010660777020763
INFO:root:Epoch 55, Step 500, loss: 0.09109952300786972, disc_loss: 0.0019499313784763217
INFO:root:Epoch 55, Step 1000, loss: 0.08058089762926102, disc_loss: 0.0005517754470929503
INFO:root:Epoch 55, Step 1500, loss: 0.08418630063533783, disc_loss: 0.0003973109705839306
INFO:root:Epoch 55, Step 2000, loss: 0.097136951982975, disc_loss: 0.0006776084774173796
INFO:root:Epoch 55, Step 2500, loss: 0.10329081118106842, disc_loss: 0.0028069678228348494
INFO:root:Generator loss: 0.05733427735389147, Discriminator loss: 0.0038728970540936095
INFO:root:Epoch 56, Step 500, loss: 0.0701676458120346, disc_loss: 0.0002897451922763139
INFO:root:Epoch 56, Step 1000, loss: 0.07286207377910614, disc_loss: 0.0009855006355792284
INFO:root:Epoch 56, Step 1500, loss: 0.062375131994485855, disc_loss: 0.0007881619385443628
INFO:root:Epoch 56, Step 2000, loss: 0.08233466744422913, disc_loss: 0.0022371781524270773
INFO:root:Epoch 56, Step 2500, loss: 0.061667799949645996, disc_loss: 0.0758061334490776
INFO:root:Generator loss: 0.05717389979987469, Discriminator loss: 0.004947774884959534
INFO:root:Epoch 57, Step 500, loss: 0.07146426290273666, disc_loss: 0.000228148463065736
INFO:root:Epoch 57, Step 1000, loss: 0.07325704395771027, disc_loss: 0.0006516476278193295
INFO:root:Epoch 57, Step 1500, loss: 0.043020810931921005, disc_loss: 0.11025407165288925
INFO:root:Epoch 57, Step 2000, loss: 0.06425036489963531, disc_loss: 0.0016364851035177708
INFO:root:Epoch 57, Step 2500, loss: 0.0897943452000618, disc_loss: 0.0002601810556370765
INFO:root:Generator loss: 0.05722290247642589, Discriminator loss: 0.0041830985645045305
INFO:root:Epoch 58, Step 500, loss: 0.09365411847829819, disc_loss: 0.016998419538140297
INFO:root:Epoch 58, Step 1000, loss: 0.049860935658216476, disc_loss: 0.0013120434014126658
INFO:root:Epoch 58, Step 1500, loss: 0.05976509302854538, disc_loss: 0.0004132281173951924
INFO:root:Epoch 58, Step 2000, loss: 0.041890017688274384, disc_loss: 0.0005079160328023136
INFO:root:Epoch 58, Step 2500, loss: 0.09614421427249908, disc_loss: 0.0007098347414284945
INFO:root:Generator loss: 0.057641553547848196, Discriminator loss: 0.004292387251641309
INFO:root:Epoch 59, Step 500, loss: 0.07948704808950424, disc_loss: 0.0004597272491082549
INFO:root:Epoch 59, Step 1000, loss: 0.07182246446609497, disc_loss: 0.00039281637873500586
INFO:root:Epoch 59, Step 1500, loss: 0.07564781606197357, disc_loss: 0.0016466695815324783
INFO:root:Epoch 59, Step 2000, loss: 0.07231633365154266, disc_loss: 0.000675660150591284
INFO:root:Epoch 59, Step 2500, loss: 0.09423111379146576, disc_loss: 0.0015300058294087648
INFO:root:Generator loss: 0.05749712681886062, Discriminator loss: 0.00518949041845225
Training finished.

---------------------------------------------------------------------------------------------------------------------------------
Starting training:
without SE:
Namespace(batch_size=4, cut_len=32000, data_dir='/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/DEMAND_16KHz', decay_epoch=12, epochs=60, init_lr=0.0005, log_interval=500, loss_weights=[0.3, 0.7, 1.0, 0.01], save_model_dir='./saved_models_log/saved_models_20250718_VoiceDEMAND_16khz')
['NVIDIA A100-SXM4-80GB']
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
TSCNet                                             [1, 1, 321, 201]          --
├─DenseEncoder: 1-1                                [1, 64, 321, 101]         --
│    └─Sequential: 2-1                             [1, 64, 321, 201]         --
│    │    └─Conv2d: 3-1                            [1, 64, 321, 201]         256
│    │    └─InstanceNorm2d: 3-2                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-3                             [1, 64, 321, 201]         64
│    └─DilatedDenseNet: 2-2                        [1, 64, 321, 201]         --
│    │    └─ConstantPad2d: 3-4                     [1, 64, 322, 203]         --
│    │    └─Conv2d: 3-5                            [1, 64, 321, 201]         24,640
│    │    └─InstanceNorm2d: 3-6                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-7                             [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-8                     [1, 128, 323, 203]        --
│    │    └─Conv2d: 3-9                            [1, 64, 321, 201]         49,216
│    │    └─InstanceNorm2d: 3-10                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-11                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-12                    [1, 192, 325, 203]        --
│    │    └─Conv2d: 3-13                           [1, 64, 321, 201]         73,792
│    │    └─InstanceNorm2d: 3-14                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-15                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-16                    [1, 256, 329, 203]        --
│    │    └─Conv2d: 3-17                           [1, 64, 321, 201]         98,368
│    │    └─InstanceNorm2d: 3-18                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-19                            [1, 64, 321, 201]         64
│    └─Sequential: 2-3                             [1, 64, 321, 101]         --
│    │    └─Conv2d: 3-20                           [1, 64, 321, 101]         12,352
│    │    └─InstanceNorm2d: 3-21                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-22                            [1, 64, 321, 101]         64
├─TSCB: 1-2                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-4                         [101, 321, 64]            --
│    │    └─Scale: 3-23                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-24                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-25              [101, 321, 64]            29,376
│    │    └─Scale: 3-26                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-27                        [101, 321, 64]            128
│    └─ConformerBlock: 2-5                         [321, 101, 64]            --
│    │    └─Scale: 3-28                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-29                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-30              [321, 101, 64]            29,376
│    │    └─Scale: 3-31                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-32                        [321, 101, 64]            128
├─TSCB: 1-3                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-6                         [101, 321, 64]            --
│    │    └─Scale: 3-33                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-34                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-35              [101, 321, 64]            29,376
│    │    └─Scale: 3-36                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-37                        [101, 321, 64]            128
│    └─ConformerBlock: 2-7                         [321, 101, 64]            --
│    │    └─Scale: 3-38                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-39                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-40              [321, 101, 64]            29,376
│    │    └─Scale: 3-41                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-42                        [321, 101, 64]            128
├─TSCB: 1-4                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-8                         [101, 321, 64]            --
│    │    └─Scale: 3-43                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-44                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-45              [101, 321, 64]            29,376
│    │    └─Scale: 3-46                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-47                        [101, 321, 64]            128
│    └─ConformerBlock: 2-9                         [321, 101, 64]            --
│    │    └─Scale: 3-48                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-49                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-50              [321, 101, 64]            29,376
│    │    └─Scale: 3-51                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-52                        [321, 101, 64]            128
├─TSCB: 1-5                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-10                        [101, 321, 64]            --
│    │    └─Scale: 3-53                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-54                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-55              [101, 321, 64]            29,376
│    │    └─Scale: 3-56                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-57                        [101, 321, 64]            128
│    └─ConformerBlock: 2-11                        [321, 101, 64]            --
│    │    └─Scale: 3-58                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-59                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-60              [321, 101, 64]            29,376
│    │    └─Scale: 3-61                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-62                        [321, 101, 64]            128
├─MaskDecoder: 1-6                                 [1, 1, 321, 201]          --
│    └─DilatedDenseNet: 2-12                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-63                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-64                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-65                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-66                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-67                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-68                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-69                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-70                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-71                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-72                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-73                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-74                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-75                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-76                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-77                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-78                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-13                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-79                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-80                           [1, 128, 321, 101]        24,704
│    └─Conv2d: 2-14                                [1, 1, 321, 201]          129
│    └─InstanceNorm2d: 2-15                        [1, 1, 321, 201]          2
│    └─PReLU: 2-16                                 [1, 1, 321, 201]          1
│    └─Conv2d: 2-17                                [1, 1, 321, 201]          2
│    └─PReLU: 2-18                                 [1, 201, 321]             201
├─ComplexDecoder: 1-7                              [1, 2, 321, 201]          --
│    └─DilatedDenseNet: 2-19                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-81                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-82                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-83                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-84                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-85                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-86                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-87                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-88                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-89                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-90                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-91                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-92                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-93                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-94                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-95                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-96                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-20                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-97                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-98                           [1, 128, 321, 101]        24,704
│    └─InstanceNorm2d: 2-21                        [1, 64, 321, 202]         128
│    └─PReLU: 2-22                                 [1, 64, 321, 202]         64
│    └─Conv2d: 2-23                                [1, 2, 321, 201]          258
====================================================================================================
Total params: 1,834,833
Trainable params: 1,834,833
Non-trainable params: 0
Total mult-adds (G): 41.56
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 4856.40
Params size (MB): 7.34
Estimated Total Size (MB): 4864.25
====================================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Discriminator                            [1, 1]                    --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Conv2d: 2-1                       [1, 16, 100, 160]         512
│    └─InstanceNorm2d: 2-2               [1, 16, 100, 160]         32
│    └─PReLU: 2-3                        [1, 16, 100, 160]         16
│    └─Conv2d: 2-4                       [1, 32, 50, 80]           8,192
│    └─InstanceNorm2d: 2-5               [1, 32, 50, 80]           64
│    └─PReLU: 2-6                        [1, 32, 50, 80]           32
│    └─Conv2d: 2-7                       [1, 64, 25, 40]           32,768
│    └─InstanceNorm2d: 2-8               [1, 64, 25, 40]           128
│    └─PReLU: 2-9                        [1, 64, 25, 40]           64
│    └─Conv2d: 2-10                      [1, 128, 12, 20]          131,072
│    └─InstanceNorm2d: 2-11              [1, 128, 12, 20]          256
│    └─PReLU: 2-12                       [1, 128, 12, 20]          128
│    └─AdaptiveMaxPool2d: 2-13           [1, 128, 1, 1]            --
│    └─Flatten: 2-14                     [1, 128]                  --
│    └─Linear: 2-15                      [1, 64]                   8,256
│    └─Dropout: 2-16                     [1, 64]                   --
│    └─PReLU: 2-17                       [1, 64]                   64
│    └─Linear: 2-18                      [1, 1]                    65
│    └─LearnableSigmoid: 2-19            [1, 1]                    1
==========================================================================================
Total params: 181,650
Trainable params: 181,650
Non-trainable params: 0
Total mult-adds (M): 19.67
==========================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 11.49
Params size (MB): 0.73
Estimated Total Size (MB): 12.73
==========================================================================================
/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/CMGAN_src/data/dataloader.py:52: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")         # in linux
INFO:root:Epoch 0, Step 500, loss: 0.22474785149097443, disc_loss: 0.02905142307281494
INFO:root:Epoch 0, Step 1000, loss: 0.30409061908721924, disc_loss: 0.003923324868083
INFO:root:Epoch 0, Step 1500, loss: 0.3036629557609558, disc_loss: 0.006665391847491264
INFO:root:Epoch 0, Step 2000, loss: 0.22611500322818756, disc_loss: 0.01901853270828724
INFO:root:Epoch 0, Step 2500, loss: 0.2887275516986847, disc_loss: 0.020800312981009483
INFO:root:Generator loss: 0.2166983135478589, Discriminator loss: 0.01166869689613237
INFO:root:Epoch 1, Step 500, loss: 0.26960045099258423, disc_loss: 0.001908478094264865
INFO:root:Epoch 1, Step 1000, loss: 0.17416858673095703, disc_loss: 0.003915143199265003
INFO:root:Epoch 1, Step 1500, loss: 0.3265569508075714, disc_loss: 0.0016214792849496007
INFO:root:Epoch 1, Step 2000, loss: 0.2633805274963379, disc_loss: 0.016134997829794884
INFO:root:Epoch 1, Step 2500, loss: 0.3155548572540283, disc_loss: 0.009505413472652435
INFO:root:Generator loss: 0.19045853629274276, Discriminator loss: 0.007653904358519567
INFO:root:Epoch 2, Step 500, loss: 0.2156854122877121, disc_loss: 0.010562083683907986
INFO:root:Epoch 2, Step 1000, loss: 0.2802836000919342, disc_loss: 0.009426062926650047
INFO:root:Epoch 2, Step 1500, loss: 0.2560853958129883, disc_loss: 0.007881294935941696
INFO:root:Epoch 2, Step 2000, loss: 0.3152700960636139, disc_loss: 0.013961832970380783
INFO:root:Epoch 2, Step 2500, loss: 0.3621880114078522, disc_loss: 0.002692651702091098
INFO:root:Generator loss: 0.18298978365740728, Discriminator loss: 0.005434870949384894
INFO:root:Epoch 3, Step 500, loss: 0.26029765605926514, disc_loss: 0.00849568098783493
INFO:root:Epoch 3, Step 1000, loss: 0.1788109391927719, disc_loss: 0.0010767864296212792
INFO:root:Epoch 3, Step 1500, loss: 0.2627735137939453, disc_loss: 0.004229191690683365
INFO:root:Epoch 3, Step 2000, loss: 0.2408275306224823, disc_loss: 0.0009180866181850433
INFO:root:Epoch 3, Step 2500, loss: 0.19992026686668396, disc_loss: 0.003266181331127882
INFO:root:Generator loss: 0.1829164699081657, Discriminator loss: 0.006419803083702488
INFO:root:Epoch 4, Step 500, loss: 0.2298423945903778, disc_loss: 0.0031448709778487682
INFO:root:Epoch 4, Step 1000, loss: 0.19619935750961304, disc_loss: 0.005107381846755743
INFO:root:Epoch 4, Step 1500, loss: 0.23838672041893005, disc_loss: 0.011414538137614727
INFO:root:Epoch 4, Step 2000, loss: 0.299004465341568, disc_loss: 0.01714302785694599
INFO:root:Epoch 4, Step 2500, loss: 0.24055413901805878, disc_loss: 0.007929477840662003
INFO:root:Generator loss: 0.17673407733729743, Discriminator loss: 0.00779789202429526
INFO:root:Epoch 5, Step 500, loss: 0.22101904451847076, disc_loss: 0.004120372701436281
INFO:root:Epoch 5, Step 1000, loss: 0.23235151171684265, disc_loss: 0.006891627795994282
INFO:root:Epoch 5, Step 1500, loss: 0.2672605812549591, disc_loss: 0.0030488406773656607
INFO:root:Epoch 5, Step 2000, loss: 0.22434209287166595, disc_loss: 0.0012173305731266737
INFO:root:Epoch 5, Step 2500, loss: 0.21551215648651123, disc_loss: 0.006500478368252516
INFO:root:Generator loss: 0.1759132902743747, Discriminator loss: 0.01341409349132519
INFO:root:Epoch 6, Step 500, loss: 0.26831743121147156, disc_loss: 0.008992457762360573
INFO:root:Epoch 6, Step 1000, loss: 0.23743204772472382, disc_loss: 0.008411767892539501
INFO:root:Epoch 6, Step 1500, loss: 0.26381561160087585, disc_loss: 0.008946903049945831
INFO:root:Epoch 6, Step 2000, loss: 0.2371951937675476, disc_loss: 0.00395871140062809
INFO:root:Epoch 6, Step 2500, loss: 0.17278282344341278, disc_loss: 0.0018815877847373486
INFO:root:Generator loss: 0.16709367095411404, Discriminator loss: 0.00817555188666464
INFO:root:Epoch 7, Step 500, loss: 0.3036436438560486, disc_loss: 0.0024451047647744417
INFO:root:Epoch 7, Step 1000, loss: 0.2126343697309494, disc_loss: 0.004559861496090889
INFO:root:Epoch 7, Step 1500, loss: 0.2170187085866928, disc_loss: 0.011136089451611042
INFO:root:Epoch 7, Step 2000, loss: 0.24873755872249603, disc_loss: 0.005408944562077522
INFO:root:Epoch 7, Step 2500, loss: 0.19200672209262848, disc_loss: 0.00018737069331109524
INFO:root:Generator loss: 0.16322797670671083, Discriminator loss: 0.005996705184655899
INFO:root:Epoch 8, Step 500, loss: 0.1444091945886612, disc_loss: 0.00861392542719841
INFO:root:Epoch 8, Step 1000, loss: 0.21454405784606934, disc_loss: 0.0021421965211629868
INFO:root:Epoch 8, Step 1500, loss: 0.21272535622119904, disc_loss: 0.0017494232160970569
INFO:root:Epoch 8, Step 2000, loss: 0.14293794333934784, disc_loss: 0.0037338081747293472
INFO:root:Epoch 8, Step 2500, loss: 0.19282840192317963, disc_loss: 0.005254662130028009
INFO:root:Generator loss: 0.16179955262437606, Discriminator loss: 0.005327789185261263
INFO:root:Epoch 9, Step 500, loss: 0.18523776531219482, disc_loss: 0.0031526151578873396
INFO:root:Epoch 9, Step 1000, loss: 0.2549458146095276, disc_loss: 0.0010047554969787598
INFO:root:Epoch 9, Step 1500, loss: 0.1481451392173767, disc_loss: 0.00544963963329792
INFO:root:Epoch 9, Step 2000, loss: 0.24291512370109558, disc_loss: 0.007235548924654722
INFO:root:Epoch 9, Step 2500, loss: 0.21284811198711395, disc_loss: 0.0007198598468676209
INFO:root:Generator loss: 0.15677089197109045, Discriminator loss: 0.005036490795655216
INFO:root:Epoch 10, Step 500, loss: 0.26357758045196533, disc_loss: 0.010878210887312889
INFO:root:Epoch 10, Step 1000, loss: 0.21237759292125702, disc_loss: 0.004077055025845766
INFO:root:Epoch 10, Step 1500, loss: 0.21380315721035004, disc_loss: 0.0033423062413930893
INFO:root:Epoch 10, Step 2000, loss: 0.27095404267311096, disc_loss: 0.0030891571659594774
INFO:root:Epoch 10, Step 2500, loss: 0.16936667263507843, disc_loss: 0.0018356430809944868
INFO:root:Generator loss: 0.16075477466999905, Discriminator loss: 0.007633791755245167
INFO:root:Epoch 11, Step 500, loss: 0.22585952281951904, disc_loss: 0.0012891923543065786
INFO:root:Epoch 11, Step 1000, loss: 0.22662168741226196, disc_loss: 0.0005916485097259283
INFO:root:Epoch 11, Step 1500, loss: 0.2517945468425751, disc_loss: 0.0011743458453565836
INFO:root:Epoch 11, Step 2000, loss: 0.2200840562582016, disc_loss: 0.004796117078512907
INFO:root:Epoch 11, Step 2500, loss: 0.18146401643753052, disc_loss: 0.0036756510380655527
INFO:root:Generator loss: 0.1571960755922262, Discriminator loss: 0.0066562391580500665
INFO:root:Epoch 12, Step 500, loss: 0.21762420237064362, disc_loss: 0.0025485018268227577
INFO:root:Epoch 12, Step 1000, loss: 0.1933651715517044, disc_loss: 0.0011497532250359654
INFO:root:Epoch 12, Step 1500, loss: 0.1723363846540451, disc_loss: 0.004771396517753601
INFO:root:Epoch 12, Step 2000, loss: 0.2005109041929245, disc_loss: 0.0028872601687908173
INFO:root:Epoch 12, Step 2500, loss: 0.19198985397815704, disc_loss: 0.0036155316047370434
INFO:root:Generator loss: 0.1583440736370179, Discriminator loss: 0.007718669873055068
INFO:root:Epoch 13, Step 500, loss: 0.2420358508825302, disc_loss: 0.002206760225817561
INFO:root:Epoch 13, Step 1000, loss: 0.18110023438930511, disc_loss: 0.0006637828191742301
INFO:root:Epoch 13, Step 1500, loss: 0.15677328407764435, disc_loss: 0.00574213732033968
INFO:root:Epoch 13, Step 2000, loss: 0.17667824029922485, disc_loss: 0.0002813434402924031
INFO:root:Epoch 13, Step 2500, loss: 0.27546608448028564, disc_loss: 0.001621194533072412
INFO:root:Generator loss: 0.1517565857655215, Discriminator loss: 0.008140185495100472
INFO:root:Epoch 14, Step 500, loss: 0.23002226650714874, disc_loss: 0.002643123036250472
INFO:root:Epoch 14, Step 1000, loss: 0.2377118170261383, disc_loss: 0.0025946032255887985
INFO:root:Epoch 14, Step 1500, loss: 0.19148892164230347, disc_loss: 0.006158152595162392
INFO:root:Epoch 14, Step 2000, loss: 0.1844034343957901, disc_loss: 0.0020221902523189783
INFO:root:Epoch 14, Step 2500, loss: 0.1712827831506729, disc_loss: 0.0015493646496906877
INFO:root:Generator loss: 0.15950646924162373, Discriminator loss: 0.005999891631343646
INFO:root:Epoch 15, Step 500, loss: 0.25991174578666687, disc_loss: 0.0028084316290915012
INFO:root:Epoch 15, Step 1000, loss: 0.25462302565574646, disc_loss: 0.0026828700210899115
INFO:root:Epoch 15, Step 1500, loss: 0.1708681732416153, disc_loss: 0.0012271279701963067
INFO:root:Epoch 15, Step 2000, loss: 0.12742479145526886, disc_loss: 0.005533102434128523
INFO:root:Epoch 15, Step 2500, loss: 0.22345690429210663, disc_loss: 0.0016841550823301077
INFO:root:Generator loss: 0.15122101524645842, Discriminator loss: 0.005841956020658384
INFO:root:Epoch 16, Step 500, loss: 0.24913419783115387, disc_loss: 0.001095109386369586
INFO:root:Epoch 16, Step 1000, loss: 0.16056668758392334, disc_loss: 0.0002690961700864136
INFO:root:Epoch 16, Step 1500, loss: 0.2039673775434494, disc_loss: 0.0013294488890096545
INFO:root:Epoch 16, Step 2000, loss: 0.18976227939128876, disc_loss: 0.0002385071275057271
INFO:root:Epoch 16, Step 2500, loss: 0.20810095965862274, disc_loss: 0.0020919060334563255
INFO:root:Generator loss: 0.15324367687684817, Discriminator loss: 0.0071832987292527305
INFO:root:Epoch 17, Step 500, loss: 0.22813962399959564, disc_loss: 0.0034587793052196503
INFO:root:Epoch 17, Step 1000, loss: 0.22490385174751282, disc_loss: 0.00048674558638595045
INFO:root:Epoch 17, Step 1500, loss: 0.17254185676574707, disc_loss: 0.006542440969496965
INFO:root:Epoch 17, Step 2000, loss: 0.23887045681476593, disc_loss: 0.005589704494923353
INFO:root:Epoch 17, Step 2500, loss: 0.16440366208553314, disc_loss: 0.0009854665258899331
INFO:root:Generator loss: 0.15477724235902712, Discriminator loss: 0.005621354669484805
INFO:root:Epoch 18, Step 500, loss: 0.27820587158203125, disc_loss: 0.0030173722188919783
INFO:root:Epoch 18, Step 1000, loss: 0.24730712175369263, disc_loss: 0.002183347474783659
INFO:root:Epoch 18, Step 1500, loss: 0.24753202497959137, disc_loss: 0.0006544495117850602
INFO:root:Epoch 18, Step 2000, loss: 0.1931339055299759, disc_loss: 0.0013753054663538933
INFO:root:Epoch 18, Step 2500, loss: 0.2590257227420807, disc_loss: 0.0005891674081794918
INFO:root:Generator loss: 0.15473001551570245, Discriminator loss: 0.005993325698971567
INFO:root:Epoch 19, Step 500, loss: 0.1500679850578308, disc_loss: 0.0007824921631254256
INFO:root:Epoch 19, Step 1000, loss: 0.20321914553642273, disc_loss: 0.003632074687629938
INFO:root:Epoch 19, Step 1500, loss: 0.23347000777721405, disc_loss: 0.0007829663227312267
INFO:root:Epoch 19, Step 2000, loss: 0.15081113576889038, disc_loss: 0.0010321232257410884
INFO:root:Epoch 19, Step 2500, loss: 0.22830580174922943, disc_loss: 0.0006449762149713933
INFO:root:Generator loss: 0.154264247026837, Discriminator loss: 0.008725915416487148
INFO:root:Epoch 20, Step 500, loss: 0.190712109208107, disc_loss: 0.0022097108885645866
INFO:root:Epoch 20, Step 1000, loss: 0.18595291674137115, disc_loss: 0.0009635086171329021
INFO:root:Epoch 20, Step 1500, loss: 0.20609742403030396, disc_loss: 0.0009626835817471147
INFO:root:Epoch 20, Step 2000, loss: 0.15587133169174194, disc_loss: 0.0033697427716106176
INFO:root:Epoch 20, Step 2500, loss: 0.20546744763851166, disc_loss: 0.0020260843448340893
INFO:root:Generator loss: 0.14768881983693363, Discriminator loss: 0.006263513663548861
INFO:root:Epoch 21, Step 500, loss: 0.24253322184085846, disc_loss: 0.005074722692370415
INFO:root:Epoch 21, Step 1000, loss: 0.20548726618289948, disc_loss: 0.00032487561111338437
INFO:root:Epoch 21, Step 1500, loss: 0.18031637370586395, disc_loss: 0.004289018455892801
INFO:root:Epoch 21, Step 2000, loss: 0.2002221941947937, disc_loss: 0.0015091074164956808
INFO:root:Epoch 21, Step 2500, loss: 0.19230540096759796, disc_loss: 0.0024257816839963198
INFO:root:Generator loss: 0.15176306151359983, Discriminator loss: 0.005075560682704695
INFO:root:Epoch 22, Step 500, loss: 0.23158273100852966, disc_loss: 0.005478506442159414
INFO:root:Epoch 22, Step 1000, loss: 0.2554013431072235, disc_loss: 0.002135039074346423
INFO:root:Epoch 22, Step 1500, loss: 0.21312151849269867, disc_loss: 0.0012685863766819239
INFO:root:Epoch 22, Step 2000, loss: 0.1475622057914734, disc_loss: 0.0032785083167254925
INFO:root:Epoch 22, Step 2500, loss: 0.2210012525320053, disc_loss: 0.0064458828419446945
INFO:root:Generator loss: 0.15005268228864208, Discriminator loss: 0.00833543928315212
INFO:root:Epoch 23, Step 500, loss: 0.20202448964118958, disc_loss: 0.008010096848011017
INFO:root:Epoch 23, Step 1000, loss: 0.2353523075580597, disc_loss: 0.0022804017644375563
INFO:root:Epoch 23, Step 1500, loss: 0.1780223846435547, disc_loss: 0.0010668408358469605
INFO:root:Epoch 23, Step 2000, loss: 0.21830402314662933, disc_loss: 0.00236292346380651
INFO:root:Epoch 23, Step 2500, loss: 0.2030019760131836, disc_loss: 0.003545341081917286
INFO:root:Generator loss: 0.15009236936140985, Discriminator loss: 0.0058938072635074485
INFO:root:Epoch 24, Step 500, loss: 0.1811511218547821, disc_loss: 0.0010240481933578849
INFO:root:Epoch 24, Step 1000, loss: 0.15769244730472565, disc_loss: 0.0013742797309532762
INFO:root:Epoch 24, Step 1500, loss: 0.19635537266731262, disc_loss: 0.07973500341176987
INFO:root:Epoch 24, Step 2000, loss: 0.14372575283050537, disc_loss: 0.002407185733318329
INFO:root:Epoch 24, Step 2500, loss: 0.24546508491039276, disc_loss: 0.0015171109698712826
INFO:root:Generator loss: 0.1485875192848803, Discriminator loss: 0.00511807400658495
INFO:root:Epoch 25, Step 500, loss: 0.20454548299312592, disc_loss: 0.00015470256039407104
INFO:root:Epoch 25, Step 1000, loss: 0.16313470900058746, disc_loss: 0.0009394358494319022
INFO:root:Epoch 25, Step 1500, loss: 0.21291086077690125, disc_loss: 0.0013819510350003839
INFO:root:Epoch 25, Step 2000, loss: 0.10624022781848907, disc_loss: 0.0017440087394788861
INFO:root:Epoch 25, Step 2500, loss: 0.23866963386535645, disc_loss: 0.0013780349399894476
INFO:root:Generator loss: 0.14663367411031306, Discriminator loss: 0.0049092384465748
INFO:root:Epoch 26, Step 500, loss: 0.1918131560087204, disc_loss: 0.00422823429107666
INFO:root:Epoch 26, Step 1000, loss: 0.16956523060798645, disc_loss: 0.0016048407414928079
INFO:root:Epoch 26, Step 1500, loss: 0.21747712790966034, disc_loss: 0.0018333251355215907
INFO:root:Epoch 26, Step 2000, loss: 0.12222308665513992, disc_loss: 0.001899507362395525
INFO:root:Epoch 26, Step 2500, loss: 0.13204118609428406, disc_loss: 0.003836157498881221
INFO:root:Generator loss: 0.14698189218501442, Discriminator loss: 0.004573948158898382
INFO:root:Epoch 27, Step 500, loss: 0.21968691051006317, disc_loss: 0.0013567224377766252
INFO:root:Epoch 27, Step 1000, loss: 0.15978819131851196, disc_loss: 0.0013570509618148208
INFO:root:Epoch 27, Step 1500, loss: 0.2557832598686218, disc_loss: 0.0012286276323720813
INFO:root:Epoch 27, Step 2000, loss: 0.1478758454322815, disc_loss: 8.986641478259116e-05
INFO:root:Epoch 27, Step 2500, loss: 0.17463666200637817, disc_loss: 0.0032954751513898373
INFO:root:Generator loss: 0.14729812748513174, Discriminator loss: 0.006928284343479549
INFO:root:Epoch 28, Step 500, loss: 0.2299908548593521, disc_loss: 0.0025255687069147825
INFO:root:Epoch 28, Step 1000, loss: 0.20862121880054474, disc_loss: 0.0016646061558276415
INFO:root:Epoch 28, Step 1500, loss: 0.15090399980545044, disc_loss: 0.001638664398342371
INFO:root:Epoch 28, Step 2000, loss: 0.15923941135406494, disc_loss: 0.0008401009254157543
INFO:root:Epoch 28, Step 2500, loss: 0.1576189249753952, disc_loss: 0.0022078196052461863
INFO:root:Generator loss: 0.14735282234196523, Discriminator loss: 0.0046658111981724305
INFO:root:Epoch 29, Step 500, loss: 0.1857900172472, disc_loss: 0.0015021138824522495
INFO:root:Epoch 29, Step 1000, loss: 0.1330161839723587, disc_loss: 0.0038603453431278467
INFO:root:Epoch 29, Step 1500, loss: 0.16549353301525116, disc_loss: 0.0005325690726749599
INFO:root:Epoch 29, Step 2000, loss: 0.1646365076303482, disc_loss: 0.0006904299953021109
INFO:root:Epoch 29, Step 2500, loss: 0.14582137763500214, disc_loss: 0.0008879283559508622
INFO:root:Generator loss: 0.14828517750918285, Discriminator loss: 0.005594894757327054
INFO:root:Epoch 30, Step 500, loss: 0.20861110091209412, disc_loss: 0.0026662226300686598
INFO:root:Epoch 30, Step 1000, loss: 0.21317780017852783, disc_loss: 0.0010027197422459722
INFO:root:Epoch 30, Step 1500, loss: 0.2710629403591156, disc_loss: 0.002294368576258421
INFO:root:Epoch 30, Step 2000, loss: 0.18169797956943512, disc_loss: 0.0025281240232288837
INFO:root:Epoch 30, Step 2500, loss: 0.21142739057540894, disc_loss: 0.00015352923946920782
INFO:root:Generator loss: 0.14805616561359572, Discriminator loss: 0.003999245177643052
INFO:root:Epoch 31, Step 500, loss: 0.13449151813983917, disc_loss: 0.0010333950631320477
INFO:root:Epoch 31, Step 1000, loss: 0.16063781082630157, disc_loss: 0.0009392278152517974
INFO:root:Epoch 31, Step 1500, loss: 0.1956646889448166, disc_loss: 0.0011549190385267138
INFO:root:Epoch 31, Step 2000, loss: 0.184988871216774, disc_loss: 0.0020072637125849724
INFO:root:Epoch 31, Step 2500, loss: 0.157389298081398, disc_loss: 0.002698228694498539
INFO:root:Generator loss: 0.14695529957998146, Discriminator loss: 0.0052971536054790755
INFO:root:Epoch 32, Step 500, loss: 0.1879606395959854, disc_loss: 0.0024857863318175077
INFO:root:Epoch 32, Step 1000, loss: 0.19654865562915802, disc_loss: 0.015878278762102127
INFO:root:Epoch 32, Step 1500, loss: 0.18625310063362122, disc_loss: 0.00470429752022028
INFO:root:Epoch 32, Step 2000, loss: 0.14354930818080902, disc_loss: 0.00107561144977808
INFO:root:Epoch 32, Step 2500, loss: 0.26681989431381226, disc_loss: 0.0013198645319789648
INFO:root:Generator loss: 0.14719167713401388, Discriminator loss: 0.008175665099280345
INFO:root:Epoch 33, Step 500, loss: 0.15392057597637177, disc_loss: 0.0026676268316805363
INFO:root:Epoch 33, Step 1000, loss: 0.2009771466255188, disc_loss: 0.0010990486480295658
INFO:root:Epoch 33, Step 1500, loss: 0.20312370359897614, disc_loss: 0.0013479205081239343
INFO:root:Epoch 33, Step 2000, loss: 0.20648206770420074, disc_loss: 0.0011756103485822678
INFO:root:Epoch 33, Step 2500, loss: 0.1419822722673416, disc_loss: 0.0014683827757835388
INFO:root:Generator loss: 0.1495826927926934, Discriminator loss: 0.008238389400220803
INFO:root:Epoch 34, Step 500, loss: 0.24416449666023254, disc_loss: 0.0026774578727781773
INFO:root:Epoch 34, Step 1000, loss: 0.18802428245544434, disc_loss: 0.002323796506971121
INFO:root:Epoch 34, Step 1500, loss: 0.19959187507629395, disc_loss: 0.0017908824374899268
INFO:root:Epoch 34, Step 2000, loss: 0.21038216352462769, disc_loss: 0.0006531226099468768
INFO:root:Epoch 34, Step 2500, loss: 0.13888637721538544, disc_loss: 0.0011936621740460396
INFO:root:Generator loss: 0.14613570942028056, Discriminator loss: 0.0038758080738208944
INFO:root:Epoch 35, Step 500, loss: 0.22681957483291626, disc_loss: 0.016850296407938004
INFO:root:Epoch 35, Step 1000, loss: 0.1813148707151413, disc_loss: 0.0013014284195378423
INFO:root:Epoch 35, Step 1500, loss: 0.18770545721054077, disc_loss: 0.0010791560634970665
INFO:root:Epoch 35, Step 2000, loss: 0.19000546634197235, disc_loss: 0.0013534992467612028
INFO:root:Epoch 35, Step 2500, loss: 0.1698361486196518, disc_loss: 0.0052314200438559055
INFO:root:Generator loss: 0.14862833233568276, Discriminator loss: 0.006326944706000804
INFO:root:Epoch 36, Step 500, loss: 0.1643926501274109, disc_loss: 0.00057748903054744
INFO:root:Epoch 36, Step 1000, loss: 0.17672310769557953, disc_loss: 0.005035222973674536
INFO:root:Epoch 36, Step 1500, loss: 0.23819905519485474, disc_loss: 0.001011848682537675
INFO:root:Epoch 36, Step 2000, loss: 0.14938317239284515, disc_loss: 0.0007366043864749372
INFO:root:Epoch 36, Step 2500, loss: 0.23858754336833954, disc_loss: 0.0016356734558939934
INFO:root:Generator loss: 0.14636277892057178, Discriminator loss: 0.006931568429597938
INFO:root:Epoch 37, Step 500, loss: 0.23562662303447723, disc_loss: 0.003570208791643381
INFO:root:Epoch 37, Step 1000, loss: 0.1713133454322815, disc_loss: 0.0023990273475646973
INFO:root:Epoch 37, Step 1500, loss: 0.134856715798378, disc_loss: 0.001270617009140551
INFO:root:Epoch 37, Step 2000, loss: 0.1372757852077484, disc_loss: 0.0021723629906773567
INFO:root:Epoch 37, Step 2500, loss: 0.14109735190868378, disc_loss: 0.0006020981818437576
INFO:root:Generator loss: 0.1464223235990237, Discriminator loss: 0.005161430788045869
INFO:root:Epoch 38, Step 500, loss: 0.16406667232513428, disc_loss: 0.002194889821112156
INFO:root:Epoch 38, Step 1000, loss: 0.18089786171913147, disc_loss: 0.0005608653300441802
INFO:root:Epoch 38, Step 1500, loss: 0.19917526841163635, disc_loss: 0.0005083624855615199
INFO:root:Epoch 38, Step 2000, loss: 0.21542216837406158, disc_loss: 0.0003018188290297985
INFO:root:Epoch 38, Step 2500, loss: 0.2060168981552124, disc_loss: 0.0012411910574883223
INFO:root:Generator loss: 0.14843088222070805, Discriminator loss: 0.005448377698291013
INFO:root:Epoch 39, Step 500, loss: 0.1830831617116928, disc_loss: 0.0011610790388658643
INFO:root:Epoch 39, Step 1000, loss: 0.17119336128234863, disc_loss: 0.0005112116923555732
INFO:root:Epoch 39, Step 1500, loss: 0.1675472855567932, disc_loss: 0.0034304934088140726
INFO:root:Epoch 39, Step 2000, loss: 0.158808633685112, disc_loss: 0.07698436081409454
INFO:root:Epoch 39, Step 2500, loss: 0.2888544201850891, disc_loss: 0.03160517290234566
INFO:root:Generator loss: 0.14714986136526736, Discriminator loss: 0.005842969791311827
INFO:root:Epoch 40, Step 500, loss: 0.22548072040081024, disc_loss: 0.004717851988971233
INFO:root:Epoch 40, Step 1000, loss: 0.12999345362186432, disc_loss: 0.0005208070506341755
INFO:root:Epoch 40, Step 1500, loss: 0.22294951975345612, disc_loss: 0.0014358209446072578
INFO:root:Epoch 40, Step 2000, loss: 0.15261605381965637, disc_loss: 0.0016040429472923279
INFO:root:Epoch 40, Step 2500, loss: 0.2009570151567459, disc_loss: 0.00016749181668274105
INFO:root:Generator loss: 0.14534249362870327, Discriminator loss: 0.0057878904480479195
INFO:root:Epoch 41, Step 500, loss: 0.14796656370162964, disc_loss: 6.60884688841179e-05
INFO:root:Epoch 41, Step 1000, loss: 0.18888024985790253, disc_loss: 0.0007925992249511182
INFO:root:Epoch 41, Step 1500, loss: 0.15324939787387848, disc_loss: 0.0011919010430574417
INFO:root:Epoch 41, Step 2000, loss: 0.1825818121433258, disc_loss: 0.00023565490846522152
INFO:root:Epoch 41, Step 2500, loss: 0.18198291957378387, disc_loss: 0.001106716226786375
INFO:root:Generator loss: 0.14793853685983177, Discriminator loss: 0.0065233822454510764
INFO:root:Epoch 42, Step 500, loss: 0.17046965658664703, disc_loss: 0.0011338909389451146
INFO:root:Epoch 42, Step 1000, loss: 0.2061847448348999, disc_loss: 0.0028825115878134966
INFO:root:Epoch 42, Step 1500, loss: 0.20776276290416718, disc_loss: 0.00018945611373055726
INFO:root:Epoch 42, Step 2000, loss: 0.2414737343788147, disc_loss: 0.0012159908656030893
INFO:root:Epoch 42, Step 2500, loss: 0.1984747350215912, disc_loss: 0.002605048706755042
INFO:root:Generator loss: 0.148700409360881, Discriminator loss: 0.007376672240849799
INFO:root:Epoch 43, Step 500, loss: 0.24334202706813812, disc_loss: 0.00010303316230420023
INFO:root:Epoch 43, Step 1000, loss: 0.2596449553966522, disc_loss: 0.0002656920114532113
INFO:root:Epoch 43, Step 1500, loss: 0.17532555758953094, disc_loss: 0.001450690208002925
INFO:root:Epoch 43, Step 2000, loss: 0.24632208049297333, disc_loss: 0.003126633819192648
INFO:root:Epoch 43, Step 2500, loss: 0.20915670692920685, disc_loss: 0.0010474977316334844
INFO:root:Generator loss: 0.14434354907823999, Discriminator loss: 0.004839366810681418
INFO:root:Epoch 44, Step 500, loss: 0.23661203682422638, disc_loss: 0.002064549131318927
INFO:root:Epoch 44, Step 1000, loss: 0.17501337826251984, disc_loss: 0.0011404938995838165
INFO:root:Epoch 44, Step 1500, loss: 0.1759973168373108, disc_loss: 0.0017127693863585591
INFO:root:Epoch 44, Step 2000, loss: 0.18147020041942596, disc_loss: 0.0009007895132526755
INFO:root:Epoch 44, Step 2500, loss: 0.20433488488197327, disc_loss: 0.0017436427297070622
INFO:root:Generator loss: 0.14589314665464523, Discriminator loss: 0.0049108405945694315
INFO:root:Epoch 45, Step 500, loss: 0.14586666226387024, disc_loss: 0.0032715764828026295
INFO:root:Epoch 45, Step 1000, loss: 0.1825631856918335, disc_loss: 0.001379787689074874
INFO:root:Epoch 45, Step 1500, loss: 0.21763746440410614, disc_loss: 0.0034408767241984606
INFO:root:Epoch 45, Step 2000, loss: 0.117268405854702, disc_loss: 0.0005962297436781228
INFO:root:Epoch 45, Step 2500, loss: 0.2791043519973755, disc_loss: 0.0009587309323251247
INFO:root:Generator loss: 0.14927412233161694, Discriminator loss: 0.006981169343529897
INFO:root:Epoch 46, Step 500, loss: 0.24333074688911438, disc_loss: 0.0022912686690688133
INFO:root:Epoch 46, Step 1000, loss: 0.1643739938735962, disc_loss: 0.00014544402074534446
INFO:root:Epoch 46, Step 1500, loss: 0.16704057157039642, disc_loss: 0.0016146969282999635
INFO:root:Epoch 46, Step 2000, loss: 0.1789604127407074, disc_loss: 0.003498997073620558
INFO:root:Epoch 46, Step 2500, loss: 0.18905337154865265, disc_loss: 0.00462074251845479
INFO:root:Generator loss: 0.1458883451894649, Discriminator loss: 0.00549033355202076
INFO:root:Epoch 47, Step 500, loss: 0.20534250140190125, disc_loss: 0.0005342711810953915
INFO:root:Epoch 47, Step 1000, loss: 0.19631339609622955, disc_loss: 0.0004283837624825537
INFO:root:Epoch 47, Step 1500, loss: 0.13058941066265106, disc_loss: 0.0022551189176738262
INFO:root:Epoch 47, Step 2000, loss: 0.13124945759773254, disc_loss: 0.0008496109512634575
INFO:root:Epoch 47, Step 2500, loss: 0.19208374619483948, disc_loss: 0.0010583855910226703
INFO:root:Generator loss: 0.14794298995611738, Discriminator loss: 0.007363646114418833
INFO:root:Epoch 48, Step 500, loss: 0.2127149999141693, disc_loss: 0.0002341270010219887
INFO:root:Epoch 48, Step 1000, loss: 0.14894653856754303, disc_loss: 0.0009702435345388949
INFO:root:Epoch 48, Step 1500, loss: 0.16917838156223297, disc_loss: 0.0026184734888374805
INFO:root:Epoch 48, Step 2000, loss: 0.1347915232181549, disc_loss: 0.0012702601961791515
INFO:root:Epoch 48, Step 2500, loss: 0.23276498913764954, disc_loss: 0.0014007800491526723
INFO:root:Generator loss: 0.1471872623394994, Discriminator loss: 0.006474321050491993
INFO:root:Epoch 49, Step 500, loss: 0.12552395462989807, disc_loss: 0.002493911888450384
INFO:root:Epoch 49, Step 1000, loss: 0.20147329568862915, disc_loss: 0.0014659649459645152
INFO:root:Epoch 49, Step 1500, loss: 0.20307214558124542, disc_loss: 0.0006048237555660307
INFO:root:Epoch 49, Step 2000, loss: 0.14557139575481415, disc_loss: 0.003389626508578658
INFO:root:Epoch 49, Step 2500, loss: 0.20766541361808777, disc_loss: 0.0007900324417278171
INFO:root:Generator loss: 0.14601632449956772, Discriminator loss: 0.005504108214198408
INFO:root:Epoch 50, Step 500, loss: 0.2320891171693802, disc_loss: 0.0009621792705729604
INFO:root:Epoch 50, Step 1000, loss: 0.16293205320835114, disc_loss: 0.0006757958326488733
INFO:root:Epoch 50, Step 1500, loss: 0.28385135531425476, disc_loss: 0.0014759341720491648
INFO:root:Epoch 50, Step 2000, loss: 0.1842515915632248, disc_loss: 0.0026458597276359797
INFO:root:Epoch 50, Step 2500, loss: 0.1876383274793625, disc_loss: 0.0016269867774099112
INFO:root:Generator loss: 0.1486105100043769, Discriminator loss: 0.006882177324707335
INFO:root:Epoch 51, Step 500, loss: 0.18543069064617157, disc_loss: 0.0008443987462669611
INFO:root:Epoch 51, Step 1000, loss: 0.21712727844715118, disc_loss: 0.0009830943308770657
INFO:root:Epoch 51, Step 1500, loss: 0.1453334391117096, disc_loss: 0.01707114465534687
INFO:root:Epoch 51, Step 2000, loss: 0.17660419642925262, disc_loss: 0.001685981871560216
INFO:root:Epoch 51, Step 2500, loss: 0.12167266011238098, disc_loss: 0.001662782276980579
INFO:root:Generator loss: 0.14607203664999563, Discriminator loss: 0.005218153815909777
INFO:root:Epoch 52, Step 500, loss: 0.15255779027938843, disc_loss: 0.0016871218103915453
INFO:root:Epoch 52, Step 1000, loss: 0.1766696572303772, disc_loss: 0.00040028520743362606
INFO:root:Epoch 52, Step 1500, loss: 0.13886140286922455, disc_loss: 0.0008039771928451955
INFO:root:Epoch 52, Step 2000, loss: 0.2759159505367279, disc_loss: 0.0004316225531511009
INFO:root:Epoch 52, Step 2500, loss: 0.16383910179138184, disc_loss: 0.0006436686962842941
INFO:root:Generator loss: 0.14690449851953868, Discriminator loss: 0.004575891274655378
INFO:root:Epoch 53, Step 500, loss: 0.16620784997940063, disc_loss: 0.0023817347828298807
INFO:root:Epoch 53, Step 1000, loss: 0.18823780119419098, disc_loss: 0.0033341264352202415
INFO:root:Epoch 53, Step 1500, loss: 0.1635335236787796, disc_loss: 0.0018560058670118451
INFO:root:Epoch 53, Step 2000, loss: 0.2203061729669571, disc_loss: 0.0025954253505915403
INFO:root:Epoch 53, Step 2500, loss: 0.12794393301010132, disc_loss: 0.0018642633222043514
INFO:root:Generator loss: 0.1471786253081942, Discriminator loss: 0.005194779799884362
INFO:root:Epoch 54, Step 500, loss: 0.2640891373157501, disc_loss: 0.002090358640998602
INFO:root:Epoch 54, Step 1000, loss: 0.19596874713897705, disc_loss: 0.0010654600337147713
INFO:root:Epoch 54, Step 1500, loss: 0.21573859453201294, disc_loss: 0.0014777620090171695
INFO:root:Epoch 54, Step 2000, loss: 0.21312600374221802, disc_loss: 0.001240651705302298
INFO:root:Epoch 54, Step 2500, loss: 0.2496747523546219, disc_loss: 0.0007507418631576002
INFO:root:Generator loss: 0.14929123544721928, Discriminator loss: 0.007868926526374779
INFO:root:Epoch 55, Step 500, loss: 0.12084364145994186, disc_loss: 0.0013063459191471338
INFO:root:Epoch 55, Step 1000, loss: 0.16512903571128845, disc_loss: 0.000794856867287308
INFO:root:Epoch 55, Step 1500, loss: 0.21801821887493134, disc_loss: 0.002148496452718973
INFO:root:Epoch 55, Step 2000, loss: 0.1508403718471527, disc_loss: 0.0017176058609038591
INFO:root:Epoch 55, Step 2500, loss: 0.19543184340000153, disc_loss: 9.104571654461324e-05
INFO:root:Generator loss: 0.1464171519557249, Discriminator loss: 0.005319142694588663
INFO:root:Epoch 56, Step 500, loss: 0.1949601024389267, disc_loss: 0.0004594245692715049
INFO:root:Epoch 56, Step 1000, loss: 0.1596039980649948, disc_loss: 0.0012024190509691834
INFO:root:Epoch 56, Step 1500, loss: 0.17134594917297363, disc_loss: 0.0003417929110582918
INFO:root:Epoch 56, Step 2000, loss: 0.1742829978466034, disc_loss: 0.027118034660816193
INFO:root:Epoch 56, Step 2500, loss: 0.211641326546669, disc_loss: 0.0006466408376581967
INFO:root:Generator loss: 0.14826465322120677, Discriminator loss: 0.006938119894611306
INFO:root:Epoch 57, Step 500, loss: 0.18470515310764313, disc_loss: 0.0028956809546798468
INFO:root:Epoch 57, Step 1000, loss: 0.08987710624933243, disc_loss: 0.0008109677000902593
INFO:root:Epoch 57, Step 1500, loss: 0.11362955719232559, disc_loss: 0.0006024328758940101
INFO:root:Epoch 57, Step 2000, loss: 0.2318817675113678, disc_loss: 0.00024236374883912504
INFO:root:Epoch 57, Step 2500, loss: 0.20872409641742706, disc_loss: 0.0021361459512263536
INFO:root:Generator loss: 0.1472767197608369, Discriminator loss: 0.005507626818320364
INFO:root:Epoch 58, Step 500, loss: 0.1799832284450531, disc_loss: 0.0008995853131636977
INFO:root:Epoch 58, Step 1000, loss: 0.18430377542972565, disc_loss: 0.002237720414996147
INFO:root:Epoch 58, Step 1500, loss: 0.20750868320465088, disc_loss: 0.0007876899326220155
INFO:root:Epoch 58, Step 2000, loss: 0.1976911872625351, disc_loss: 0.0010489810956642032
INFO:root:Epoch 58, Step 2500, loss: 0.23493072390556335, disc_loss: 0.002987232990562916
INFO:root:Generator loss: 0.14657473802855872, Discriminator loss: 0.005938667308601881
INFO:root:Epoch 59, Step 500, loss: 0.14572325348854065, disc_loss: 0.0011666424106806517
INFO:root:Epoch 59, Step 1000, loss: 0.15921208262443542, disc_loss: 0.0012759400997310877
INFO:root:Epoch 59, Step 1500, loss: 0.1491692215204239, disc_loss: 0.0003530960239004344
INFO:root:Epoch 59, Step 2000, loss: 0.13161616027355194, disc_loss: 0.0013261130079627037
INFO:root:Epoch 59, Step 2500, loss: 0.12079492956399918, disc_loss: 0.00131147017236799
INFO:root:Generator loss: 0.14723533992339105, Discriminator loss: 0.00675829730025019
Training finished.

------------------------------------------------------------------------------------------------------------------------------------------
Starting batch evaluation...
Evaluating: CMGAN_epoch_0_0.081
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.8255767386804505 csig:  4.338765255726251 cbak:  3.4799332134578815 covl:  3.640149978174602 ssnr:  8.393641299772838 stoi:  0.939553683288271


Evaluating: CMGAN_epoch_10_0.062
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.15611838643412 csig:  4.478770182918226 cbak:  3.7532260362293535 covl:  3.8862689128942542 ssnr:  10.091490342705345 stoi:  0.9529036582643851


Evaluating: CMGAN_epoch_1_0.078
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.8711892175442966 csig:  4.381691958968014 cbak:  3.546336099355413 covl:  3.687504993435873 ssnr:  9.052770342569104 stoi:  0.9386878671812121


Evaluating: CMGAN_epoch_11_0.063
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3288860176373456 csig:  4.531469247688792 cbak:  3.8275416306277195 covl:  4.013070574987401 ssnr:  9.963875293821184 stoi:  0.9494558712108545


Evaluating: CMGAN_epoch_12_0.065
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2216670077691956 csig:  4.511942474815902 cbak:  3.7190155719878595 covl:  3.9495981791383317 ssnr:  9.120479330842711 stoi:  0.9537343451423606


Evaluating: CMGAN_epoch_13_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.28335563650409 csig:  4.548611210391863 cbak:  3.822392115479754 covl:  3.996067154893158 ssnr:  10.224921800278738 stoi:  0.954094010723049


Evaluating: CMGAN_epoch_14_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3242889026415 csig:  4.571053631182435 cbak:  3.8309360908257375 covl:  4.04225240418562 ssnr:  10.040979911793965 stoi:  0.9538005988798024


Evaluating: CMGAN_epoch_15_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2579522312266156 csig:  4.524984062595627 cbak:  3.8153567222835267 covl:  3.97420166566123 ssnr:  10.29752573175713 stoi:  0.955054513705428


Evaluating: CMGAN_epoch_16_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2307382147867703 csig:  4.512532324814852 cbak:  3.8093486651930593 covl:  3.9503205648966557 ssnr:  10.40205127078555 stoi:  0.9541549735975885


Evaluating: CMGAN_epoch_17_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.304112479524705 csig:  4.560178281359282 cbak:  3.8386013768012983 covl:  4.023891528635409 ssnr:  10.321194781891842 stoi:  0.9516087493664791


Evaluating: CMGAN_epoch_18_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3368439062417132 csig:  4.554975623119673 cbak:  3.8371755318253977 covl:  4.035627040887216 ssnr:  10.047698665690508 stoi:  0.9541291920841206


Evaluating: CMGAN_epoch_19_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2558346354556313 csig:  4.550706165203349 cbak:  3.8063852423189406 covl:  3.9874861513509856 ssnr:  10.178024697028137 stoi:  0.9552116024027163


Evaluating: CMGAN_epoch_20_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2968026000319175 csig:  4.574795963308683 cbak:  3.8145406201863836 covl:  4.024825680684825 ssnr:  10.006718332461803 stoi:  0.9550977473874883


Evaluating: CMGAN_epoch_2_0.073
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0442142595075867 csig:  4.458119743817728 cbak:  3.6385686340444314 covl:  3.8231249593704204 ssnr:  9.198423062243506 stoi:  0.9445857642892446


Evaluating: CMGAN_epoch_21_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2880369291722196 csig:  4.56071885073362 cbak:  3.8208190886491793 covl:  4.014938401011746 ssnr:  10.15371144670645 stoi:  0.9546761072645925


Evaluating: CMGAN_epoch_22_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.258929705012192 csig:  4.5852220579887275 cbak:  3.8342572248969478 covl:  4.004304286547596 ssnr:  10.605184208982784 stoi:  0.955112274705531


Evaluating: CMGAN_epoch_23_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2804551824782657 csig:  4.562521571622809 cbak:  3.8041223381600178 covl:  4.011615114809444 ssnr:  9.9600117133602 stoi:  0.9555418646157607


Evaluating: CMGAN_epoch_24_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3447438131258327 csig:  4.597363086619679 cbak:  3.8571105152467458 covl:  4.06536685740775 ssnr:  10.29801383257175 stoi:  0.955272068286166


Evaluating: CMGAN_epoch_25_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.317625631117126 csig:  4.58697941059279 cbak:  3.8514437705544977 covl:  4.042702874275641 ssnr:  10.392235343302904 stoi:  0.9555276489664559


Evaluating: CMGAN_epoch_26_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3671859078904958 csig:  4.609496481693373 cbak:  3.8537101918583683 covl:  4.085001016010845 ssnr:  10.087563591648378 stoi:  0.9553893920020347


Evaluating: CMGAN_epoch_27_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3290687152772276 csig:  4.59226603884522 cbak:  3.8564267266332233 covl:  4.053564283200456 ssnr:  10.411110704262095 stoi:  0.955431278174669


Evaluating: CMGAN_epoch_28_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2944329495279536 csig:  4.589225040841595 cbak:  3.840111525749217 covl:  4.034671318345967 ssnr:  10.394484589750462 stoi:  0.9562687712468553


Evaluating: CMGAN_epoch_29_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.355383681006802 csig:  4.600110164718409 cbak:  3.854891025532616 covl:  4.072257204210142 ssnr:  10.18033491561163 stoi:  0.9552610200521036


Evaluating: CMGAN_epoch_30_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.334356304077269 csig:  4.579467417263269 cbak:  3.855413654226258 covl:  4.05034665261605 ssnr:  10.342095449649142 stoi:  0.956072451842536


Evaluating: CMGAN_epoch_3_0.075
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.027056360852371 csig:  4.46872330371317 cbak:  3.6202912786590673 covl:  3.821881192062786 ssnr:  9.040924069086424 stoi:  0.9470035317146165


Evaluating: CMGAN_epoch_31_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.291489941547218 csig:  4.594291830317219 cbak:  3.834245402266492 covl:  4.032583957578832 ssnr:  10.329352886186479 stoi:  0.9560338465653135


Evaluating: CMGAN_epoch_32_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3409046909762816 csig:  4.60338605717361 cbak:  3.820122083199358 covl:  4.06924925743541 ssnr:  9.766101261434722 stoi:  0.9554788830298256


Evaluating: CMGAN_epoch_33_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3402864060644966 csig:  4.607254914271178 cbak:  3.8609592067114638 covl:  4.070058539174826 ssnr:  10.3942805871945 stoi:  0.9556786262602617


Evaluating: CMGAN_epoch_34_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3252646700271127 csig:  4.604573493235327 cbak:  3.86390146398421 covl:  4.058530817941532 ssnr:  10.551172291225523 stoi:  0.9562931148357899


Evaluating: CMGAN_epoch_35_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3396289348602295 csig:  4.594528648215738 cbak:  3.858498832101843 covl:  4.062786465334339 ssnr:  10.369126303988276 stoi:  0.9572508142131826


Evaluating: CMGAN_epoch_36_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.364280404541099 csig:  4.602041200373577 cbak:  3.8659756814484463 covl:  4.080457924789146 ssnr:  10.303218337538066 stoi:  0.9560160474729589


Evaluating: CMGAN_epoch_37_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3799363039072277 csig:  4.597688955532222 cbak:  3.8865442163250616 covl:  4.086972175772481 ssnr:  10.50302291679742 stoi:  0.9561133484276362


Evaluating: CMGAN_epoch_38_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3636920255364724 csig:  4.608115396897852 cbak:  3.8713290707748325 covl:  4.083971277902525 ssnr:  10.386500412685606 stoi:  0.9563992549703562


Evaluating: CMGAN_epoch_39_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3712307596669615 csig:  4.602270793678288 cbak:  3.8595637243495813 covl:  4.086264481682555 ssnr:  10.159439113868217 stoi:  0.9556658340054547


Evaluating: CMGAN_epoch_40_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.382205606519597 csig:  4.602728275853495 cbak:  3.86610104412643 covl:  4.091864510767536 ssnr:  10.172775844909681 stoi:  0.9559948230474006


Evaluating: CMGAN_epoch_4_0.072
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1192826081826848 csig:  4.519574190145644 cbak:  3.648742116332653 covl:  3.895404002787138 ssnr:  8.777113238467484 stoi:  0.945830700378351


Evaluating: CMGAN_epoch_41_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.350143952855786 csig:  4.591111840400675 cbak:  3.8440428069793007 covl:  4.063261420537226 ssnr:  10.072523593168905 stoi:  0.955935700415913


Evaluating: CMGAN_epoch_42_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.327705823246715 csig:  4.5697851464679555 cbak:  3.8436483196038917 covl:  4.042280848612132 ssnr:  10.211174241970722 stoi:  0.956609580308697


Evaluating: CMGAN_epoch_43_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3721687557917197 csig:  4.617506412045508 cbak:  3.873298556830839 covl:  4.095773961107954 ssnr:  10.354355039642767 stoi:  0.9564436025191101


Evaluating: CMGAN_epoch_44_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3450250101899637 csig:  4.601645093294548 cbak:  3.8655870797070357 covl:  4.070908756050226 ssnr:  10.43719097118243 stoi:  0.9569100245964146


Evaluating: CMGAN_epoch_45_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.385541352976873 csig:  4.618049960679488 cbak:  3.8912240729433143 covl:  4.099159981424591 ssnr:  10.51971707954418 stoi:  0.9566000510651131


Evaluating: CMGAN_epoch_46_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3674764204951164 csig:  4.610961794426738 cbak:  3.8936494293485318 covl:  4.08670799976254 ssnr:  10.694147210024695 stoi:  0.9564512881486975


Evaluating: CMGAN_epoch_47_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3402751841880742 csig:  4.614259157097337 cbak:  3.861947928510367 covl:  4.070519919051712 ssnr:  10.400587249011258 stoi:  0.9567475966623032


Evaluating: CMGAN_epoch_48_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3571354769965978 csig:  4.606698051690352 cbak:  3.86686620817106 covl:  4.080192676800233 ssnr:  10.357210751454733 stoi:  0.9565645375908263


Evaluating: CMGAN_epoch_49_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3678474612895726 csig:  4.608235032071043 cbak:  3.8820729492975494 covl:  4.085661976490966 ssnr:  10.518331425961122 stoi:  0.956920157373858


Evaluating: CMGAN_epoch_50_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.363176190448039 csig:  4.6071796004271395 cbak:  3.8644213456918965 covl:  4.08330055637582 ssnr:  10.279101091062682 stoi:  0.9570046678854043


Evaluating: CMGAN_epoch_5_0.068
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.166886494576352 csig:  4.568970381646399 cbak:  3.7103257871372644 covl:  3.944728688676203 ssnr:  9.397495385486145 stoi:  0.949614829281944


Evaluating: CMGAN_epoch_51_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.363943310183229 csig:  4.618718146183531 cbak:  3.877169335764022 covl:  4.089963683983759 ssnr:  10.464852576264406 stoi:  0.9570669435326259


Evaluating: CMGAN_epoch_52_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.360857170473025 csig:  4.610747783395688 cbak:  3.8689986323750176 covl:  4.082911034551955 ssnr:  10.374883091250622 stoi:  0.9567295234199077


Evaluating: CMGAN_epoch_53_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3801924457538477 csig:  4.626907737351116 cbak:  3.868990859507559 covl:  4.104384144454249 ssnr:  10.226259880041074 stoi:  0.9563548385221542


Evaluating: CMGAN_epoch_54_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.377771303491685 csig:  4.616232925850748 cbak:  3.8807180481544763 covl:  4.096443560907451 ssnr:  10.41829177371463 stoi:  0.9568608253454431


Evaluating: CMGAN_epoch_55_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3780082038884025 csig:  4.618596145356527 cbak:  3.8730429520710716 covl:  4.0993139588521865 ssnr:  10.29538391804231 stoi:  0.956745075431338


Evaluating: CMGAN_epoch_56_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.373133016587461 csig:  4.615045229298402 cbak:  3.881716613846107 covl:  4.092904403741002 ssnr:  10.474451607772856 stoi:  0.9562675714417196


Evaluating: CMGAN_epoch_57_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.373116134584529 csig:  4.6179691591138665 cbak:  3.8862767440112607 covl:  4.096057567850315 ssnr:  10.539166547525383 stoi:  0.9566592722905265


Evaluating: CMGAN_epoch_58_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3704766499475367 csig:  4.622738507483613 cbak:  3.876390491543077 covl:  4.096356842260722 ssnr:  10.40367215138637 stoi:  0.956517513400576


Evaluating: CMGAN_epoch_59_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3713372166006312 csig:  4.614676765497967 cbak:  3.8723205362648607 covl:  4.091919765264193 ssnr:  10.346063437574356 stoi:  0.956494925338691


Evaluating: CMGAN_epoch_6_0.069
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1522966410639217 csig:  4.542186799022999 cbak:  3.714513741511768 covl:  3.923281140694612 ssnr:  9.542926499766958 stoi:  0.9503392148775875


Evaluating: CMGAN_epoch_7_0.067
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1112744646164976 csig:  4.478121299018807 cbak:  3.6790401680081373 covl:  3.8643626035641203 ssnr:  9.324854721205723 stoi:  0.9514439128481973


Evaluating: CMGAN_epoch_8_0.065
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.184658623436122 csig:  4.486496009209448 cbak:  3.7248461035925717 covl:  3.908324317980055 ssnr:  9.501588282863707 stoi:  0.9515429912883631


Evaluating: CMGAN_epoch_9_0.064
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.167454900093449 csig:  4.494266138894467 cbak:  3.749590933270089 covl:  3.9032533389395265 ssnr:  9.96713342070935 stoi:  0.9521365905329952


Batch evaluation finished.

------------------------------------------------------------------------------------------------------------------------------
Starting batch evaluation...
Evaluating: CMGAN_epoch_0_0.216
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.686126108163769 csig:  4.125230654626634 cbak:  3.3696474673285928 covl:  3.4556935258369323 ssnr:  7.738939214919565 stoi:  0.9325983178431169


Evaluating: CMGAN_epoch_10_0.160
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.130480282225655 csig:  4.40549073521646 cbak:  3.7389385354445195 covl:  3.841491083273143 ssnr:  10.086187403427132 stoi:  0.9503648373979058


Evaluating: CMGAN_epoch_1_0.190
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.735343251124169 csig:  4.2046805515723324 cbak:  3.4836950824383797 covl:  3.521811298303699 ssnr:  9.107294102168286 stoi:  0.9383883228129439


Evaluating: CMGAN_epoch_11_0.157
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1602314895796546 csig:  4.350969415976399 cbak:  3.774922848742115 covl:  3.8291121152712324 ssnr:  10.42573754459266 stoi:  0.950436691575113


Evaluating: CMGAN_epoch_12_0.158
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1866806767229896 csig:  4.432169730785091 cbak:  3.781166856548141 covl:  3.886630544604803 ssnr:  10.34014214630667 stoi:  0.9522364167778284


Evaluating: CMGAN_epoch_13_0.151
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.212393012729663 csig:  4.4200527176309246 cbak:  3.822714430106561 covl:  3.896578887990225 ssnr:  10.767959569940977 stoi:  0.9525028110506908


Evaluating: CMGAN_epoch_14_0.159
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2126483214132993 csig:  4.423117665803298 cbak:  3.770808945146598 covl:  3.8992188337903926 ssnr:  9.985077742647226 stoi:  0.9522892978906872


Evaluating: CMGAN_epoch_15_0.151
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.207752240369621 csig:  4.4439997151636765 cbak:  3.820805071557872 covl:  3.9089516049588657 ssnr:  10.775037425297121 stoi:  0.9528038514645315


Evaluating: CMGAN_epoch_16_0.153
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1911522994921047 csig:  4.375702260855589 cbak:  3.7992023811621034 covl:  3.858732600126507 ssnr:  10.567709293440897 stoi:  0.9535133973543072


Evaluating: CMGAN_epoch_17_0.154
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2009273599652412 csig:  4.403583044896863 cbak:  3.7972459896810546 covl:  3.8809226828939436 ssnr:  10.465410159850377 stoi:  0.9524003991779931


Evaluating: CMGAN_epoch_18_0.154
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.168196257601664 csig:  4.453088690604508 cbak:  3.7929663519005343 covl:  3.889771440225038 ssnr:  10.657776947280277 stoi:  0.9539733781864472


Evaluating: CMGAN_epoch_19_0.154
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.220698956436324 csig:  4.435027804862361 cbak:  3.806305250671821 covl:  3.9101022539327226 ssnr:  10.458143083412544 stoi:  0.9529168200555869


Evaluating: CMGAN_epoch_20_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.196632768922639 csig:  4.417921424683824 cbak:  3.82546002445376 covl:  3.8857846582846656 ssnr:  10.918769343276265 stoi:  0.9543576730461969


Evaluating: CMGAN_epoch_2_0.182
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.945274285321097 csig:  4.301614622251528 cbak:  3.6004261089657192 covl:  3.684003580755757 ssnr:  9.358387709855643 stoi:  0.9400746760320573


Evaluating: CMGAN_epoch_21_0.151
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.18325168444115 csig:  4.413113668155335 cbak:  3.8032501189451904 covl:  3.8724475654872914 ssnr:  10.69062238262368 stoi:  0.9536829489836066


Evaluating: CMGAN_epoch_22_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2530206702287914 csig:  4.473661564709652 cbak:  3.8417208543503447 covl:  3.947838253293634 ssnr:  10.756529369211542 stoi:  0.9537645812562677


Evaluating: CMGAN_epoch_23_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.230137623774195 csig:  4.452969768471492 cbak:  3.8318924934842897 covl:  3.9234774309655838 ssnr:  10.783863232119183 stoi:  0.9536248796898291


Evaluating: CMGAN_epoch_24_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2078063770115954 csig:  4.449165477970964 cbak:  3.8296613175024095 covl:  3.909088667675785 ssnr:  10.917256829668029 stoi:  0.9542905391506215


Evaluating: CMGAN_epoch_25_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2664123265777976 csig:  4.474613701981754 cbak:  3.8607443817750005 covl:  3.9534641572158673 ssnr:  10.961255420020661 stoi:  0.9549213618954802


Evaluating: CMGAN_epoch_26_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.23925296253371 csig:  4.442645304324261 cbak:  3.845612888380743 covl:  3.9223827630925605 ssnr:  10.921656662453534 stoi:  0.955069976968738


Evaluating: CMGAN_epoch_27_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2821055566801607 csig:  4.496705283150826 cbak:  3.863434562523432 covl:  3.9780704880950686 ssnr:  10.873950193479356 stoi:  0.9547241818432092


Evaluating: CMGAN_epoch_28_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2806552618163303 csig:  4.489530852684885 cbak:  3.8658243524256823 covl:  3.9730484243367776 ssnr:  10.921435847416154 stoi:  0.9537636989906836


Evaluating: CMGAN_epoch_29_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2728123949858747 csig:  4.484210274077115 cbak:  3.8537488053577778 covl:  3.9633000705188732 ssnr:  10.812067536075132 stoi:  0.9554744467162034


Evaluating: CMGAN_epoch_30_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.287112503375822 csig:  4.500966259587073 cbak:  3.8605980374483853 covl:  3.9809528427209804 ssnr:  10.807475322713028 stoi:  0.9543927233223691


Evaluating: CMGAN_epoch_3_0.182
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.905241653178502 csig:  4.223343014316474 cbak:  3.5748761566647205 covl:  3.618354611276232 ssnr:  9.266088709191788 stoi:  0.9451677965223273


Evaluating: CMGAN_epoch_31_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2763565359185045 csig:  4.460526083704837 cbak:  3.862936569886643 covl:  3.9541124776760785 ssnr:  10.909273991838942 stoi:  0.954286812505948


Evaluating: CMGAN_epoch_32_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2766668459454786 csig:  4.484226826634296 cbak:  3.860224564182085 covl:  3.965559477288312 ssnr:  10.864669011848195 stoi:  0.954709257242457


Evaluating: CMGAN_epoch_33_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1808999135945606 csig:  4.459064259412002 cbak:  3.8043827549792857 covl:  3.9001051953069963 ssnr:  10.711209895163728 stoi:  0.9552939698898667


Evaluating: CMGAN_epoch_34_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2530339678514353 csig:  4.472858489406324 cbak:  3.856592136035164 covl:  3.9480132623629474 ssnr:  10.998959955977941 stoi:  0.9548115544948628


Evaluating: CMGAN_epoch_35_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2600925062755937 csig:  4.466910307617468 cbak:  3.845515598250408 covl:  3.9489670978522176 ssnr:  10.774577266863297 stoi:  0.9556108855930779


Evaluating: CMGAN_epoch_36_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2597437182676443 csig:  4.465118656618184 cbak:  3.855890644489537 covl:  3.9443700594654776 ssnr:  10.930507883341336 stoi:  0.9554193127379158


Evaluating: CMGAN_epoch_37_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3078862080006926 csig:  4.506641844900049 cbak:  3.879238428456264 covl:  3.994954355287046 ssnr:  10.933008810430602 stoi:  0.9555684730350076


Evaluating: CMGAN_epoch_38_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3156479414805626 csig:  4.4854482023738935 cbak:  3.8682764182582985 covl:  3.9867771165040056 ssnr:  10.72600826517544 stoi:  0.9554768107334777


Evaluating: CMGAN_epoch_39_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.270032971229368 csig:  4.4842875180243045 cbak:  3.856997158723485 covl:  3.9623558646513235 ssnr:  10.873682114416322 stoi:  0.9551273826396924


Evaluating: CMGAN_epoch_40_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.306520645479554 csig:  4.492326014845027 cbak:  3.879665228081723 covl:  3.9878727001738135 ssnr:  10.948918750338624 stoi:  0.9551253971266949


Evaluating: CMGAN_epoch_4_0.176
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.9554696744217455 csig:  4.299142400168658 cbak:  3.6129827951137945 covl:  3.686676604064632 ssnr:  9.45033505206274 stoi:  0.9469496410850484


Evaluating: CMGAN_epoch_41_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2904396919370855 csig:  4.497549040323488 cbak:  3.864218510426267 covl:  3.9784792273681244 ssnr:  10.832661782873847 stoi:  0.9546251110824402


Evaluating: CMGAN_epoch_42_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2831281024275474 csig:  4.488021388962895 cbak:  3.854579188339699 covl:  3.972657861519142 ssnr:  10.741633647736991 stoi:  0.9548407678543606


Evaluating: CMGAN_epoch_43_0.144
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.307689270782239 csig:  4.510433509175034 cbak:  3.8851610364485487 covl:  3.996828008386467 ssnr:  11.021475577185587 stoi:  0.9558960490473036


Evaluating: CMGAN_epoch_44_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2929984710170226 csig:  4.468683955429008 cbak:  3.8736147956705036 covl:  3.9660072571681964 ssnr:  10.957290270828128 stoi:  0.9561594854694446


Evaluating: CMGAN_epoch_45_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2963254771475654 csig:  4.50090096926773 cbak:  3.8588781712465265 covl:  3.985706707495742 ssnr:  10.716398037879683 stoi:  0.9555231899431968


Evaluating: CMGAN_epoch_46_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2895523091253724 csig:  4.482818457380486 cbak:  3.874594688562149 covl:  3.9731799175066724 ssnr:  10.994170392088236 stoi:  0.9553089235489265


Evaluating: CMGAN_epoch_47_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.255705585902177 csig:  4.448492006679087 cbak:  3.8503207978164204 covl:  3.934064613567303 ssnr:  10.870808447065803 stoi:  0.955598942544368


Evaluating: CMGAN_epoch_48_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2658781608910235 csig:  4.48853421226919 cbak:  3.85540999414649 covl:  3.962200268511365 ssnr:  10.877542684164016 stoi:  0.9557908128746332


Evaluating: CMGAN_epoch_49_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2928502524940715 csig:  4.485308866805649 cbak:  3.8704492150828473 covl:  3.9756433097044774 ssnr:  10.905377746165962 stoi:  0.9555679974418616


Evaluating: CMGAN_epoch_50_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2958921380702733 csig:  4.513442028363513 cbak:  3.864787151891898 covl:  3.9923829537582125 ssnr:  10.799466473631439 stoi:  0.955057860705632


Evaluating: CMGAN_epoch_5_0.175
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.026360138527398 csig:  4.41579506730213 cbak:  3.6482609100172074 covl:  3.797098981012369 ssnr:  9.48457105769411 stoi:  0.9430324208378391


Evaluating: CMGAN_epoch_51_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3086486871092067 csig:  4.5037231687124 cbak:  3.877568884659244 covl:  3.992772432317295 ssnr:  10.897291721019913 stoi:  0.9553673665233482


Evaluating: CMGAN_epoch_52_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3109389465410732 csig:  4.47842864050253 cbak:  3.874733378817324 covl:  3.9803625417711306 ssnr:  10.842614744385259 stoi:  0.9555982530886693


Evaluating: CMGAN_epoch_53_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.267471546108283 csig:  4.491007207797577 cbak:  3.8551524335324125 covl:  3.964804476875363 ssnr:  10.864749291079496 stoi:  0.9557386469642309


Evaluating: CMGAN_epoch_54_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2686376133300725 csig:  4.4902951815749965 cbak:  3.8445634884427236 covl:  3.965506833854724 ssnr:  10.692712164149444 stoi:  0.9558685199435083


Evaluating: CMGAN_epoch_55_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.284702753557742 csig:  4.479804600582183 cbak:  3.8674308187443303 covl:  3.969120941021594 ssnr:  10.92052763090689 stoi:  0.9557365738617138


Evaluating: CMGAN_epoch_56_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3120542025392496 csig:  4.491686078220538 cbak:  3.8709486474487864 covl:  3.9904702928860676 ssnr:  10.788886286981477 stoi:  0.9549281846375459


Evaluating: CMGAN_epoch_57_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2982637760708635 csig:  4.4875358569880985 cbak:  3.867041496987188 covl:  3.979140202382084 ssnr:  10.824651164847937 stoi:  0.9556853104427013


Evaluating: CMGAN_epoch_58_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2918918365703047 csig:  4.5067133735800855 cbak:  3.8681766331450187 covl:  3.9864273072625425 ssnr:  10.879667023821492 stoi:  0.955261456419105


Evaluating: CMGAN_epoch_59_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2781412458246195 csig:  4.475542082543937 cbak:  3.857955177797368 covl:  3.9623375705958543 ssnr:  10.82219743168839 stoi:  0.9558953429418018


Evaluating: CMGAN_epoch_6_0.167
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0758440594360668 csig:  4.358370129051111 cbak:  3.705115430267617 covl:  3.7870519451229194 ssnr:  9.98316938180397 stoi:  0.9474551334189777


Evaluating: CMGAN_epoch_7_0.163
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0906898918950443 csig:  4.374080370772169 cbak:  3.726037389395371 covl:  3.796302082230903 ssnr:  10.20675544096884 stoi:  0.948633202085518


Evaluating: CMGAN_epoch_8_0.161
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.062210023113825 csig:  4.35841619999348 cbak:  3.720419238868876 covl:  3.7773935358086033 ssnr:  10.30377471296788 stoi:  0.9499233576435604


Evaluating: CMGAN_epoch_9_0.156
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.144439083279915 csig:  4.397826025241021 cbak:  3.7729100542698424 covl:  3.8437791057929607 ssnr:  10.503727365643488 stoi:  0.9495890815799515


Batch evaluation finished.
