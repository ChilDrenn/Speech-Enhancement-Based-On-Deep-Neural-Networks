Starting training:
with SE:
Namespace(batch_size=4, cut_len=32000, data_dir='/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/DEMAND_16KHz', decay_epoch=12, epochs=60, init_lr=0.0005, log_interval=500, loss_weights=[0.3, 0.7, 1.0, 0.01], save_model_dir='./saved_models_log/saved_models_20250721_VoiceDEMAND_16khz')
['NVIDIA A100-SXM4-80GB']
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
TSCNet                                             [1, 1, 321, 201]          --
├─DenseEncoder: 1-1                                [1, 64, 321, 101]         --
│    └─Sequential: 2-1                             [1, 64, 321, 201]         --
│    │    └─Conv2d: 3-1                            [1, 64, 321, 201]         256
│    │    └─InstanceNorm2d: 3-2                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-3                             [1, 64, 321, 201]         64
│    └─SEBlock: 2-2                                [1, 64, 321, 201]         --
│    │    └─Sequential: 3-4                        [1, 64]                   580
│    └─DilatedDenseNet: 2-3                        [1, 64, 321, 201]         --
│    │    └─ConstantPad2d: 3-5                     [1, 64, 322, 203]         --
│    │    └─Conv2d: 3-6                            [1, 64, 321, 201]         24,640
│    │    └─InstanceNorm2d: 3-7                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-8                             [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-9                     [1, 128, 323, 203]        --
│    │    └─Conv2d: 3-10                           [1, 64, 321, 201]         49,216
│    │    └─InstanceNorm2d: 3-11                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-12                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-13                    [1, 192, 325, 203]        --
│    │    └─Conv2d: 3-14                           [1, 64, 321, 201]         73,792
│    │    └─InstanceNorm2d: 3-15                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-16                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-17                    [1, 256, 329, 203]        --
│    │    └─Conv2d: 3-18                           [1, 64, 321, 201]         98,368
│    │    └─InstanceNorm2d: 3-19                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-20                            [1, 64, 321, 201]         64
│    └─Sequential: 2-4                             [1, 64, 321, 101]         --
│    │    └─Conv2d: 3-21                           [1, 64, 321, 101]         12,352
│    │    └─InstanceNorm2d: 3-22                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-23                            [1, 64, 321, 101]         64
├─TSCB: 1-2                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-5                         [101, 321, 64]            --
│    │    └─Scale: 3-24                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-25                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-26              [101, 321, 64]            29,376
│    │    └─Scale: 3-27                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-28                        [101, 321, 64]            128
│    └─ConformerBlock: 2-6                         [321, 101, 64]            --
│    │    └─Scale: 3-29                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-30                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-31              [321, 101, 64]            29,376
│    │    └─Scale: 3-32                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-33                        [321, 101, 64]            128
├─TSCB: 1-3                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-7                         [101, 321, 64]            --
│    │    └─Scale: 3-34                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-35                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-36              [101, 321, 64]            29,376
│    │    └─Scale: 3-37                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-38                        [101, 321, 64]            128
│    └─ConformerBlock: 2-8                         [321, 101, 64]            --
│    │    └─Scale: 3-39                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-40                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-41              [321, 101, 64]            29,376
│    │    └─Scale: 3-42                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-43                        [321, 101, 64]            128
├─TSCB: 1-4                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-9                         [101, 321, 64]            --
│    │    └─Scale: 3-44                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-45                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-46              [101, 321, 64]            29,376
│    │    └─Scale: 3-47                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-48                        [101, 321, 64]            128
│    └─ConformerBlock: 2-10                        [321, 101, 64]            --
│    │    └─Scale: 3-49                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-50                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-51              [321, 101, 64]            29,376
│    │    └─Scale: 3-52                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-53                        [321, 101, 64]            128
├─TSCB: 1-5                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-11                        [101, 321, 64]            --
│    │    └─Scale: 3-54                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-55                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-56              [101, 321, 64]            29,376
│    │    └─Scale: 3-57                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-58                        [101, 321, 64]            128
│    └─ConformerBlock: 2-12                        [321, 101, 64]            --
│    │    └─Scale: 3-59                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-60                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-61              [321, 101, 64]            29,376
│    │    └─Scale: 3-62                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-63                        [321, 101, 64]            128
├─MaskDecoder: 1-6                                 [1, 1, 321, 201]          --
│    └─DilatedDenseNet: 2-13                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-64                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-65                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-66                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-67                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-68                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-69                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-70                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-71                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-72                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-73                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-74                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-75                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-76                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-77                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-78                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-79                            [1, 64, 321, 101]         64
│    └─SEBlock: 2-14                               [1, 64, 321, 101]         --
│    │    └─Sequential: 3-80                       [1, 64]                   580
│    └─SPConvTranspose2d: 2-15                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-81                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-82                           [1, 128, 321, 101]        24,704
│    └─Conv2d: 2-16                                [1, 1, 321, 201]          129
│    └─InstanceNorm2d: 2-17                        [1, 1, 321, 201]          2
│    └─PReLU: 2-18                                 [1, 1, 321, 201]          1
│    └─Conv2d: 2-19                                [1, 1, 321, 201]          2
│    └─PReLU: 2-20                                 [1, 201, 321]             201
├─ComplexDecoder: 1-7                              [1, 2, 321, 201]          --
│    └─DilatedDenseNet: 2-21                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-83                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-84                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-85                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-86                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-87                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-88                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-89                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-90                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-91                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-92                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-93                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-94                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-95                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-96                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-97                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-98                            [1, 64, 321, 101]         64
│    └─SEBlock: 2-22                               [1, 64, 321, 101]         --
│    │    └─Sequential: 3-99                       [1, 64]                   580
│    └─SPConvTranspose2d: 2-23                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-100                   [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-101                          [1, 128, 321, 101]        24,704
│    └─InstanceNorm2d: 2-24                        [1, 64, 321, 202]         128
│    └─PReLU: 2-25                                 [1, 64, 321, 202]         64
│    └─Conv2d: 2-26                                [1, 2, 321, 201]          258
====================================================================================================
Total params: 1,836,573
Trainable params: 1,836,573
Non-trainable params: 0
Total mult-adds (G): 41.56
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 4856.40
Params size (MB): 7.35
Estimated Total Size (MB): 4864.26
====================================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Discriminator                            [1, 1]                    --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Conv2d: 2-1                       [1, 16, 100, 160]         512
│    └─InstanceNorm2d: 2-2               [1, 16, 100, 160]         32
│    └─PReLU: 2-3                        [1, 16, 100, 160]         16
│    └─Conv2d: 2-4                       [1, 32, 50, 80]           8,192
│    └─InstanceNorm2d: 2-5               [1, 32, 50, 80]           64
│    └─PReLU: 2-6                        [1, 32, 50, 80]           32
│    └─Conv2d: 2-7                       [1, 64, 25, 40]           32,768
│    └─InstanceNorm2d: 2-8               [1, 64, 25, 40]           128
│    └─PReLU: 2-9                        [1, 64, 25, 40]           64
│    └─Conv2d: 2-10                      [1, 128, 12, 20]          131,072
│    └─InstanceNorm2d: 2-11              [1, 128, 12, 20]          256
│    └─PReLU: 2-12                       [1, 128, 12, 20]          128
│    └─AdaptiveMaxPool2d: 2-13           [1, 128, 1, 1]            --
│    └─Flatten: 2-14                     [1, 128]                  --
│    └─Linear: 2-15                      [1, 64]                   8,256
│    └─Dropout: 2-16                     [1, 64]                   --
│    └─PReLU: 2-17                       [1, 64]                   64
│    └─Linear: 2-18                      [1, 1]                    65
│    └─LearnableSigmoid: 2-19            [1, 1]                    1
==========================================================================================
Total params: 181,650
Trainable params: 181,650
Non-trainable params: 0
Total mult-adds (M): 19.67
==========================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 11.49
Params size (MB): 0.73
Estimated Total Size (MB): 12.73
==========================================================================================
/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/CMGAN_src/data/dataloader.py:52: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")         # in linux
INFO:root:Epoch 0, Step 500, loss: 0.36480599641799927, disc_loss: 0.001760278013534844
INFO:root:Epoch 0, Step 1000, loss: 0.35485726594924927, disc_loss: 0.003678449196740985
INFO:root:Epoch 0, Step 1500, loss: 0.29089054465293884, disc_loss: 0.05472727492451668
INFO:root:Epoch 0, Step 2000, loss: 0.2932116687297821, disc_loss: 0.003507340094074607
INFO:root:Epoch 0, Step 2500, loss: 0.2719320058822632, disc_loss: 0.0038085307460278273
INFO:root:Generator loss: 0.18679497622459837, Discriminator loss: 0.007221488434667654
INFO:root:Epoch 1, Step 500, loss: 0.2794743776321411, disc_loss: 0.004950979724526405
INFO:root:Epoch 1, Step 1000, loss: 0.3109741806983948, disc_loss: 0.022743405774235725
INFO:root:Epoch 1, Step 1500, loss: 0.24369478225708008, disc_loss: 0.04267895594239235
INFO:root:Epoch 1, Step 2000, loss: 0.2549527883529663, disc_loss: 0.001964043825864792
INFO:root:Epoch 1, Step 2500, loss: 0.22039790451526642, disc_loss: 0.00651243282482028
INFO:root:Generator loss: 0.18392038175347938, Discriminator loss: 0.009390756560040828
INFO:root:Epoch 2, Step 500, loss: 0.22167466580867767, disc_loss: 0.001373305101878941
INFO:root:Epoch 2, Step 1000, loss: 0.25448909401893616, disc_loss: 0.004963903222233057
INFO:root:Epoch 2, Step 1500, loss: 0.2444244772195816, disc_loss: 0.012272678315639496
INFO:root:Epoch 2, Step 2000, loss: 0.2198760211467743, disc_loss: 0.0018612148705869913
INFO:root:Epoch 2, Step 2500, loss: 0.18134574592113495, disc_loss: 0.0013157560024410486
INFO:root:Generator loss: 0.17828720193175437, Discriminator loss: 0.012350340676578711
INFO:root:Epoch 3, Step 500, loss: 0.23401115834712982, disc_loss: 0.0014253397239372134
INFO:root:Epoch 3, Step 1000, loss: 0.3327789008617401, disc_loss: 0.0049951570108532906
INFO:root:Epoch 3, Step 1500, loss: 0.21422041952610016, disc_loss: 0.0014334132429212332
INFO:root:Epoch 3, Step 2000, loss: 0.16824206709861755, disc_loss: 0.0009554809075780213
INFO:root:Epoch 3, Step 2500, loss: 0.21368782222270966, disc_loss: 0.005683849565684795
INFO:root:Generator loss: 0.18566736021956193, Discriminator loss: 0.01034102820253307
INFO:root:Epoch 4, Step 500, loss: 0.27706611156463623, disc_loss: 0.002519110683351755
INFO:root:Epoch 4, Step 1000, loss: 0.18934036791324615, disc_loss: 0.0019503544317558408
INFO:root:Epoch 4, Step 1500, loss: 0.19062291085720062, disc_loss: 0.016692250967025757
INFO:root:Epoch 4, Step 2000, loss: 0.329769104719162, disc_loss: 0.0018486845074221492
INFO:root:Epoch 4, Step 2500, loss: 0.25799551606178284, disc_loss: 0.0016605597920715809
INFO:root:Generator loss: 0.1671406844431914, Discriminator loss: 0.007089367007935031
INFO:root:Epoch 5, Step 500, loss: 0.33361396193504333, disc_loss: 0.001193587901070714
INFO:root:Epoch 5, Step 1000, loss: 0.25727665424346924, disc_loss: 0.008751902729272842
INFO:root:Epoch 5, Step 1500, loss: 0.2703855633735657, disc_loss: 0.003732828889042139
INFO:root:Epoch 5, Step 2000, loss: 0.19917181134223938, disc_loss: 0.000551569857634604
INFO:root:Epoch 5, Step 2500, loss: 0.21598514914512634, disc_loss: 0.0020248007494956255
INFO:root:Generator loss: 0.1643337788223063, Discriminator loss: 0.00811012703456319
INFO:root:Epoch 6, Step 500, loss: 0.25562161207199097, disc_loss: 0.004134666174650192
INFO:root:Epoch 6, Step 1000, loss: 0.17379061877727509, disc_loss: 0.00861071702092886
INFO:root:Epoch 6, Step 1500, loss: 0.3115112781524658, disc_loss: 0.007624381687492132
INFO:root:Epoch 6, Step 2000, loss: 0.21556279063224792, disc_loss: 0.0005140580469742417
INFO:root:Epoch 6, Step 2500, loss: 0.18732236325740814, disc_loss: 0.0021857707761228085
INFO:root:Generator loss: 0.16305916340461055, Discriminator loss: 0.00836105613296205
INFO:root:Epoch 7, Step 500, loss: 0.2683200240135193, disc_loss: 0.023405712097883224
INFO:root:Epoch 7, Step 1000, loss: 0.2969144582748413, disc_loss: 0.0034813799429684877
INFO:root:Epoch 7, Step 1500, loss: 0.197116419672966, disc_loss: 0.0013747442280873656
INFO:root:Epoch 7, Step 2000, loss: 0.19730840623378754, disc_loss: 0.007411382161080837
INFO:root:Epoch 7, Step 2500, loss: 0.25925421714782715, disc_loss: 0.0017363853985443711
INFO:root:Generator loss: 0.17493495399367462, Discriminator loss: 0.005541272782333516
INFO:root:Epoch 8, Step 500, loss: 0.1959831267595291, disc_loss: 0.0018604514189064503
INFO:root:Epoch 8, Step 1000, loss: 0.2200431376695633, disc_loss: 0.0011660264572128654
INFO:root:Epoch 8, Step 1500, loss: 0.19641543924808502, disc_loss: 0.0024598247837275267
INFO:root:Epoch 8, Step 2000, loss: 0.1793002188205719, disc_loss: 0.0013056639581918716
INFO:root:Epoch 8, Step 2500, loss: 0.20222441852092743, disc_loss: 0.001957370201125741
INFO:root:Generator loss: 0.1615281031620734, Discriminator loss: 0.013269504423396496
INFO:root:Epoch 9, Step 500, loss: 0.20833511650562286, disc_loss: 0.0016172475880011916
INFO:root:Epoch 9, Step 1000, loss: 0.2551782429218292, disc_loss: 0.0009241887019015849
INFO:root:Epoch 9, Step 1500, loss: 0.304896742105484, disc_loss: 0.0007825029315426946
INFO:root:Epoch 9, Step 2000, loss: 0.2264268845319748, disc_loss: 0.0027554496191442013
INFO:root:Epoch 9, Step 2500, loss: 0.2855212092399597, disc_loss: 0.037196047604084015
INFO:root:Generator loss: 0.1597441659824362, Discriminator loss: 0.012757137245289502
INFO:root:Epoch 10, Step 500, loss: 0.198383629322052, disc_loss: 0.0028310762718319893
INFO:root:Epoch 10, Step 1000, loss: 0.28389260172843933, disc_loss: 0.0015517835272476077
INFO:root:Epoch 10, Step 1500, loss: 0.1781134009361267, disc_loss: 0.0017826355760917068
INFO:root:Epoch 10, Step 2000, loss: 0.23991739749908447, disc_loss: 0.0006557380547747016
INFO:root:Epoch 10, Step 2500, loss: 0.15599535405635834, disc_loss: 0.00199155998416245
INFO:root:Generator loss: 0.15680221876907116, Discriminator loss: 0.004966757467097955
INFO:root:Epoch 11, Step 500, loss: 0.2219574898481369, disc_loss: 0.0017866587731987238
INFO:root:Epoch 11, Step 1000, loss: 0.1816113442182541, disc_loss: 0.0014414668548852205
INFO:root:Epoch 11, Step 1500, loss: 0.2527447044849396, disc_loss: 0.0004173631314188242
INFO:root:Epoch 11, Step 2000, loss: 0.21227417886257172, disc_loss: 0.0038130604662001133
INFO:root:Epoch 11, Step 2500, loss: 0.2001761794090271, disc_loss: 0.0016544477548450232
INFO:root:Generator loss: 0.16059119337536756, Discriminator loss: 0.0073469994140837516
INFO:root:Epoch 12, Step 500, loss: 0.18762817978858948, disc_loss: 0.0033418929670006037
INFO:root:Epoch 12, Step 1000, loss: 0.14638687670230865, disc_loss: 0.00380630767904222
INFO:root:Epoch 12, Step 1500, loss: 0.22794893383979797, disc_loss: 0.0010250532068312168
INFO:root:Epoch 12, Step 2000, loss: 0.18568283319473267, disc_loss: 0.001179902465082705
INFO:root:Epoch 12, Step 2500, loss: 0.23750512301921844, disc_loss: 0.0005597637500613928
INFO:root:Generator loss: 0.15523701114127936, Discriminator loss: 0.0061180409798042585
INFO:root:Epoch 13, Step 500, loss: 0.20309385657310486, disc_loss: 0.005625090561807156
INFO:root:Epoch 13, Step 1000, loss: 0.1937587410211563, disc_loss: 0.00024145626230165362
INFO:root:Epoch 13, Step 1500, loss: 0.1666097193956375, disc_loss: 0.0015008831396698952
INFO:root:Epoch 13, Step 2000, loss: 0.20103779435157776, disc_loss: 0.000725846563000232
INFO:root:Epoch 13, Step 2500, loss: 0.2058214247226715, disc_loss: 0.000767046120017767
INFO:root:Generator loss: 0.15320818976146502, Discriminator loss: 0.008520133065828913
INFO:root:Epoch 14, Step 500, loss: 0.24109384417533875, disc_loss: 0.002565499860793352
INFO:root:Epoch 14, Step 1000, loss: 0.22682657837867737, disc_loss: 0.00035065141855739057
INFO:root:Epoch 14, Step 1500, loss: 0.30196064710617065, disc_loss: 0.003997432999312878
INFO:root:Epoch 14, Step 2000, loss: 0.18948332965373993, disc_loss: 0.0008358086342923343
INFO:root:Epoch 14, Step 2500, loss: 0.20574650168418884, disc_loss: 0.000703575205989182
INFO:root:Generator loss: 0.16215317551661462, Discriminator loss: 0.009919992304329073
INFO:root:Epoch 15, Step 500, loss: 0.16634121537208557, disc_loss: 0.0012139835162088275
INFO:root:Epoch 15, Step 1000, loss: 0.25449293851852417, disc_loss: 0.0012938551371917129
INFO:root:Epoch 15, Step 1500, loss: 0.19354644417762756, disc_loss: 0.0009706577402539551
INFO:root:Epoch 15, Step 2000, loss: 0.19472834467887878, disc_loss: 0.0009827861795201898
INFO:root:Epoch 15, Step 2500, loss: 0.16095313429832458, disc_loss: 0.0005458200466819108
INFO:root:Generator loss: 0.15272823240137795, Discriminator loss: 0.007679090060476491
INFO:root:Epoch 16, Step 500, loss: 0.11408261954784393, disc_loss: 0.0012070073280483484
INFO:root:Epoch 16, Step 1000, loss: 0.18390831351280212, disc_loss: 0.0023983519058674574
INFO:root:Epoch 16, Step 1500, loss: 0.15451496839523315, disc_loss: 0.0016917915781959891
INFO:root:Epoch 16, Step 2000, loss: 0.15049387514591217, disc_loss: 0.0024657370522618294
INFO:root:Epoch 16, Step 2500, loss: 0.20162811875343323, disc_loss: 0.004243406467139721
INFO:root:Generator loss: 0.15225540036426008, Discriminator loss: 0.007752607234084562
INFO:root:Epoch 17, Step 500, loss: 0.17720742523670197, disc_loss: 0.005024250131100416
INFO:root:Epoch 17, Step 1000, loss: 0.22022788226604462, disc_loss: 0.000941142498049885
INFO:root:Epoch 17, Step 1500, loss: 0.19466492533683777, disc_loss: 0.0035405990201979876
INFO:root:Epoch 17, Step 2000, loss: 0.15192696452140808, disc_loss: 0.003180543426424265
INFO:root:Epoch 17, Step 2500, loss: 0.24896502494812012, disc_loss: 0.0010588975856080651
INFO:root:Generator loss: 0.15071149231884087, Discriminator loss: 0.005315596123941715
INFO:root:Epoch 18, Step 500, loss: 0.23203234374523163, disc_loss: 0.0020688744261860847
INFO:root:Epoch 18, Step 1000, loss: 0.19119496643543243, disc_loss: 0.007285416591912508
INFO:root:Epoch 18, Step 1500, loss: 0.22236694395542145, disc_loss: 0.002581641310825944
INFO:root:Epoch 18, Step 2000, loss: 0.18577024340629578, disc_loss: 0.0016505086096003652
INFO:root:Epoch 18, Step 2500, loss: 0.26288992166519165, disc_loss: 0.03600970655679703
INFO:root:Generator loss: 0.16159808422321253, Discriminator loss: 0.0068359322439683085
INFO:root:Epoch 19, Step 500, loss: 0.17322823405265808, disc_loss: 0.001715491758659482
INFO:root:Epoch 19, Step 1000, loss: 0.22008861601352692, disc_loss: 0.0011854683980345726
INFO:root:Epoch 19, Step 1500, loss: 0.15649275481700897, disc_loss: 0.0019927306566387415
INFO:root:Epoch 19, Step 2000, loss: 0.16703860461711884, disc_loss: 0.07411554455757141
INFO:root:Epoch 19, Step 2500, loss: 0.16331541538238525, disc_loss: 0.0014894165797159076
INFO:root:Generator loss: 0.1491977561590741, Discriminator loss: 0.007286288615644489
INFO:root:Epoch 20, Step 500, loss: 0.23766133189201355, disc_loss: 0.0003136427258141339
INFO:root:Epoch 20, Step 1000, loss: 0.11271552741527557, disc_loss: 0.00025659753009676933
INFO:root:Epoch 20, Step 1500, loss: 0.2864075005054474, disc_loss: 0.0029742862097918987
INFO:root:Epoch 20, Step 2000, loss: 0.1928308606147766, disc_loss: 0.004495308268815279
INFO:root:Epoch 20, Step 2500, loss: 0.18327738344669342, disc_loss: 0.0011025543790310621
INFO:root:Generator loss: 0.1533083773570732, Discriminator loss: 0.008069595135875539
INFO:root:Epoch 21, Step 500, loss: 0.22383534908294678, disc_loss: 0.005019253585487604
INFO:root:Epoch 21, Step 1000, loss: 0.18798354268074036, disc_loss: 0.0014674710109829903
INFO:root:Epoch 21, Step 1500, loss: 0.19858214259147644, disc_loss: 0.00519440695643425
INFO:root:Epoch 21, Step 2000, loss: 0.18643203377723694, disc_loss: 0.0015191958518698812
INFO:root:Epoch 21, Step 2500, loss: 0.17351305484771729, disc_loss: 0.0034913949202746153
INFO:root:Generator loss: 0.14863025436846955, Discriminator loss: 0.007860267781598823
INFO:root:Epoch 22, Step 500, loss: 0.20171977579593658, disc_loss: 0.0020552300848066807
INFO:root:Epoch 22, Step 1000, loss: 0.18104156851768494, disc_loss: 0.0023338927421718836
INFO:root:Epoch 22, Step 1500, loss: 0.23363003134727478, disc_loss: 0.0021507572382688522
INFO:root:Epoch 22, Step 2000, loss: 0.3012998700141907, disc_loss: 0.00028421368915587664
INFO:root:Epoch 22, Step 2500, loss: 0.20520006120204926, disc_loss: 0.0003091419057454914
INFO:root:Generator loss: 0.1503088440999244, Discriminator loss: 0.006258702717848756
INFO:root:Epoch 23, Step 500, loss: 0.2475624680519104, disc_loss: 0.0021250920835882425
INFO:root:Epoch 23, Step 1000, loss: 0.2688988745212555, disc_loss: 0.0014021776150912046
INFO:root:Epoch 23, Step 1500, loss: 0.22256457805633545, disc_loss: 0.0038680932484567165
INFO:root:Epoch 23, Step 2000, loss: 0.12261305004358292, disc_loss: 0.004177856259047985
INFO:root:Epoch 23, Step 2500, loss: 0.24165964126586914, disc_loss: 0.0006199416820891201
INFO:root:Generator loss: 0.14991162565437335, Discriminator loss: 0.005414759695659351
INFO:root:Epoch 24, Step 500, loss: 0.1803942620754242, disc_loss: 0.0013859615428373218
INFO:root:Epoch 24, Step 1000, loss: 0.30799245834350586, disc_loss: 0.0010631324257701635
INFO:root:Epoch 24, Step 1500, loss: 0.21982599794864655, disc_loss: 0.09282123297452927
INFO:root:Epoch 24, Step 2000, loss: 0.16459275782108307, disc_loss: 0.001274386653676629
INFO:root:Epoch 24, Step 2500, loss: 0.19598668813705444, disc_loss: 0.0011494449572637677
INFO:root:Generator loss: 0.1463845994649003, Discriminator loss: 0.004423898594166848
INFO:root:Epoch 25, Step 500, loss: 0.1954285204410553, disc_loss: 0.0005737002938985825
INFO:root:Epoch 25, Step 1000, loss: 0.139540433883667, disc_loss: 0.001139194006100297
INFO:root:Epoch 25, Step 1500, loss: 0.199270099401474, disc_loss: 0.00035789195680990815
INFO:root:Epoch 25, Step 2000, loss: 0.21838296949863434, disc_loss: 0.002227922435849905
INFO:root:Epoch 25, Step 2500, loss: 0.2133057713508606, disc_loss: 0.0014298665337264538
INFO:root:Generator loss: 0.15024998671944859, Discriminator loss: 0.005782945559544317
INFO:root:Epoch 26, Step 500, loss: 0.15683746337890625, disc_loss: 0.005752619821578264
INFO:root:Epoch 26, Step 1000, loss: 0.20373192429542542, disc_loss: 0.005968514829874039
INFO:root:Epoch 26, Step 1500, loss: 0.16870155930519104, disc_loss: 8.64794128574431e-05
INFO:root:Epoch 26, Step 2000, loss: 0.2401660829782486, disc_loss: 0.0013739237328991294
INFO:root:Epoch 26, Step 2500, loss: 0.14565877616405487, disc_loss: 0.000123799909488298
INFO:root:Generator loss: 0.1491950565533152, Discriminator loss: 0.004458141014412513
INFO:root:Epoch 27, Step 500, loss: 0.22536085546016693, disc_loss: 0.0016289092600345612
INFO:root:Epoch 27, Step 1000, loss: 0.2141142189502716, disc_loss: 0.001009437721222639
INFO:root:Epoch 27, Step 1500, loss: 0.1656523197889328, disc_loss: 0.00040168900159187615
INFO:root:Epoch 27, Step 2000, loss: 0.1629050225019455, disc_loss: 0.0011503692949190736
INFO:root:Epoch 27, Step 2500, loss: 0.1370559185743332, disc_loss: 0.003623850643634796
INFO:root:Generator loss: 0.14925253300846203, Discriminator loss: 0.006202199372090088
INFO:root:Epoch 28, Step 500, loss: 0.24021084606647491, disc_loss: 0.003933637402951717
INFO:root:Epoch 28, Step 1000, loss: 0.212386816740036, disc_loss: 0.002248520264402032
INFO:root:Epoch 28, Step 1500, loss: 0.14202679693698883, disc_loss: 0.013650942593812943
INFO:root:Epoch 28, Step 2000, loss: 0.19615180790424347, disc_loss: 0.003349786391481757
INFO:root:Epoch 28, Step 2500, loss: 0.21412797272205353, disc_loss: 0.00018327543511986732
INFO:root:Generator loss: 0.14804998383794016, Discriminator loss: 0.004108614199369574
INFO:root:Epoch 29, Step 500, loss: 0.17321325838565826, disc_loss: 0.000446920603280887
INFO:root:Epoch 29, Step 1000, loss: 0.1201920285820961, disc_loss: 0.001177969970740378
INFO:root:Epoch 29, Step 1500, loss: 0.21651656925678253, disc_loss: 0.0010790362721309066
INFO:root:Epoch 29, Step 2000, loss: 0.18687105178833008, disc_loss: 0.0005557287950068712
INFO:root:Epoch 29, Step 2500, loss: 0.2334761619567871, disc_loss: 0.000476894318126142
INFO:root:Generator loss: 0.14737426692131653, Discriminator loss: 0.005125195426497387
INFO:root:Epoch 30, Step 500, loss: 0.1725720465183258, disc_loss: 0.00375187024474144
INFO:root:Epoch 30, Step 1000, loss: 0.20648059248924255, disc_loss: 0.0012349081225693226
INFO:root:Epoch 30, Step 1500, loss: 0.24287432432174683, disc_loss: 0.0003657360502984375
INFO:root:Epoch 30, Step 2000, loss: 0.17634382843971252, disc_loss: 0.0005809185095131397
INFO:root:Epoch 30, Step 2500, loss: 0.19719354808330536, disc_loss: 0.0006177488248795271
INFO:root:Generator loss: 0.15046566276295673, Discriminator loss: 0.0061090009383635725
INFO:root:Epoch 31, Step 500, loss: 0.23580633103847504, disc_loss: 0.0002540594432502985
INFO:root:Epoch 31, Step 1000, loss: 0.14203113317489624, disc_loss: 0.0004564615956041962
INFO:root:Epoch 31, Step 1500, loss: 0.18564066290855408, disc_loss: 0.000634712865576148
INFO:root:Epoch 31, Step 2000, loss: 0.19662857055664062, disc_loss: 0.000413783680414781
INFO:root:Epoch 31, Step 2500, loss: 0.2160218209028244, disc_loss: 0.003134571947157383
INFO:root:Generator loss: 0.14912728961665653, Discriminator loss: 0.004791412240447067
INFO:root:Epoch 32, Step 500, loss: 0.21894681453704834, disc_loss: 0.001099211280234158
INFO:root:Epoch 32, Step 1000, loss: 0.17767295241355896, disc_loss: 0.03690078854560852
INFO:root:Epoch 32, Step 1500, loss: 0.2674192488193512, disc_loss: 0.0009515582933090627
INFO:root:Epoch 32, Step 2000, loss: 0.16014543175697327, disc_loss: 0.0004541565722320229
INFO:root:Epoch 32, Step 2500, loss: 0.16958338022232056, disc_loss: 0.0017136178212240338
INFO:root:Generator loss: 0.15211112348778735, Discriminator loss: 0.005780023227610232
INFO:root:Epoch 33, Step 500, loss: 0.1715015470981598, disc_loss: 0.0032761679030954838
INFO:root:Epoch 33, Step 1000, loss: 0.1922457069158554, disc_loss: 0.00027826111181639135
INFO:root:Epoch 33, Step 1500, loss: 0.19302816689014435, disc_loss: 0.001984006492421031
INFO:root:Epoch 33, Step 2000, loss: 0.2264683097600937, disc_loss: 0.0013746198965236545
INFO:root:Epoch 33, Step 2500, loss: 0.21464839577674866, disc_loss: 0.0016904218355193734
INFO:root:Generator loss: 0.14702314651996187, Discriminator loss: 0.005620367875539141
INFO:root:Epoch 34, Step 500, loss: 0.18223103880882263, disc_loss: 0.0009543236228637397
INFO:root:Epoch 34, Step 1000, loss: 0.16896826028823853, disc_loss: 0.0014935622457414865
INFO:root:Epoch 34, Step 1500, loss: 0.20968642830848694, disc_loss: 0.0020515306387096643
INFO:root:Epoch 34, Step 2000, loss: 0.16302227973937988, disc_loss: 0.0015525969211012125
INFO:root:Epoch 34, Step 2500, loss: 0.19903244078159332, disc_loss: 0.0007291568908840418
INFO:root:Generator loss: 0.15365096709681947, Discriminator loss: 0.005982104519310631
INFO:root:Epoch 35, Step 500, loss: 0.1604795604944229, disc_loss: 0.0015581987099722028
INFO:root:Epoch 35, Step 1000, loss: 0.16866786777973175, disc_loss: 0.0014507027808576822
INFO:root:Epoch 35, Step 1500, loss: 0.21061788499355316, disc_loss: 0.0014126002788543701
INFO:root:Epoch 35, Step 2000, loss: 0.23443660140037537, disc_loss: 0.000980706070549786
INFO:root:Epoch 35, Step 2500, loss: 0.267285019159317, disc_loss: 0.0019638051744550467
INFO:root:Generator loss: 0.14596518765664795, Discriminator loss: 0.005487794701887484
INFO:root:Epoch 36, Step 500, loss: 0.23222292959690094, disc_loss: 0.0014451033202931285
INFO:root:Epoch 36, Step 1000, loss: 0.20879215002059937, disc_loss: 0.0006265640840865672
INFO:root:Epoch 36, Step 1500, loss: 0.17578858137130737, disc_loss: 0.001921408693306148
INFO:root:Epoch 36, Step 2000, loss: 0.23756259679794312, disc_loss: 0.00032307286164723337
INFO:root:Epoch 36, Step 2500, loss: 0.18669255077838898, disc_loss: 0.0002036907389992848
INFO:root:Generator loss: 0.14813864947233385, Discriminator loss: 0.005631698242564419
INFO:root:Epoch 37, Step 500, loss: 0.18507276475429535, disc_loss: 0.00037093766150064766
INFO:root:Epoch 37, Step 1000, loss: 0.17332077026367188, disc_loss: 0.002693770220503211
INFO:root:Epoch 37, Step 1500, loss: 0.21282140910625458, disc_loss: 0.002007674425840378
INFO:root:Epoch 37, Step 2000, loss: 0.2726612389087677, disc_loss: 0.0025570248253643513
INFO:root:Epoch 37, Step 2500, loss: 0.19082844257354736, disc_loss: 0.0015695010079070926
INFO:root:Generator loss: 0.14617949232314398, Discriminator loss: 0.004991642974328517
INFO:root:Epoch 38, Step 500, loss: 0.18385282158851624, disc_loss: 0.0009151673875749111
INFO:root:Epoch 38, Step 1000, loss: 0.3008362948894501, disc_loss: 0.0029870897997170687
INFO:root:Epoch 38, Step 1500, loss: 0.21476788818836212, disc_loss: 0.0009111472172662616
INFO:root:Epoch 38, Step 2000, loss: 0.16502749919891357, disc_loss: 0.0008587189950048923
INFO:root:Epoch 38, Step 2500, loss: 0.2218039482831955, disc_loss: 0.003261287696659565
INFO:root:Generator loss: 0.147731199535062, Discriminator loss: 0.005121302179264885
INFO:root:Epoch 39, Step 500, loss: 0.20068179070949554, disc_loss: 0.0004833288840018213
INFO:root:Epoch 39, Step 1000, loss: 0.1840275675058365, disc_loss: 0.0014471531612798572
INFO:root:Epoch 39, Step 1500, loss: 0.2496587038040161, disc_loss: 0.00044558188528753817
INFO:root:Epoch 39, Step 2000, loss: 0.15792885422706604, disc_loss: 0.0020721079781651497
INFO:root:Epoch 39, Step 2500, loss: 0.23559805750846863, disc_loss: 0.002074484247714281
INFO:root:Generator loss: 0.14587214382962116, Discriminator loss: 0.006063152137958418
INFO:root:Epoch 40, Step 500, loss: 0.16052734851837158, disc_loss: 0.0016863951459527016
INFO:root:Epoch 40, Step 1000, loss: 0.16263064742088318, disc_loss: 0.004407273139804602
INFO:root:Epoch 40, Step 1500, loss: 0.2309708297252655, disc_loss: 0.00048226932995021343
INFO:root:Epoch 40, Step 2000, loss: 0.2055741548538208, disc_loss: 0.0014350657584145665
INFO:root:Epoch 40, Step 2500, loss: 0.19957517087459564, disc_loss: 0.00018001307034865022
INFO:root:Generator loss: 0.14811466757244277, Discriminator loss: 0.0049704438705111455
INFO:root:Epoch 41, Step 500, loss: 0.3921284079551697, disc_loss: 0.0003702079120557755
INFO:root:Epoch 41, Step 1000, loss: 0.178117573261261, disc_loss: 0.0017780557973310351
INFO:root:Epoch 41, Step 1500, loss: 0.13008680939674377, disc_loss: 0.0008523680735379457
INFO:root:Epoch 41, Step 2000, loss: 0.23620039224624634, disc_loss: 0.00020431909069884568
INFO:root:Epoch 41, Step 2500, loss: 0.1764468401670456, disc_loss: 0.002292202552780509
INFO:root:Generator loss: 0.14642022828598625, Discriminator loss: 0.004562960532143513
INFO:root:Epoch 42, Step 500, loss: 0.22318385541439056, disc_loss: 0.004478695802390575
INFO:root:Epoch 42, Step 1000, loss: 0.1792517751455307, disc_loss: 0.001604250050149858
INFO:root:Epoch 42, Step 1500, loss: 0.15372514724731445, disc_loss: 0.0017921491526067257
INFO:root:Epoch 42, Step 2000, loss: 0.2568913698196411, disc_loss: 0.001368546043522656
INFO:root:Epoch 42, Step 2500, loss: 0.18099595606327057, disc_loss: 0.009196550585329533
INFO:root:Generator loss: 0.14845844629464797, Discriminator loss: 0.005273171170381264
INFO:root:Epoch 43, Step 500, loss: 0.17924398183822632, disc_loss: 0.0005816738121211529
INFO:root:Epoch 43, Step 1000, loss: 0.14031054079532623, disc_loss: 0.0011399531504139304
INFO:root:Epoch 43, Step 1500, loss: 0.19618485867977142, disc_loss: 0.012073153629899025
INFO:root:Epoch 43, Step 2000, loss: 0.1403481811285019, disc_loss: 0.00020431471057236195
INFO:root:Epoch 43, Step 2500, loss: 0.13355231285095215, disc_loss: 0.0026186013128608465
INFO:root:Generator loss: 0.14782923626378902, Discriminator loss: 0.006137810620785582
INFO:root:Epoch 44, Step 500, loss: 0.22315263748168945, disc_loss: 0.0010761287994682789
INFO:root:Epoch 44, Step 1000, loss: 0.18191732466220856, disc_loss: 0.0005242417100816965
INFO:root:Epoch 44, Step 1500, loss: 0.1477629542350769, disc_loss: 0.00067752948962152
INFO:root:Epoch 44, Step 2000, loss: 0.13648012280464172, disc_loss: 0.0024802912957966328
INFO:root:Epoch 44, Step 2500, loss: 0.19879427552223206, disc_loss: 0.0015828186878934503
INFO:root:Generator loss: 0.14875781131022184, Discriminator loss: 0.00829521962247243
INFO:root:Epoch 45, Step 500, loss: 0.13115713000297546, disc_loss: 0.0009741386165842414
INFO:root:Epoch 45, Step 1000, loss: 0.17944218218326569, disc_loss: 0.003285817801952362
INFO:root:Epoch 45, Step 1500, loss: 0.14362654089927673, disc_loss: 0.001050826394930482
INFO:root:Epoch 45, Step 2000, loss: 0.1789437085390091, disc_loss: 0.0005134831881150603
INFO:root:Epoch 45, Step 2500, loss: 0.1432753950357437, disc_loss: 0.0004064008826389909
INFO:root:Generator loss: 0.14733574644309802, Discriminator loss: 0.004944391138875307
INFO:root:Epoch 46, Step 500, loss: 0.2227780669927597, disc_loss: 0.0007084257085807621
INFO:root:Epoch 46, Step 1000, loss: 0.19407567381858826, disc_loss: 0.0016836734721437097
INFO:root:Epoch 46, Step 1500, loss: 0.2124943733215332, disc_loss: 0.0012191098649054766
INFO:root:Epoch 46, Step 2000, loss: 0.2266724705696106, disc_loss: 0.0007316034752875566
INFO:root:Epoch 46, Step 2500, loss: 0.12773838639259338, disc_loss: 0.0005753585719503462
INFO:root:Generator loss: 0.14805475466893714, Discriminator loss: 0.005936762607146114
INFO:root:Epoch 47, Step 500, loss: 0.1649109274148941, disc_loss: 0.002198372269049287
INFO:root:Epoch 47, Step 1000, loss: 0.1756979078054428, disc_loss: 0.0008400000515393913
INFO:root:Epoch 47, Step 1500, loss: 0.18234282732009888, disc_loss: 0.0012568270321935415
INFO:root:Epoch 47, Step 2000, loss: 0.1919807344675064, disc_loss: 0.0013501453213393688
INFO:root:Epoch 47, Step 2500, loss: 0.11693424731492996, disc_loss: 0.0009471818339079618
INFO:root:Generator loss: 0.14861386840783278, Discriminator loss: 0.0052251179323735695
INFO:root:Epoch 48, Step 500, loss: 0.2223605364561081, disc_loss: 0.0016664100112393498
INFO:root:Epoch 48, Step 1000, loss: 0.13113467395305634, disc_loss: 0.0029477279167622328
INFO:root:Epoch 48, Step 1500, loss: 0.2264370620250702, disc_loss: 0.00043882554746232927
INFO:root:Epoch 48, Step 2000, loss: 0.10461048036813736, disc_loss: 0.00036733210436068475
INFO:root:Epoch 48, Step 2500, loss: 0.16475045680999756, disc_loss: 0.002550833858549595
INFO:root:Generator loss: 0.14658120929182156, Discriminator loss: 0.005046164398734318
INFO:root:Epoch 49, Step 500, loss: 0.2088738977909088, disc_loss: 0.0010780894663184881
INFO:root:Epoch 49, Step 1000, loss: 0.13282427191734314, disc_loss: 0.0018382645212113857
INFO:root:Epoch 49, Step 1500, loss: 0.19930881261825562, disc_loss: 0.00265000038780272
INFO:root:Epoch 49, Step 2000, loss: 0.2693479359149933, disc_loss: 0.0017504096031188965
INFO:root:Epoch 49, Step 2500, loss: 0.1664438247680664, disc_loss: 0.0017850355943664908
INFO:root:Generator loss: 0.1474712997385599, Discriminator loss: 0.006439501676079125
INFO:root:Epoch 50, Step 500, loss: 0.20469503104686737, disc_loss: 0.0037625092081725597
INFO:root:Epoch 50, Step 1000, loss: 0.1624937206506729, disc_loss: 0.0012744253035634756
INFO:root:Epoch 50, Step 1500, loss: 0.16506120562553406, disc_loss: 0.00026086828438565135
INFO:root:Epoch 50, Step 2000, loss: 0.12355786561965942, disc_loss: 0.0007355384295806289
INFO:root:Epoch 50, Step 2500, loss: 0.15656428039073944, disc_loss: 0.001017753267660737
INFO:root:Generator loss: 0.14612536645919375, Discriminator loss: 0.006263298145454737
INFO:root:Epoch 51, Step 500, loss: 0.19832417368888855, disc_loss: 0.02715951018035412
INFO:root:Epoch 51, Step 1000, loss: 0.2594590187072754, disc_loss: 0.001878035138361156
INFO:root:Epoch 51, Step 1500, loss: 0.17384062707424164, disc_loss: 0.0009054866968654096
INFO:root:Epoch 51, Step 2000, loss: 0.14554131031036377, disc_loss: 0.0009158121538348496
INFO:root:Epoch 51, Step 2500, loss: 0.18689943850040436, disc_loss: 0.002403577556833625
INFO:root:Generator loss: 0.1494631567988002, Discriminator loss: 0.004101946354425202
INFO:root:Epoch 52, Step 500, loss: 0.28567615151405334, disc_loss: 0.0014829984866082668
INFO:root:Epoch 52, Step 1000, loss: 0.23701557517051697, disc_loss: 6.192684668349102e-05
INFO:root:Epoch 52, Step 1500, loss: 0.1403486579656601, disc_loss: 0.0007471531280316412
INFO:root:Epoch 52, Step 2000, loss: 0.1077519878745079, disc_loss: 0.0011453269980847836
INFO:root:Epoch 52, Step 2500, loss: 0.17090456187725067, disc_loss: 0.0006765348953194916
INFO:root:Generator loss: 0.14964666919222155, Discriminator loss: 0.007470223582061505
INFO:root:Epoch 53, Step 500, loss: 0.19975389540195465, disc_loss: 0.0013929307460784912
INFO:root:Epoch 53, Step 1000, loss: 0.23262934386730194, disc_loss: 0.0011351010762155056
INFO:root:Epoch 53, Step 1500, loss: 0.2729252278804779, disc_loss: 0.0021782873664051294
INFO:root:Epoch 53, Step 2000, loss: 0.21736101806163788, disc_loss: 0.0015289199072867632
INFO:root:Epoch 53, Step 2500, loss: 0.19195528328418732, disc_loss: 0.0001974821207113564
INFO:root:Generator loss: 0.14729923223262853, Discriminator loss: 0.004570223682588848
INFO:root:Epoch 54, Step 500, loss: 0.1663016825914383, disc_loss: 0.0004415601724758744
INFO:root:Epoch 54, Step 1000, loss: 0.262975811958313, disc_loss: 0.00030189764220267534
INFO:root:Epoch 54, Step 1500, loss: 0.16679571568965912, disc_loss: 0.0014291097177192569
INFO:root:Epoch 54, Step 2000, loss: 0.19041676819324493, disc_loss: 0.0010663163848221302
INFO:root:Epoch 54, Step 2500, loss: 0.2282182276248932, disc_loss: 0.00018123078916687518
INFO:root:Generator loss: 0.14866855013573055, Discriminator loss: 0.005688388988805722
INFO:root:Epoch 55, Step 500, loss: 0.19495198130607605, disc_loss: 0.0006752232438884676
INFO:root:Epoch 55, Step 1000, loss: 0.16434845328330994, disc_loss: 0.001483214320614934
INFO:root:Epoch 55, Step 1500, loss: 0.2080022096633911, disc_loss: 0.002587445778772235
INFO:root:Epoch 55, Step 2000, loss: 0.15588298439979553, disc_loss: 0.0005700874608010054
INFO:root:Epoch 55, Step 2500, loss: 0.13397282361984253, disc_loss: 0.0017989255720749497
INFO:root:Generator loss: 0.148282225849559, Discriminator loss: 0.0053943412554536795
INFO:root:Epoch 56, Step 500, loss: 0.17334139347076416, disc_loss: 0.001014225883409381
INFO:root:Epoch 56, Step 1000, loss: 0.17860911786556244, disc_loss: 0.0009214368765242398
INFO:root:Epoch 56, Step 1500, loss: 0.18977996706962585, disc_loss: 0.0011374271707609296
INFO:root:Epoch 56, Step 2000, loss: 0.20623205602169037, disc_loss: 0.0016146533889696002
INFO:root:Epoch 56, Step 2500, loss: 0.18183909356594086, disc_loss: 0.00033840679679997265
INFO:root:Generator loss: 0.14729258602539314, Discriminator loss: 0.005863869425208303
INFO:root:Epoch 57, Step 500, loss: 0.193978413939476, disc_loss: 0.0009271332528442144
INFO:root:Epoch 57, Step 1000, loss: 0.2361052930355072, disc_loss: 0.00048621499445289373
INFO:root:Epoch 57, Step 1500, loss: 0.23580823838710785, disc_loss: 0.002198867965489626
INFO:root:Epoch 57, Step 2000, loss: 0.1524619162082672, disc_loss: 0.0006231038132682443
INFO:root:Epoch 57, Step 2500, loss: 0.21025513112545013, disc_loss: 0.0010288431076332927
INFO:root:Generator loss: 0.14851086778403486, Discriminator loss: 0.0054679064304614215
INFO:root:Epoch 58, Step 500, loss: 0.14637041091918945, disc_loss: 0.0002362811064813286
INFO:root:Epoch 58, Step 1000, loss: 0.1516624093055725, disc_loss: 0.0017596640391275287
INFO:root:Epoch 58, Step 1500, loss: 0.16508997976779938, disc_loss: 0.005480214022099972
INFO:root:Epoch 58, Step 2000, loss: 0.17111648619174957, disc_loss: 0.0008860450470820069
INFO:root:Epoch 58, Step 2500, loss: 0.09150104224681854, disc_loss: 0.0007189033203758299
INFO:root:Generator loss: 0.14596241929577392, Discriminator loss: 0.005693236166991076
INFO:root:Epoch 59, Step 500, loss: 0.17735478281974792, disc_loss: 0.00023293672711588442
INFO:root:Epoch 59, Step 1000, loss: 0.14792637526988983, disc_loss: 0.0024113543331623077
INFO:root:Epoch 59, Step 1500, loss: 0.23733660578727722, disc_loss: 0.0009372477070428431
INFO:root:Epoch 59, Step 2000, loss: 0.17583313584327698, disc_loss: 0.0010882980423048139
INFO:root:Epoch 59, Step 2500, loss: 0.11411377787590027, disc_loss: 0.0008593680686317384
INFO:root:Generator loss: 0.14474850798984176, Discriminator loss: 0.004539507138104861
Training finished.
Starting batch evaluation...
Evaluating: CMGAN_epoch_0_0.186
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.7327836184825713 csig:  4.224813773231449 cbak:  3.511182680934232 covl:  3.539694651677021 ssnr:  9.59086270031502 stoi:  0.9391378695092608


Evaluating: CMGAN_epoch_10_0.156
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0485473052390573 csig:  4.352510914852114 cbak:  3.741988470758865 covl:  3.7665347255646497 ssnr:  10.746508020709587 stoi:  0.9502097769169812


Evaluating: CMGAN_epoch_1_0.183
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.831567527165691 csig:  4.294356461237024 cbak:  3.5506852322680102 covl:  3.625271097319369 ssnr:  9.469776952646383 stoi:  0.9401868144983594


Evaluating: CMGAN_epoch_11_0.160
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0692117506439245 csig:  4.326337475140976 cbak:  3.7228780546303377 covl:  3.764898840284101 ssnr:  10.291514498412452 stoi:  0.950921635437201


Evaluating: CMGAN_epoch_12_0.155
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1658588442408924 csig:  4.498876750829179 cbak:  3.7876626317149977 covl:  3.9076267528448123 ssnr:  10.5668321150478 stoi:  0.951813650566903


Evaluating: CMGAN_epoch_13_0.153
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.185854144322062 csig:  4.505617930763067 cbak:  3.809508280951155 covl:  3.9264687358208783 ssnr:  10.759180434236104 stoi:  0.9515538203695727


Evaluating: CMGAN_epoch_14_0.162
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1751991798287458 csig:  4.474705291957888 cbak:  3.7546007876612015 covl:  3.904399708304166 ssnr:  10.028929768846714 stoi:  0.9525518963044931


Evaluating: CMGAN_epoch_15_0.152
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1611938741311287 csig:  4.438599703602864 cbak:  3.796242714294979 covl:  3.8759775689784264 ssnr:  10.727997972161866 stoi:  0.9532232143638246


Evaluating: CMGAN_epoch_16_0.152
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1564007020980407 csig:  4.457526762018337 cbak:  3.795220844909584 covl:  3.8810757879193756 ssnr:  10.759868138166196 stoi:  0.9534513663806848


Evaluating: CMGAN_epoch_17_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1693291704631545 csig:  4.423800959288964 cbak:  3.8100904579398076 covl:  3.8705872431178046 ssnr:  10.886506445861102 stoi:  0.9532315511779772


Evaluating: CMGAN_epoch_18_0.161
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.167201013530342 csig:  4.4978056247956175 cbak:  3.764628191786447 covl:  3.910553014369412 ssnr:  10.232553477864615 stoi:  0.9536226467274043


Evaluating: CMGAN_epoch_19_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.217264526098677 csig:  4.488834413142125 cbak:  3.8362875973723587 covl:  3.9313211614604735 ssnr:  10.937087078294345 stoi:  0.9538935988947552


Evaluating: CMGAN_epoch_20_0.153
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.225714506020824 csig:  4.511469209065002 cbak:  3.8107974259840582 covl:  3.9537395029502327 ssnr:  10.488507842290295 stoi:  0.9527716533414865


Evaluating: CMGAN_epoch_2_0.178
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.914014462273098 csig:  4.320956626594213 cbak:  3.603852413561458 covl:  3.681077322854246 ssnr:  9.668217573443979 stoi:  0.9404777997926771


Evaluating: CMGAN_epoch_21_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1757973519343774 csig:  4.496633903785435 cbak:  3.8179461891810242 covl:  3.913128152345749 ssnr:  10.965308843738713 stoi:  0.9538086721342641


Evaluating: CMGAN_epoch_22_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1759846164184866 csig:  4.399497685362492 cbak:  3.8104001101326643 covl:  3.862172391976816 ssnr:  10.85338371625644 stoi:  0.9541568507316764


Evaluating: CMGAN_epoch_23_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1896167530596835 csig:  4.461440122921841 cbak:  3.8151381930655637 covl:  3.9052472707061505 ssnr:  10.81036891962105 stoi:  0.9534142836065377


Evaluating: CMGAN_epoch_24_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2497371286153793 csig:  4.5312503550993295 cbak:  3.861099049491976 covl:  3.974446457135305 ssnr:  11.07285101876121 stoi:  0.9541482518003123


Evaluating: CMGAN_epoch_25_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2100225998070635 csig:  4.497682477892491 cbak:  3.8232695739424156 covl:  3.932286663153081 ssnr:  10.800385446048832 stoi:  0.9547119446770188


Evaluating: CMGAN_epoch_26_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2625187120391326 csig:  4.531567585544602 cbak:  3.8527158721507364 covl:  3.9823270810694322 ssnr:  10.857822115847947 stoi:  0.9539493331610661


Evaluating: CMGAN_epoch_27_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2694926914370175 csig:  4.530125978891088 cbak:  3.855339957528843 covl:  3.9842126700357374 ssnr:  10.846713754981344 stoi:  0.9543659422914416


Evaluating: CMGAN_epoch_28_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.25918078480415 csig:  4.536621665411152 cbak:  3.849794185444785 covl:  3.9792390360520637 ssnr:  10.84066479758847 stoi:  0.9550438873114804


Evaluating: CMGAN_epoch_29_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2347208913958188 csig:  4.499588817072551 cbak:  3.845372134820996 covl:  3.948671930642473 ssnr:  10.948898871735992 stoi:  0.9546596495775795


Evaluating: CMGAN_epoch_30_0.150
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.226958165180336 csig:  4.5225922677452255 cbak:  3.8246667187754038 covl:  3.9568085333714835 ssnr:  10.70358000025255 stoi:  0.9552056590479482


Evaluating: CMGAN_epoch_3_0.185
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.947899235828409 csig:  4.320912267081351 cbak:  3.5811982361470243 covl:  3.69769045550049 ssnr:  9.124660615980904 stoi:  0.9455799516022243


Evaluating: CMGAN_epoch_31_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.227067543175614 csig:  4.483025706975064 cbak:  3.8355580015036375 covl:  3.935730756923967 ssnr:  10.854135411753147 stoi:  0.9554559801009078


Evaluating: CMGAN_epoch_32_0.152
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.254036109424332 csig:  4.49363171625609 cbak:  3.8320724845837564 covl:  3.9569061779493864 ssnr:  10.621328766218193 stoi:  0.9536293725871025


Evaluating: CMGAN_epoch_33_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.258673457121386 csig:  4.54327984921512 cbak:  3.858291456409451 covl:  3.9854611304974523 ssnr:  10.970016248724352 stoi:  0.9548197026460858


Evaluating: CMGAN_epoch_34_0.153
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3068163601808176 csig:  4.500328254863351 cbak:  3.8442856862634356 covl:  3.9888048959146367 ssnr:  10.435143226011752 stoi:  0.9533969835472033


Evaluating: CMGAN_epoch_35_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.265374307638233 csig:  4.523122102652209 cbak:  3.864091611506821 covl:  3.975754813052049 ssnr:  11.015636666381068 stoi:  0.9544491709727557


Evaluating: CMGAN_epoch_36_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.217052474907301 csig:  4.531114100799864 cbak:  3.837101380063478 covl:  3.956636775759294 ssnr:  10.942732126619523 stoi:  0.9557913091313274


Evaluating: CMGAN_epoch_37_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.243787674359905 csig:  4.5226996485066655 cbak:  3.857772777377522 covl:  3.965973906418094 ssnr:  11.0692201589591 stoi:  0.955172414535687


Evaluating: CMGAN_epoch_38_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.251218075891143 csig:  4.514232883835432 cbak:  3.845854938663909 covl:  3.964246043392537 ssnr:  10.833463188930203 stoi:  0.955302485010497


Evaluating: CMGAN_epoch_39_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2730506855307273 csig:  4.527156233863385 cbak:  3.870128021095964 covl:  3.983926263591507 ssnr:  11.041841635502813 stoi:  0.954875153289337


Evaluating: CMGAN_epoch_40_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.259637813544968 csig:  4.513082178583069 cbak:  3.852222249872896 covl:  3.968248576853502 ssnr:  10.875728286114496 stoi:  0.9554070995069172


Evaluating: CMGAN_epoch_4_0.167
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.9146465044287804 csig:  4.319272062728609 cbak:  3.6554577565344646 covl:  3.675181263147534 ssnr:  10.421774443031644 stoi:  0.9440882429901866


Evaluating: CMGAN_epoch_41_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.227837272205399 csig:  4.513249825906852 cbak:  3.846100966332241 covl:  3.9512730954567763 ssnr:  11.013758615690751 stoi:  0.9555256139584668


Evaluating: CMGAN_epoch_42_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2556422574138177 csig:  4.516592840180717 cbak:  3.8491565877008114 covl:  3.969311339065834 ssnr:  10.85485542398673 stoi:  0.9557475649518561


Evaluating: CMGAN_epoch_43_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2713018874230895 csig:  4.538816339406383 cbak:  3.858399161085234 covl:  3.9909140423182063 ssnr:  10.877635157369093 stoi:  0.955375070088548


Evaluating: CMGAN_epoch_44_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2018856663727067 csig:  4.494659015580388 cbak:  3.825288790004119 covl:  3.927391277299151 ssnr:  10.888183619119182 stoi:  0.9557049619358439


Evaluating: CMGAN_epoch_45_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2659621844881945 csig:  4.5191440719139875 cbak:  3.854342492638263 covl:  3.9746599293015334 ssnr:  10.86729276626728 stoi:  0.9551956123664364


Evaluating: CMGAN_epoch_46_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.260315739414067 csig:  4.51364622131921 cbak:  3.8510622373813503 covl:  3.970258320389035 ssnr:  10.856758199399641 stoi:  0.9550333755486845


Evaluating: CMGAN_epoch_47_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.259310970896656 csig:  4.513217744966925 cbak:  3.847694823406103 covl:  3.970247929198622 ssnr:  10.808218031481292 stoi:  0.955320893856987


Evaluating: CMGAN_epoch_48_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.277110854109514 csig:  4.532820281270311 cbak:  3.8655817153541085 covl:  3.9901091181600172 ssnr:  10.943362992481255 stoi:  0.9556031410861605


Evaluating: CMGAN_epoch_49_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2726926041170232 csig:  4.531035420881945 cbak:  3.8604585217282987 covl:  3.985184989726305 ssnr:  10.90165702769987 stoi:  0.9553366546641481


Evaluating: CMGAN_epoch_50_0.146
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.269864778061515 csig:  4.5348704394322175 cbak:  3.864152657692469 covl:  3.9877332872423215 ssnr:  10.979438074282754 stoi:  0.9555582365404227


Evaluating: CMGAN_epoch_5_0.164
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0160585623053673 csig:  4.386369958386487 cbak:  3.707532300050729 covl:  3.7686206240609432 ssnr:  10.462045808691625 stoi:  0.94889947189959


Evaluating: CMGAN_epoch_51_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.292465801811913 csig:  4.529817242612743 cbak:  3.8587923293611204 covl:  3.995527279134158 ssnr:  10.748767477447736 stoi:  0.9554872838784727


Evaluating: CMGAN_epoch_52_0.149
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.250580245285358 csig:  4.523735735413749 cbak:  3.8402199534264705 covl:  3.969887834048065 ssnr:  10.761338692637791 stoi:  0.9554077223683691


Evaluating: CMGAN_epoch_53_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.238841653448864 csig:  4.521819773609865 cbak:  3.8472471868304257 covl:  3.962800588452897 ssnr:  10.945800444287107 stoi:  0.9558266732316035


Evaluating: CMGAN_epoch_54_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2617273172996577 csig:  4.537039014447411 cbak:  3.848276125764626 covl:  3.982720592103736 ssnr:  10.806120964680085 stoi:  0.9558682963704155


Evaluating: CMGAN_epoch_55_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.242136207743756 csig:  4.520243878937466 cbak:  3.842671677392089 covl:  3.9631597229000013 ssnr:  10.853016109794556 stoi:  0.9558485237463931


Evaluating: CMGAN_epoch_56_0.147
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2822118300257377 csig:  4.536961320947015 cbak:  3.863929856033082 covl:  3.996109872270323 ssnr:  10.889322285732135 stoi:  0.9556523798746634


Evaluating: CMGAN_epoch_57_0.148
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.263174134695414 csig:  4.504222157855617 cbak:  3.8483479382329118 covl:  3.9658746776490554 ssnr:  10.79324865741882 stoi:  0.9557574608102747


Evaluating: CMGAN_epoch_58_0.145
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.257160166368901 csig:  4.510241484306612 cbak:  3.8573806214228674 covl:  3.964996997987389 ssnr:  10.971771095621577 stoi:  0.9556126700902939


Evaluating: CMGAN_epoch_59_0.144
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2606515532847746 csig:  4.516786962081032 cbak:  3.867626824618858 covl:  3.9697767462102003 ssnr:  11.099568461850541 stoi:  0.9556886839904815


Evaluating: CMGAN_epoch_6_0.163
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0459381551707834 csig:  4.428598366853195 cbak:  3.718956044287095 covl:  3.80675805774096 ssnr:  10.405629303605263 stoi:  0.9452048392841363


Evaluating: CMGAN_epoch_7_0.174
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.051171677205169 csig:  4.363075004516157 cbak:  3.686067803095967 covl:  3.764663124612667 ssnr:  10.044490936309597 stoi:  0.9464190808315366


Evaluating: CMGAN_epoch_8_0.161
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.085187234924835 csig:  4.419357684174375 cbak:  3.735358553444817 covl:  3.8228643237329285 ssnr:  10.359023956102073 stoi:  0.9484928764258144


Evaluating: CMGAN_epoch_9_0.159
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.099180568045783 csig:  4.383616291331283 cbak:  3.745981700871246 covl:  3.8117748028732947 ssnr:  10.442130510951372 stoi:  0.9505170128606615


