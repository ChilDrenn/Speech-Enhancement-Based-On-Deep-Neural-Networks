Starting training:
with SE:
Namespace(batch_size=4, cut_len=32000, data_dir='/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/DEMAND_16KHz', decay_epoch=12, epochs=60, init_lr=0.0005, log_interval=500, loss_weights=[0.1, 0.9, 0.2, 0.05], save_model_dir='./saved_models_log/saved_models_20250720_VoiceDEMAND_16khz')
['NVIDIA A100-SXM4-80GB']
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
TSCNet                                             [1, 1, 321, 201]          --
├─DenseEncoder: 1-1                                [1, 64, 321, 101]         --
│    └─Sequential: 2-1                             [1, 64, 321, 201]         --
│    │    └─Conv2d: 3-1                            [1, 64, 321, 201]         256
│    │    └─InstanceNorm2d: 3-2                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-3                             [1, 64, 321, 201]         64
│    └─SEBlock: 2-2                                [1, 64, 321, 201]         --
│    │    └─Sequential: 3-4                        [1, 64]                   580
│    └─DilatedDenseNet: 2-3                        [1, 64, 321, 201]         --
│    │    └─ConstantPad2d: 3-5                     [1, 64, 322, 203]         --
│    │    └─Conv2d: 3-6                            [1, 64, 321, 201]         24,640
│    │    └─InstanceNorm2d: 3-7                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-8                             [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-9                     [1, 128, 323, 203]        --
│    │    └─Conv2d: 3-10                           [1, 64, 321, 201]         49,216
│    │    └─InstanceNorm2d: 3-11                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-12                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-13                    [1, 192, 325, 203]        --
│    │    └─Conv2d: 3-14                           [1, 64, 321, 201]         73,792
│    │    └─InstanceNorm2d: 3-15                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-16                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-17                    [1, 256, 329, 203]        --
│    │    └─Conv2d: 3-18                           [1, 64, 321, 201]         98,368
│    │    └─InstanceNorm2d: 3-19                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-20                            [1, 64, 321, 201]         64
│    └─Sequential: 2-4                             [1, 64, 321, 101]         --
│    │    └─Conv2d: 3-21                           [1, 64, 321, 101]         12,352
│    │    └─InstanceNorm2d: 3-22                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-23                            [1, 64, 321, 101]         64
├─TSCB: 1-2                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-5                         [101, 321, 64]            --
│    │    └─Scale: 3-24                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-25                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-26              [101, 321, 64]            29,376
│    │    └─Scale: 3-27                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-28                        [101, 321, 64]            128
│    └─ConformerBlock: 2-6                         [321, 101, 64]            --
│    │    └─Scale: 3-29                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-30                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-31              [321, 101, 64]            29,376
│    │    └─Scale: 3-32                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-33                        [321, 101, 64]            128
├─TSCB: 1-3                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-7                         [101, 321, 64]            --
│    │    └─Scale: 3-34                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-35                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-36              [101, 321, 64]            29,376
│    │    └─Scale: 3-37                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-38                        [101, 321, 64]            128
│    └─ConformerBlock: 2-8                         [321, 101, 64]            --
│    │    └─Scale: 3-39                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-40                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-41              [321, 101, 64]            29,376
│    │    └─Scale: 3-42                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-43                        [321, 101, 64]            128
├─TSCB: 1-4                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-9                         [101, 321, 64]            --
│    │    └─Scale: 3-44                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-45                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-46              [101, 321, 64]            29,376
│    │    └─Scale: 3-47                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-48                        [101, 321, 64]            128
│    └─ConformerBlock: 2-10                        [321, 101, 64]            --
│    │    └─Scale: 3-49                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-50                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-51              [321, 101, 64]            29,376
│    │    └─Scale: 3-52                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-53                        [321, 101, 64]            128
├─TSCB: 1-5                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-11                        [101, 321, 64]            --
│    │    └─Scale: 3-54                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-55                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-56              [101, 321, 64]            29,376
│    │    └─Scale: 3-57                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-58                        [101, 321, 64]            128
│    └─ConformerBlock: 2-12                        [321, 101, 64]            --
│    │    └─Scale: 3-59                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-60                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-61              [321, 101, 64]            29,376
│    │    └─Scale: 3-62                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-63                        [321, 101, 64]            128
├─MaskDecoder: 1-6                                 [1, 1, 321, 201]          --
│    └─DilatedDenseNet: 2-13                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-64                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-65                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-66                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-67                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-68                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-69                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-70                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-71                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-72                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-73                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-74                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-75                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-76                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-77                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-78                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-79                            [1, 64, 321, 101]         64
│    └─SEBlock: 2-14                               [1, 64, 321, 101]         --
│    │    └─Sequential: 3-80                       [1, 64]                   580
│    └─SPConvTranspose2d: 2-15                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-81                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-82                           [1, 128, 321, 101]        24,704
│    └─Conv2d: 2-16                                [1, 1, 321, 201]          129
│    └─InstanceNorm2d: 2-17                        [1, 1, 321, 201]          2
│    └─PReLU: 2-18                                 [1, 1, 321, 201]          1
│    └─Conv2d: 2-19                                [1, 1, 321, 201]          2
│    └─PReLU: 2-20                                 [1, 201, 321]             201
├─ComplexDecoder: 1-7                              [1, 2, 321, 201]          --
│    └─DilatedDenseNet: 2-21                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-83                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-84                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-85                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-86                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-87                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-88                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-89                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-90                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-91                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-92                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-93                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-94                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-95                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-96                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-97                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-98                            [1, 64, 321, 101]         64
│    └─SEBlock: 2-22                               [1, 64, 321, 101]         --
│    │    └─Sequential: 3-99                       [1, 64]                   580
│    └─SPConvTranspose2d: 2-23                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-100                   [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-101                          [1, 128, 321, 101]        24,704
│    └─InstanceNorm2d: 2-24                        [1, 64, 321, 202]         128
│    └─PReLU: 2-25                                 [1, 64, 321, 202]         64
│    └─Conv2d: 2-26                                [1, 2, 321, 201]          258
====================================================================================================
Total params: 1,836,573
Trainable params: 1,836,573
Non-trainable params: 0
Total mult-adds (G): 41.56
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 4856.40
Params size (MB): 7.35
Estimated Total Size (MB): 4864.26
====================================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Discriminator                            [1, 1]                    --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Conv2d: 2-1                       [1, 16, 100, 160]         512
│    └─InstanceNorm2d: 2-2               [1, 16, 100, 160]         32
│    └─PReLU: 2-3                        [1, 16, 100, 160]         16
│    └─Conv2d: 2-4                       [1, 32, 50, 80]           8,192
│    └─InstanceNorm2d: 2-5               [1, 32, 50, 80]           64
│    └─PReLU: 2-6                        [1, 32, 50, 80]           32
│    └─Conv2d: 2-7                       [1, 64, 25, 40]           32,768
│    └─InstanceNorm2d: 2-8               [1, 64, 25, 40]           128
│    └─PReLU: 2-9                        [1, 64, 25, 40]           64
│    └─Conv2d: 2-10                      [1, 128, 12, 20]          131,072
│    └─InstanceNorm2d: 2-11              [1, 128, 12, 20]          256
│    └─PReLU: 2-12                       [1, 128, 12, 20]          128
│    └─AdaptiveMaxPool2d: 2-13           [1, 128, 1, 1]            --
│    └─Flatten: 2-14                     [1, 128]                  --
│    └─Linear: 2-15                      [1, 64]                   8,256
│    └─Dropout: 2-16                     [1, 64]                   --
│    └─PReLU: 2-17                       [1, 64]                   64
│    └─Linear: 2-18                      [1, 1]                    65
│    └─LearnableSigmoid: 2-19            [1, 1]                    1
==========================================================================================
Total params: 181,650
Trainable params: 181,650
Non-trainable params: 0
Total mult-adds (M): 19.67
==========================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 11.49
Params size (MB): 0.73
Estimated Total Size (MB): 12.73
==========================================================================================
/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/CMGAN_src/data/dataloader.py:52: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")         # in linux
INFO:root:Epoch 0, Step 500, loss: 0.08670128136873245, disc_loss: 0.04549947381019592
INFO:root:Epoch 0, Step 1000, loss: 0.15383672714233398, disc_loss: 0.0022508257534354925
INFO:root:Epoch 0, Step 1500, loss: 0.12372221797704697, disc_loss: 0.017925653606653214
INFO:root:Epoch 0, Step 2000, loss: 0.18941760063171387, disc_loss: 0.014190060086548328
INFO:root:Epoch 0, Step 2500, loss: 0.08496297150850296, disc_loss: 0.03749791905283928
INFO:root:Generator loss: 0.08291850989521707, Discriminator loss: 0.0060162141616654004
INFO:root:Epoch 1, Step 500, loss: 0.09048350900411606, disc_loss: 0.008999340236186981
INFO:root:Epoch 1, Step 1000, loss: 0.1376453936100006, disc_loss: 0.0037629480939358473
INFO:root:Epoch 1, Step 1500, loss: 0.11865082383155823, disc_loss: 0.002120917895808816
INFO:root:Epoch 1, Step 2000, loss: 0.13195064663887024, disc_loss: 0.005263976287096739
INFO:root:Epoch 1, Step 2500, loss: 0.13385486602783203, disc_loss: 0.005881730001419783
INFO:root:Generator loss: 0.07653015976753628, Discriminator loss: 0.013425401992331828
INFO:root:Epoch 2, Step 500, loss: 0.1251046061515808, disc_loss: 0.011628320440649986
INFO:root:Epoch 2, Step 1000, loss: 0.09123893082141876, disc_loss: 0.0043900227174162865
INFO:root:Epoch 2, Step 1500, loss: 0.11656910181045532, disc_loss: 0.0005681101465597749
INFO:root:Epoch 2, Step 2000, loss: 0.10369417071342468, disc_loss: 0.009141392074525356
INFO:root:Epoch 2, Step 2500, loss: 0.09433319419622421, disc_loss: 0.010555301792919636
INFO:root:Generator loss: 0.07670289892884134, Discriminator loss: 0.006191651526659397
INFO:root:Epoch 3, Step 500, loss: 0.07365970313549042, disc_loss: 0.006222601514309645
INFO:root:Epoch 3, Step 1000, loss: 0.06640885770320892, disc_loss: 0.0024116504937410355
INFO:root:Epoch 3, Step 1500, loss: 0.09020954370498657, disc_loss: 0.004300054628401995
INFO:root:Epoch 3, Step 2000, loss: 0.07639354467391968, disc_loss: 0.005803040694445372
INFO:root:Epoch 3, Step 2500, loss: 0.07741605490446091, disc_loss: 0.004015754442662001
INFO:root:Generator loss: 0.07142463778552499, Discriminator loss: 0.010368012455269441
INFO:root:Epoch 4, Step 500, loss: 0.060868751257658005, disc_loss: 0.0021687853150069714
INFO:root:Epoch 4, Step 1000, loss: 0.09985975921154022, disc_loss: 0.006139358039945364
INFO:root:Epoch 4, Step 1500, loss: 0.10898585617542267, disc_loss: 0.0040971036069095135
INFO:root:Epoch 4, Step 2000, loss: 0.1016320288181305, disc_loss: 0.002804334042593837
INFO:root:Epoch 4, Step 2500, loss: 0.0728202760219574, disc_loss: 0.003187736263498664
INFO:root:Generator loss: 0.07222755926037297, Discriminator loss: 0.015440156168781348
INFO:root:Epoch 5, Step 500, loss: 0.10090957581996918, disc_loss: 0.006334209349006414
INFO:root:Epoch 5, Step 1000, loss: 0.11728094518184662, disc_loss: 0.004116943571716547
INFO:root:Epoch 5, Step 1500, loss: 0.1221829205751419, disc_loss: 0.001470357645303011
INFO:root:Epoch 5, Step 2000, loss: 0.06969467550516129, disc_loss: 0.0007349690422415733
INFO:root:Epoch 5, Step 2500, loss: 0.11609116196632385, disc_loss: 0.004671248607337475
INFO:root:Generator loss: 0.06995886896999137, Discriminator loss: 0.005806805914236745
INFO:root:Epoch 6, Step 500, loss: 0.10180829465389252, disc_loss: 0.004842774942517281
INFO:root:Epoch 6, Step 1000, loss: 0.09816021472215652, disc_loss: 0.004481836687773466
INFO:root:Epoch 6, Step 1500, loss: 0.09276551753282547, disc_loss: 0.004897504113614559
INFO:root:Epoch 6, Step 2000, loss: 0.11109812557697296, disc_loss: 0.00277158641256392
INFO:root:Epoch 6, Step 2500, loss: 0.07126130163669586, disc_loss: 0.00127068639267236
INFO:root:Generator loss: 0.06497617083086261, Discriminator loss: 0.0048501542152682075
INFO:root:Epoch 7, Step 500, loss: 0.09285751730203629, disc_loss: 0.0011580548016354442
INFO:root:Epoch 7, Step 1000, loss: 0.1535399854183197, disc_loss: 0.0024081929586827755
INFO:root:Epoch 7, Step 1500, loss: 0.08319114148616791, disc_loss: 0.00654654111713171
INFO:root:Epoch 7, Step 2000, loss: 0.07489345967769623, disc_loss: 0.0055369725450873375
INFO:root:Epoch 7, Step 2500, loss: 0.08028696477413177, disc_loss: 0.0005299233016557992
INFO:root:Generator loss: 0.06665655664954949, Discriminator loss: 0.00565129646152519
INFO:root:Epoch 8, Step 500, loss: 0.07689709216356277, disc_loss: 0.0015063300961628556
INFO:root:Epoch 8, Step 1000, loss: 0.07494530826807022, disc_loss: 0.03422035276889801
INFO:root:Epoch 8, Step 1500, loss: 0.11364007741212845, disc_loss: 0.002225864678621292
INFO:root:Epoch 8, Step 2000, loss: 0.13930003345012665, disc_loss: 0.002463958691805601
INFO:root:Epoch 8, Step 2500, loss: 0.09919270873069763, disc_loss: 0.0008190099033527076
INFO:root:Generator loss: 0.06433217828749742, Discriminator loss: 0.006032953253946916
INFO:root:Epoch 9, Step 500, loss: 0.11734487861394882, disc_loss: 0.0008789430721662939
INFO:root:Epoch 9, Step 1000, loss: 0.12954068183898926, disc_loss: 0.0023873017635196447
INFO:root:Epoch 9, Step 1500, loss: 0.0878683552145958, disc_loss: 0.001668525394052267
INFO:root:Epoch 9, Step 2000, loss: 0.11113062500953674, disc_loss: 0.0005191471427679062
INFO:root:Epoch 9, Step 2500, loss: 0.08340948820114136, disc_loss: 0.0006709936424158514
INFO:root:Generator loss: 0.06583876170000984, Discriminator loss: 0.00585944441086963
INFO:root:Epoch 10, Step 500, loss: 0.10216347873210907, disc_loss: 0.0034612338058650494
INFO:root:Epoch 10, Step 1000, loss: 0.14420641958713531, disc_loss: 0.002839592518284917
INFO:root:Epoch 10, Step 1500, loss: 0.09776674956083298, disc_loss: 0.0018755675991997123
INFO:root:Epoch 10, Step 2000, loss: 0.0745086520910263, disc_loss: 0.0024487022310495377
INFO:root:Epoch 10, Step 2500, loss: 0.09530128538608551, disc_loss: 0.0005701774498447776
INFO:root:Generator loss: 0.06351389343515762, Discriminator loss: 0.004621718930209381
INFO:root:Epoch 11, Step 500, loss: 0.05691125988960266, disc_loss: 0.0008552863146178424
INFO:root:Epoch 11, Step 1000, loss: 0.13863737881183624, disc_loss: 0.002572439145296812
INFO:root:Epoch 11, Step 1500, loss: 0.11717037111520767, disc_loss: 0.0027056559920310974
INFO:root:Epoch 11, Step 2000, loss: 0.1158040389418602, disc_loss: 0.0035712679382413626
INFO:root:Epoch 11, Step 2500, loss: 0.05569004267454147, disc_loss: 0.0025253458879888058
INFO:root:Generator loss: 0.06164404327610453, Discriminator loss: 0.005919514718345136
INFO:root:Epoch 12, Step 500, loss: 0.06726498156785965, disc_loss: 0.003968609031289816
INFO:root:Epoch 12, Step 1000, loss: 0.0734231024980545, disc_loss: 0.0024395305663347244
INFO:root:Epoch 12, Step 1500, loss: 0.08302213251590729, disc_loss: 0.0019772376399487257
INFO:root:Epoch 12, Step 2000, loss: 0.05160926282405853, disc_loss: 0.0006879607099108398
INFO:root:Epoch 12, Step 2500, loss: 0.1026030108332634, disc_loss: 0.0006691347807645798
INFO:root:Generator loss: 0.05931138237305347, Discriminator loss: 0.006761740140523083
INFO:root:Epoch 13, Step 500, loss: 0.0947132557630539, disc_loss: 0.0016229323809966445
INFO:root:Epoch 13, Step 1000, loss: 0.0697564035654068, disc_loss: 0.002502958755940199
INFO:root:Epoch 13, Step 1500, loss: 0.07294803857803345, disc_loss: 0.0022550595458596945
INFO:root:Epoch 13, Step 2000, loss: 0.05482431873679161, disc_loss: 0.0008615636033937335
INFO:root:Epoch 13, Step 2500, loss: 0.09053369611501694, disc_loss: 0.001169466064311564
INFO:root:Generator loss: 0.05962528376975684, Discriminator loss: 0.006257189386744658
INFO:root:Epoch 14, Step 500, loss: 0.07108443230390549, disc_loss: 0.0022185416892170906
INFO:root:Epoch 14, Step 1000, loss: 0.08866633474826813, disc_loss: 0.000496160238981247
INFO:root:Epoch 14, Step 1500, loss: 0.09995649755001068, disc_loss: 0.0018282296368852258
INFO:root:Epoch 14, Step 2000, loss: 0.07946578413248062, disc_loss: 0.0007886941893957555
INFO:root:Epoch 14, Step 2500, loss: 0.06006031110882759, disc_loss: 0.0006916193524375558
INFO:root:Generator loss: 0.060670767033707745, Discriminator loss: 0.005573372571834802
INFO:root:Epoch 15, Step 500, loss: 0.07346697151660919, disc_loss: 0.002136718016117811
INFO:root:Epoch 15, Step 1000, loss: 0.07433722913265228, disc_loss: 0.0009708767756819725
INFO:root:Epoch 15, Step 1500, loss: 0.10258808732032776, disc_loss: 0.0007809172966517508
INFO:root:Epoch 15, Step 2000, loss: 0.06136716902256012, disc_loss: 0.0018919012509286404
INFO:root:Epoch 15, Step 2500, loss: 0.08703448623418808, disc_loss: 0.001771276700310409
INFO:root:Generator loss: 0.05867863306323591, Discriminator loss: 0.004422428349888595
INFO:root:Epoch 16, Step 500, loss: 0.09431303292512894, disc_loss: 0.008639855310320854
INFO:root:Epoch 16, Step 1000, loss: 0.11318263411521912, disc_loss: 0.0024837993551045656
INFO:root:Epoch 16, Step 1500, loss: 0.06780723482370377, disc_loss: 0.005243928637355566
INFO:root:Epoch 16, Step 2000, loss: 0.10205914825201035, disc_loss: 0.0006751047912985086
INFO:root:Epoch 16, Step 2500, loss: 0.07760203629732132, disc_loss: 0.002433250891044736
INFO:root:Generator loss: 0.05909035602602565, Discriminator loss: 0.008108877721417794
INFO:root:Epoch 17, Step 500, loss: 0.07118359208106995, disc_loss: 0.001018726616166532
INFO:root:Epoch 17, Step 1000, loss: 0.07049266993999481, disc_loss: 0.0003276981005910784
INFO:root:Epoch 17, Step 1500, loss: 0.07907910645008087, disc_loss: 0.0020139559637755156
INFO:root:Epoch 17, Step 2000, loss: 0.09613337367773056, disc_loss: 0.0008353170705959201
INFO:root:Epoch 17, Step 2500, loss: 0.0768222063779831, disc_loss: 0.0010305355535820127
INFO:root:Generator loss: 0.058413155394995094, Discriminator loss: 0.003934068052472267
INFO:root:Epoch 18, Step 500, loss: 0.10066744685173035, disc_loss: 0.0026463267859071493
INFO:root:Epoch 18, Step 1000, loss: 0.09346140921115875, disc_loss: 0.0034462616313248873
INFO:root:Epoch 18, Step 1500, loss: 0.04582483321428299, disc_loss: 0.0015749539015814662
INFO:root:Epoch 18, Step 2000, loss: 0.04998571053147316, disc_loss: 0.0011739658657461405
INFO:root:Epoch 18, Step 2500, loss: 0.07974780350923538, disc_loss: 0.0030303653329610825
INFO:root:Generator loss: 0.05845420570700493, Discriminator loss: 0.0036333091885503606
INFO:root:Epoch 19, Step 500, loss: 0.04600243642926216, disc_loss: 0.0005097786197438836
INFO:root:Epoch 19, Step 1000, loss: 0.07044699788093567, disc_loss: 0.0026674733962863684
INFO:root:Epoch 19, Step 1500, loss: 0.06875679641962051, disc_loss: 0.0013812422985211015
INFO:root:Epoch 19, Step 2000, loss: 0.06469395011663437, disc_loss: 0.0024428695905953646
INFO:root:Epoch 19, Step 2500, loss: 0.06773768365383148, disc_loss: 0.0008332555880770087
INFO:root:Generator loss: 0.05947085635429158, Discriminator loss: 0.00427683226279468
INFO:root:Epoch 20, Step 500, loss: 0.06281574070453644, disc_loss: 0.0024620299227535725
INFO:root:Epoch 20, Step 1000, loss: 0.11284735798835754, disc_loss: 0.0006138571770861745
INFO:root:Epoch 20, Step 1500, loss: 0.08344040811061859, disc_loss: 0.001956441206857562
INFO:root:Epoch 20, Step 2000, loss: 0.10634761303663254, disc_loss: 0.002102266065776348
INFO:root:Epoch 20, Step 2500, loss: 0.05351988226175308, disc_loss: 0.0009122418123297393
INFO:root:Generator loss: 0.0591274989425268, Discriminator loss: 0.0045599001169798654
INFO:root:Epoch 21, Step 500, loss: 0.0772707536816597, disc_loss: 0.0006975987926125526
INFO:root:Epoch 21, Step 1000, loss: 0.07880093157291412, disc_loss: 0.0005949294427409768
INFO:root:Epoch 21, Step 1500, loss: 0.08514974266290665, disc_loss: 0.0021075746044516563
INFO:root:Epoch 21, Step 2000, loss: 0.07340500503778458, disc_loss: 0.0005475725047290325
INFO:root:Epoch 21, Step 2500, loss: 0.10773739963769913, disc_loss: 0.0013337002601474524
INFO:root:Generator loss: 0.057524177860649464, Discriminator loss: 0.005554134700538023
INFO:root:Epoch 22, Step 500, loss: 0.06218436732888222, disc_loss: 0.000834885926451534
INFO:root:Epoch 22, Step 1000, loss: 0.06931599974632263, disc_loss: 0.0033642638009041548
INFO:root:Epoch 22, Step 1500, loss: 0.10372631251811981, disc_loss: 0.0017932786140590906
INFO:root:Epoch 22, Step 2000, loss: 0.06867785006761551, disc_loss: 0.0014653434045612812
INFO:root:Epoch 22, Step 2500, loss: 0.10683505237102509, disc_loss: 0.006068812217563391
INFO:root:Generator loss: 0.058897983626399225, Discriminator loss: 0.004821412047022022
INFO:root:Epoch 23, Step 500, loss: 0.06283705681562424, disc_loss: 0.00038638440310023725
INFO:root:Epoch 23, Step 1000, loss: 0.10053528100252151, disc_loss: 0.0007793242111802101
INFO:root:Epoch 23, Step 1500, loss: 0.07479502260684967, disc_loss: 0.00207327539101243
INFO:root:Epoch 23, Step 2000, loss: 0.0480530820786953, disc_loss: 0.0010863876668736339
INFO:root:Epoch 23, Step 2500, loss: 0.061389900743961334, disc_loss: 0.0025548236444592476
INFO:root:Generator loss: 0.06023731938952092, Discriminator loss: 0.005616193439070309
INFO:root:Epoch 24, Step 500, loss: 0.06298616528511047, disc_loss: 0.0018069627694785595
INFO:root:Epoch 24, Step 1000, loss: 0.06775111705064774, disc_loss: 0.0008139156852848828
INFO:root:Epoch 24, Step 1500, loss: 0.08057140558958054, disc_loss: 0.0016064861556515098
INFO:root:Epoch 24, Step 2000, loss: 0.06332913786172867, disc_loss: 5.399339715950191e-05
INFO:root:Epoch 24, Step 2500, loss: 0.09019947797060013, disc_loss: 0.0008735202136449516
INFO:root:Generator loss: 0.05748120162780713, Discriminator loss: 0.00403556118382184
INFO:root:Epoch 25, Step 500, loss: 0.09127967059612274, disc_loss: 0.0048397802747786045
INFO:root:Epoch 25, Step 1000, loss: 0.05418021231889725, disc_loss: 0.0006964401109144092
INFO:root:Epoch 25, Step 1500, loss: 0.06859208643436432, disc_loss: 0.0003860244760289788
INFO:root:Epoch 25, Step 2000, loss: 0.07583077996969223, disc_loss: 0.0002258227759739384
INFO:root:Epoch 25, Step 2500, loss: 0.09074307233095169, disc_loss: 0.001950979814864695
INFO:root:Generator loss: 0.05799985157090773, Discriminator loss: 0.002924424191714757
INFO:root:Epoch 26, Step 500, loss: 0.10732904076576233, disc_loss: 0.003988661337643862
INFO:root:Epoch 26, Step 1000, loss: 0.08182456344366074, disc_loss: 0.0007081814110279083
INFO:root:Epoch 26, Step 1500, loss: 0.10926764458417892, disc_loss: 0.0012069221120327711
INFO:root:Epoch 26, Step 2000, loss: 0.06650825589895248, disc_loss: 0.0018488921923562884
INFO:root:Epoch 26, Step 2500, loss: 0.12603935599327087, disc_loss: 0.00032415727037005126
INFO:root:Generator loss: 0.05707774934295601, Discriminator loss: 0.0040518964284556825
INFO:root:Epoch 27, Step 500, loss: 0.05546482652425766, disc_loss: 0.0009002723381854594
INFO:root:Epoch 27, Step 1000, loss: 0.09822066873311996, disc_loss: 0.0004915976896882057
INFO:root:Epoch 27, Step 1500, loss: 0.06322389096021652, disc_loss: 0.001507564214989543
INFO:root:Epoch 27, Step 2000, loss: 0.07355480641126633, disc_loss: 0.0012325242860242724
INFO:root:Epoch 27, Step 2500, loss: 0.07246123999357224, disc_loss: 0.0017789591802284122
INFO:root:Generator loss: 0.05749568386563977, Discriminator loss: 0.005970720770562269
INFO:root:Epoch 28, Step 500, loss: 0.0732610747218132, disc_loss: 0.00018431757052894682
INFO:root:Epoch 28, Step 1000, loss: 0.0925661250948906, disc_loss: 0.00035287541686557233
INFO:root:Epoch 28, Step 1500, loss: 0.06857156753540039, disc_loss: 0.0027448111213743687
INFO:root:Epoch 28, Step 2000, loss: 0.06176270917057991, disc_loss: 0.000916399119887501
INFO:root:Epoch 28, Step 2500, loss: 0.09946085512638092, disc_loss: 0.0016790135996416211
INFO:root:Generator loss: 0.05697140197983934, Discriminator loss: 0.003935662437708866
INFO:root:Epoch 29, Step 500, loss: 0.08036457747220993, disc_loss: 0.00181618332862854
INFO:root:Epoch 29, Step 1000, loss: 0.08410156518220901, disc_loss: 0.001275302143767476
INFO:root:Epoch 29, Step 1500, loss: 0.06379825621843338, disc_loss: 0.0008126177708618343
INFO:root:Epoch 29, Step 2000, loss: 0.05573512613773346, disc_loss: 0.005338369868695736
INFO:root:Epoch 29, Step 2500, loss: 0.05019616335630417, disc_loss: 0.0011705142678692937
INFO:root:Generator loss: 0.05751500050853757, Discriminator loss: 0.0040660404156016424
INFO:root:Epoch 30, Step 500, loss: 0.05376867577433586, disc_loss: 0.00117009156383574
INFO:root:Epoch 30, Step 1000, loss: 0.09846365451812744, disc_loss: 0.00306608690880239
INFO:root:Epoch 30, Step 1500, loss: 0.06315276026725769, disc_loss: 0.0008335723541676998
INFO:root:Epoch 30, Step 2000, loss: 0.09315390884876251, disc_loss: 0.0018219887278974056
INFO:root:Epoch 30, Step 2500, loss: 0.1029881089925766, disc_loss: 0.0013572665629908442
INFO:root:Generator loss: 0.05685839911434546, Discriminator loss: 0.004857568502876409
INFO:root:Epoch 31, Step 500, loss: 0.08629101514816284, disc_loss: 0.00035455013858154416
INFO:root:Epoch 31, Step 1000, loss: 0.083938367664814, disc_loss: 0.0017113086069002748
INFO:root:Epoch 31, Step 1500, loss: 0.0714401826262474, disc_loss: 0.0011296052252873778
INFO:root:Epoch 31, Step 2000, loss: 0.06304112821817398, disc_loss: 0.0015342846745625138
INFO:root:Epoch 31, Step 2500, loss: 0.04653649032115936, disc_loss: 0.0009484769543632865
INFO:root:Generator loss: 0.057079349762027706, Discriminator loss: 0.0043850391602355005
INFO:root:Epoch 32, Step 500, loss: 0.056937407702207565, disc_loss: 0.001375528983771801
INFO:root:Epoch 32, Step 1000, loss: 0.057657383382320404, disc_loss: 0.0022340051364153624
INFO:root:Epoch 32, Step 1500, loss: 0.06563665717840195, disc_loss: 0.0016831581015139818
INFO:root:Epoch 32, Step 2000, loss: 0.08487944304943085, disc_loss: 0.0026076810900121927
INFO:root:Epoch 32, Step 2500, loss: 0.08937281370162964, disc_loss: 0.0010753157548606396
INFO:root:Generator loss: 0.056729333601819656, Discriminator loss: 0.004037251811116698
INFO:root:Epoch 33, Step 500, loss: 0.07655515521764755, disc_loss: 0.0014207226922735572
INFO:root:Epoch 33, Step 1000, loss: 0.08598204702138901, disc_loss: 0.0013206514995545149
INFO:root:Epoch 33, Step 1500, loss: 0.06325193494558334, disc_loss: 0.0006238833302631974
INFO:root:Epoch 33, Step 2000, loss: 0.07095114141702652, disc_loss: 0.0013164682313799858
INFO:root:Epoch 33, Step 2500, loss: 0.08121106773614883, disc_loss: 0.00047971756430342793
INFO:root:Generator loss: 0.05749568890201524, Discriminator loss: 0.004621518596932837
INFO:root:Epoch 34, Step 500, loss: 0.10008329898118973, disc_loss: 0.0004465894598979503
INFO:root:Epoch 34, Step 1000, loss: 0.056686773896217346, disc_loss: 0.0005249321693554521
INFO:root:Epoch 34, Step 1500, loss: 0.07318797707557678, disc_loss: 0.0008264807984232903
INFO:root:Epoch 34, Step 2000, loss: 0.06267644464969635, disc_loss: 0.0012368307216092944
INFO:root:Epoch 34, Step 2500, loss: 0.05671964958310127, disc_loss: 0.05815936252474785
INFO:root:Generator loss: 0.05789120074867913, Discriminator loss: 0.004178101749787247
INFO:root:Epoch 35, Step 500, loss: 0.054831575602293015, disc_loss: 0.0010935552418231964
INFO:root:Epoch 35, Step 1000, loss: 0.07581688463687897, disc_loss: 0.0032463616225868464
INFO:root:Epoch 35, Step 1500, loss: 0.07154862582683563, disc_loss: 0.0011522360146045685
INFO:root:Epoch 35, Step 2000, loss: 0.09091994911432266, disc_loss: 0.0018670448334887624
INFO:root:Epoch 35, Step 2500, loss: 0.09395437687635422, disc_loss: 0.0007727313786745071
INFO:root:Generator loss: 0.05723093444644248, Discriminator loss: 0.004214044286006523
INFO:root:Epoch 36, Step 500, loss: 0.0751689150929451, disc_loss: 0.002655328018590808
INFO:root:Epoch 36, Step 1000, loss: 0.08940586447715759, disc_loss: 0.0028241360560059547
INFO:root:Epoch 36, Step 1500, loss: 0.08226495236158371, disc_loss: 0.0005964005249552429
INFO:root:Epoch 36, Step 2000, loss: 0.09321226924657822, disc_loss: 0.0013904174556955695
INFO:root:Epoch 36, Step 2500, loss: 0.06077786907553673, disc_loss: 0.00144778355024755
INFO:root:Generator loss: 0.05685391929904813, Discriminator loss: 0.004325323634245772
INFO:root:Epoch 37, Step 500, loss: 0.05229634419083595, disc_loss: 0.0022845081984996796
INFO:root:Epoch 37, Step 1000, loss: 0.0867263600230217, disc_loss: 0.0013340337900444865
INFO:root:Epoch 37, Step 1500, loss: 0.07060778886079788, disc_loss: 0.0011254744604229927
INFO:root:Epoch 37, Step 2000, loss: 0.06545994430780411, disc_loss: 7.226406887639314e-05
INFO:root:Epoch 37, Step 2500, loss: 0.06626259535551071, disc_loss: 0.0010269558988511562
INFO:root:Generator loss: 0.05672286883068895, Discriminator loss: 0.003502178935942865
INFO:root:Epoch 38, Step 500, loss: 0.05491106957197189, disc_loss: 0.002561417408287525
INFO:root:Epoch 38, Step 1000, loss: 0.07582257688045502, disc_loss: 0.0011219168081879616
INFO:root:Epoch 38, Step 1500, loss: 0.09359344840049744, disc_loss: 0.002579492749646306
INFO:root:Epoch 38, Step 2000, loss: 0.047862134873867035, disc_loss: 0.0007389222737401724
INFO:root:Epoch 38, Step 2500, loss: 0.06772506982088089, disc_loss: 0.0008614654070697725
INFO:root:Generator loss: 0.05733635917631457, Discriminator loss: 0.00435076622635429
INFO:root:Epoch 39, Step 500, loss: 0.05945456400513649, disc_loss: 0.0008183164754882455
INFO:root:Epoch 39, Step 1000, loss: 0.07141486555337906, disc_loss: 0.0020580003038048744
INFO:root:Epoch 39, Step 1500, loss: 0.06560717523097992, disc_loss: 0.0005259314784780145
INFO:root:Epoch 39, Step 2000, loss: 0.0599815808236599, disc_loss: 0.0013601670507341623
INFO:root:Epoch 39, Step 2500, loss: 0.056402310729026794, disc_loss: 0.0008746705134399235
INFO:root:Generator loss: 0.056215531382601235, Discriminator loss: 0.003920179965523822
INFO:root:Epoch 40, Step 500, loss: 0.0625813752412796, disc_loss: 0.001525794854387641
INFO:root:Epoch 40, Step 1000, loss: 0.069739930331707, disc_loss: 0.0029925997368991375
INFO:root:Epoch 40, Step 1500, loss: 0.06290390342473984, disc_loss: 0.0009289716253988445
INFO:root:Epoch 40, Step 2000, loss: 0.04725237935781479, disc_loss: 0.0038355428259819746
INFO:root:Epoch 40, Step 2500, loss: 0.10308806598186493, disc_loss: 0.0007996350177563727
INFO:root:Generator loss: 0.055763543357403536, Discriminator loss: 0.00473100360334869
INFO:root:Epoch 41, Step 500, loss: 0.06194192171096802, disc_loss: 0.0013559822691604495
INFO:root:Epoch 41, Step 1000, loss: 0.06235095486044884, disc_loss: 0.0013597896322607994
INFO:root:Epoch 41, Step 1500, loss: 0.08103148639202118, disc_loss: 0.001762984087690711
INFO:root:Epoch 41, Step 2000, loss: 0.05545410141348839, disc_loss: 0.0011309031397104263
INFO:root:Epoch 41, Step 2500, loss: 0.07615933567285538, disc_loss: 0.002402649959549308
INFO:root:Generator loss: 0.05717485036375453, Discriminator loss: 0.004708863168417841
INFO:root:Epoch 42, Step 500, loss: 0.06979230791330338, disc_loss: 0.0012329552555456758
INFO:root:Epoch 42, Step 1000, loss: 0.058289725333452225, disc_loss: 0.0006983319181017578
INFO:root:Epoch 42, Step 1500, loss: 0.07959557324647903, disc_loss: 0.0017395312897861004
INFO:root:Epoch 42, Step 2000, loss: 0.10258404165506363, disc_loss: 0.0014910864410921931
INFO:root:Epoch 42, Step 2500, loss: 0.040548015385866165, disc_loss: 0.0017057897057384253
INFO:root:Generator loss: 0.056838626394645105, Discriminator loss: 0.005500088343625658
INFO:root:Epoch 43, Step 500, loss: 0.06674187630414963, disc_loss: 0.0011735564330592752
INFO:root:Epoch 43, Step 1000, loss: 0.10310903936624527, disc_loss: 0.003072185441851616
INFO:root:Epoch 43, Step 1500, loss: 0.053080733865499496, disc_loss: 0.0009342433768324554
INFO:root:Epoch 43, Step 2000, loss: 0.07557825744152069, disc_loss: 0.004602281376719475
INFO:root:Epoch 43, Step 2500, loss: 0.0691903680562973, disc_loss: 0.0033530076034367085
INFO:root:Generator loss: 0.05671847288867513, Discriminator loss: 0.004491256010403305
INFO:root:Epoch 44, Step 500, loss: 0.07008543610572815, disc_loss: 0.0018194759031757712
INFO:root:Epoch 44, Step 1000, loss: 0.05988248810172081, disc_loss: 0.0011200510198250413
INFO:root:Epoch 44, Step 1500, loss: 0.08773816376924515, disc_loss: 0.0012394291115924716
INFO:root:Epoch 44, Step 2000, loss: 0.07643090188503265, disc_loss: 0.001213931362144649
INFO:root:Epoch 44, Step 2500, loss: 0.07629512250423431, disc_loss: 0.0006610160926356912
INFO:root:Generator loss: 0.05656162449565617, Discriminator loss: 0.003180267256715683
INFO:root:Epoch 45, Step 500, loss: 0.05791060999035835, disc_loss: 0.0009231168078258634
INFO:root:Epoch 45, Step 1000, loss: 0.06183471530675888, disc_loss: 0.0020496805664151907
INFO:root:Epoch 45, Step 1500, loss: 0.07695623487234116, disc_loss: 0.0012226662365719676
INFO:root:Epoch 45, Step 2000, loss: 0.10171087831258774, disc_loss: 0.004032885190099478
INFO:root:Epoch 45, Step 2500, loss: 0.10405146330595016, disc_loss: 0.0006224465323612094
INFO:root:Generator loss: 0.05710308996110576, Discriminator loss: 0.006055929171743982
INFO:root:Epoch 46, Step 500, loss: 0.08919573575258255, disc_loss: 0.0010434385621920228
INFO:root:Epoch 46, Step 1000, loss: 0.040715306997299194, disc_loss: 0.002078397199511528
INFO:root:Epoch 46, Step 1500, loss: 0.07055211067199707, disc_loss: 0.0011394984321668744
INFO:root:Epoch 46, Step 2000, loss: 0.0732177123427391, disc_loss: 0.0005147946649231017
INFO:root:Epoch 46, Step 2500, loss: 0.05483756214380264, disc_loss: 0.0004112280730623752
INFO:root:Generator loss: 0.057239413948603046, Discriminator loss: 0.004536685380099318
INFO:root:Epoch 47, Step 500, loss: 0.08909726142883301, disc_loss: 0.014064429327845573
INFO:root:Epoch 47, Step 1000, loss: 0.07524335384368896, disc_loss: 0.0003897806163877249
INFO:root:Epoch 47, Step 1500, loss: 0.06060535088181496, disc_loss: 0.00015396910021081567
INFO:root:Epoch 47, Step 2000, loss: 0.0896846204996109, disc_loss: 0.001823695725761354
INFO:root:Epoch 47, Step 2500, loss: 0.08876094967126846, disc_loss: 0.00045277722529135644
INFO:root:Generator loss: 0.05637026167682652, Discriminator loss: 0.003909279049252096
INFO:root:Epoch 48, Step 500, loss: 0.04895953834056854, disc_loss: 0.0022687078453600407
INFO:root:Epoch 48, Step 1000, loss: 0.061605729162693024, disc_loss: 0.0008926999871619046
INFO:root:Epoch 48, Step 1500, loss: 0.08490318804979324, disc_loss: 0.050627902150154114
INFO:root:Epoch 48, Step 2000, loss: 0.07021968066692352, disc_loss: 0.0018788048764690757
INFO:root:Epoch 48, Step 2500, loss: 0.06784085929393768, disc_loss: 0.0005965933087281883
INFO:root:Generator loss: 0.05574769014944729, Discriminator loss: 0.004357616430328544
INFO:root:Epoch 49, Step 500, loss: 0.0844813659787178, disc_loss: 0.0010956767946481705
INFO:root:Epoch 49, Step 1000, loss: 0.06554991006851196, disc_loss: 0.000693436770234257
INFO:root:Epoch 49, Step 1500, loss: 0.06750095635652542, disc_loss: 0.00027760659577324986
INFO:root:Epoch 49, Step 2000, loss: 0.08693937212228775, disc_loss: 0.0019862698391079903
INFO:root:Epoch 49, Step 2500, loss: 0.06747037172317505, disc_loss: 0.00016455996956210583
INFO:root:Generator loss: 0.05625908443867003, Discriminator loss: 0.004037537953019673
INFO:root:Epoch 50, Step 500, loss: 0.08428975194692612, disc_loss: 0.0034135086461901665
INFO:root:Epoch 50, Step 1000, loss: 0.07070793211460114, disc_loss: 0.0004292188386898488
INFO:root:Epoch 50, Step 1500, loss: 0.055500578135252, disc_loss: 0.0007230055052787066
INFO:root:Epoch 50, Step 2000, loss: 0.06954862922430038, disc_loss: 0.000303491426166147
INFO:root:Epoch 50, Step 2500, loss: 0.0904846116900444, disc_loss: 0.0028916301671415567
INFO:root:Generator loss: 0.05656072569703593, Discriminator loss: 0.005402216533378662
INFO:root:Epoch 51, Step 500, loss: 0.13698159158229828, disc_loss: 0.0006543039926327765
INFO:root:Epoch 51, Step 1000, loss: 0.046117331832647324, disc_loss: 0.0003706526185851544
INFO:root:Epoch 51, Step 1500, loss: 0.06343231350183487, disc_loss: 5.2783092542085797e-05
INFO:root:Epoch 51, Step 2000, loss: 0.09569181501865387, disc_loss: 0.001003200188279152
INFO:root:Epoch 51, Step 2500, loss: 0.061209194362163544, disc_loss: 0.0005420197849161923
INFO:root:Generator loss: 0.05641240880652828, Discriminator loss: 0.004217182571046932
INFO:root:Epoch 52, Step 500, loss: 0.05075540766119957, disc_loss: 0.0009896625997498631
INFO:root:Epoch 52, Step 1000, loss: 0.06435218453407288, disc_loss: 0.0010384581983089447
INFO:root:Epoch 52, Step 1500, loss: 0.07390189170837402, disc_loss: 0.003443030407652259
INFO:root:Epoch 52, Step 2000, loss: 0.08416915684938431, disc_loss: 0.00046997726894915104
INFO:root:Epoch 52, Step 2500, loss: 0.06219618767499924, disc_loss: 0.0016301277792081237
INFO:root:Generator loss: 0.05668417317340675, Discriminator loss: 0.004198875761838422
INFO:root:Epoch 53, Step 500, loss: 0.08889388293027878, disc_loss: 0.002101027173921466
INFO:root:Epoch 53, Step 1000, loss: 0.1029309332370758, disc_loss: 0.003981864079833031
INFO:root:Epoch 53, Step 1500, loss: 0.08297201991081238, disc_loss: 0.0005388588178902864
INFO:root:Epoch 53, Step 2000, loss: 0.06845375895500183, disc_loss: 0.0006309348973445594
INFO:root:Epoch 53, Step 2500, loss: 0.08395140618085861, disc_loss: 0.0010036894818767905
INFO:root:Generator loss: 0.05656955619930353, Discriminator loss: 0.0048586555818226915
INFO:root:Epoch 54, Step 500, loss: 0.08178799599409103, disc_loss: 0.00043749509495683014
INFO:root:Epoch 54, Step 1000, loss: 0.0840129628777504, disc_loss: 0.0010134481126442552
INFO:root:Epoch 54, Step 1500, loss: 0.08727501332759857, disc_loss: 0.00047579361125826836
INFO:root:Epoch 54, Step 2000, loss: 0.05088311806321144, disc_loss: 0.0003529624955262989
INFO:root:Epoch 54, Step 2500, loss: 0.07873211055994034, disc_loss: 0.00038665597094222903
INFO:root:Generator loss: 0.05627268690218046, Discriminator loss: 0.004406627029152553
INFO:root:Epoch 55, Step 500, loss: 0.05507051572203636, disc_loss: 0.005183336324989796
INFO:root:Epoch 55, Step 1000, loss: 0.06789188086986542, disc_loss: 0.00019709767366293818
INFO:root:Epoch 55, Step 1500, loss: 0.06391659379005432, disc_loss: 0.0007532972958870232
INFO:root:Epoch 55, Step 2000, loss: 0.047019898891448975, disc_loss: 0.0005374279571697116
INFO:root:Epoch 55, Step 2500, loss: 0.08593488484621048, disc_loss: 0.0008742962381802499
INFO:root:Generator loss: 0.0560285118182452, Discriminator loss: 0.004831194736555702
INFO:root:Epoch 56, Step 500, loss: 0.06734950840473175, disc_loss: 0.000279007013887167
INFO:root:Epoch 56, Step 1000, loss: 0.09986555576324463, disc_loss: 0.0014408589340746403
INFO:root:Epoch 56, Step 1500, loss: 0.0776502937078476, disc_loss: 0.0006958802114240825
INFO:root:Epoch 56, Step 2000, loss: 0.0953034833073616, disc_loss: 0.00031419427250511944
INFO:root:Epoch 56, Step 2500, loss: 0.04411564767360687, disc_loss: 0.0022977618500590324
INFO:root:Generator loss: 0.05617274787928005, Discriminator loss: 0.005908752329886941
INFO:root:Epoch 57, Step 500, loss: 0.06664083153009415, disc_loss: 0.0008286831434816122
INFO:root:Epoch 57, Step 1000, loss: 0.08869306743144989, disc_loss: 0.00017637932614888996
INFO:root:Epoch 57, Step 1500, loss: 0.12747439742088318, disc_loss: 0.0008649026276543736
INFO:root:Epoch 57, Step 2000, loss: 0.08469129353761673, disc_loss: 0.001461848965846002
INFO:root:Epoch 57, Step 2500, loss: 0.08746517449617386, disc_loss: 0.0003413125523366034
INFO:root:Generator loss: 0.05642671815291481, Discriminator loss: 0.003630681674824974
INFO:root:Epoch 58, Step 500, loss: 0.069893978536129, disc_loss: 0.0006308610900305212
INFO:root:Epoch 58, Step 1000, loss: 0.07054699957370758, disc_loss: 0.0009745495044626296
INFO:root:Epoch 58, Step 1500, loss: 0.07065755128860474, disc_loss: 0.0014457587385550141
INFO:root:Epoch 58, Step 2000, loss: 0.09841804206371307, disc_loss: 0.0011754394508898258
INFO:root:Epoch 58, Step 2500, loss: 0.07007145881652832, disc_loss: 0.0009704254916869104
INFO:root:Generator loss: 0.05684903284842239, Discriminator loss: 0.004762952081752868
INFO:root:Epoch 59, Step 500, loss: 0.047717053443193436, disc_loss: 0.0015287387650460005
INFO:root:Epoch 59, Step 1000, loss: 0.1217607706785202, disc_loss: 0.0010343882022425532
INFO:root:Epoch 59, Step 1500, loss: 0.07266448438167572, disc_loss: 0.0002804030664265156
INFO:root:Epoch 59, Step 2000, loss: 0.1106356531381607, disc_loss: 0.0013393991393968463
INFO:root:Epoch 59, Step 2500, loss: 0.08187257498502731, disc_loss: 0.0013885837979614735
INFO:root:Generator loss: 0.05641391760335096, Discriminator loss: 0.005259976401698755
Training finished.
Starting batch evaluation...
Evaluating: CMGAN_epoch_0_0.082
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.8114450119652794 csig:  4.313488471881281 cbak:  3.4733157672034833 covl:  3.619558575270314 ssnr:  8.420739228869277 stoi:  0.9385982615195235


Evaluating: CMGAN_epoch_10_0.063
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.29098763295169 csig:  4.530027255257562 cbak:  3.789562289386638 covl:  3.997683524135018 ssnr:  9.630127064949821 stoi:  0.9501190442530788


Evaluating: CMGAN_epoch_1_0.076
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.856269124642159 csig:  4.341162557913246 cbak:  3.528919367975354 covl:  3.6554488556937033 ssnr:  8.896345625604166 stoi:  0.9438154679711767


Evaluating: CMGAN_epoch_11_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.228982684247702 csig:  4.5096145797071845 cbak:  3.795470859776173 covl:  3.953185174210027 ssnr:  10.200985868693333 stoi:  0.9531078590592161


Evaluating: CMGAN_epoch_12_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.239756253593176 csig:  4.542650450313508 cbak:  3.817072195999147 covl:  3.9751408507715973 ssnr:  10.45940892534664 stoi:  0.9538489271849887


Evaluating: CMGAN_epoch_13_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2429733393551077 csig:  4.542373078396083 cbak:  3.810399790210619 covl:  3.976548561744582 ssnr:  10.313513007640067 stoi:  0.9542988840898953


Evaluating: CMGAN_epoch_14_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2928417973148014 csig:  4.531546821993318 cbak:  3.8263391650355447 covl:  3.999692962297957 ssnr:  10.19965991246564 stoi:  0.9545305815435844


Evaluating: CMGAN_epoch_15_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3091436147111133 csig:  4.53559104204154 cbak:  3.8545051595364273 covl:  4.012556018033878 ssnr:  10.519580023788702 stoi:  0.9548609906727348


Evaluating: CMGAN_epoch_16_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1951614211774566 csig:  4.545663748235213 cbak:  3.7942663888240675 covl:  3.949997589235176 ssnr:  10.424921837177791 stoi:  0.9554153230488793


Evaluating: CMGAN_epoch_17_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3004167702012848 csig:  4.564145764036715 cbak:  3.8493552031843783 covl:  4.021518068678139 ssnr:  10.491549577052313 stoi:  0.955006501698527


Evaluating: CMGAN_epoch_18_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3299188922041827 csig:  4.579667049367159 cbak:  3.868940366573374 covl:  4.043242483789366 ssnr:  10.592023625966467 stoi:  0.9550065848926294


Evaluating: CMGAN_epoch_19_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3298261535977853 csig:  4.55069018653029 cbak:  3.834559116881848 covl:  4.030298407008053 ssnr:  10.048075044805929 stoi:  0.9530134731722779


Evaluating: CMGAN_epoch_20_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3492418494328713 csig:  4.579864989010926 cbak:  3.8391606025377754 covl:  4.055915053881826 ssnr:  9.95528108519453 stoi:  0.9549357938500455


Evaluating: CMGAN_epoch_2_0.076
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.940748992764834 csig:  4.409312293123513 cbak:  3.566579886176314 covl:  3.7395693619818977 ssnr:  8.845449626503266 stoi:  0.9461576612180678


Evaluating: CMGAN_epoch_21_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.367201399166607 csig:  4.569776509246425 cbak:  3.874380689529314 covl:  4.06162917175932 ssnr:  10.414869064612105 stoi:  0.9547357463604685


Evaluating: CMGAN_epoch_22_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2637079003655796 csig:  4.568387419266741 cbak:  3.8150626974918707 covl:  3.9973653914341365 ssnr:  10.239362488361593 stoi:  0.955463319367899


Evaluating: CMGAN_epoch_23_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.255568738701274 csig:  4.502879128378512 cbak:  3.811014878727091 covl:  3.9597828184228527 ssnr:  10.242228055532618 stoi:  0.9553915054428612


Evaluating: CMGAN_epoch_24_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.333432064907065 csig:  4.5628667245382015 cbak:  3.8594305320769777 covl:  4.037882891775806 ssnr:  10.394685547392644 stoi:  0.9562832115832616


Evaluating: CMGAN_epoch_25_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3696504952838118 csig:  4.612651200044632 cbak:  3.878821204396079 covl:  4.08823343249546 ssnr:  10.45036462225749 stoi:  0.9555181843066026


Evaluating: CMGAN_epoch_26_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.345609064385729 csig:  4.588313747802016 cbak:  3.875612472507653 covl:  4.060787781051812 ssnr:  10.562856198081539 stoi:  0.9548624872438886


Evaluating: CMGAN_epoch_27_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.359133492685059 csig:  4.594960985712415 cbak:  3.8704943137873142 covl:  4.073790576831678 ssnr:  10.381834048337478 stoi:  0.9553995072799042


Evaluating: CMGAN_epoch_28_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3690902354937156 csig:  4.602699386337493 cbak:  3.8915821766939613 covl:  4.084618570085019 ssnr:  10.629220363985175 stoi:  0.9555506445867463


Evaluating: CMGAN_epoch_29_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.343696300699873 csig:  4.591232407301219 cbak:  3.876977436614564 covl:  4.061760337939878 ssnr:  10.613391103851663 stoi:  0.9559600060900034


Evaluating: CMGAN_epoch_30_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.373530538481416 csig:  4.5960270170512 cbak:  3.8903791748695715 covl:  4.082976529970963 ssnr:  10.591713925012849 stoi:  0.9551614093596623


Evaluating: CMGAN_epoch_3_0.071
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.9703219409995865 csig:  4.443077190371736 cbak:  3.5927918855284293 covl:  3.7761720469403994 ssnr:  9.01622018948274 stoi:  0.9471842185359144


Evaluating: CMGAN_epoch_31_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.390851000703654 csig:  4.602015623884375 cbak:  3.891585645154471 covl:  4.091482110251405 ssnr:  10.48774687137649 stoi:  0.9558396137328087


Evaluating: CMGAN_epoch_32_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3914685955325377 csig:  4.598066190740874 cbak:  3.9036506380292466 covl:  4.091221164281141 ssnr:  10.665756775404232 stoi:  0.9552990608917747


Evaluating: CMGAN_epoch_33_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.356470398532534 csig:  4.596791528684226 cbak:  3.866896081232276 covl:  4.073716203682453 ssnr:  10.35572233656377 stoi:  0.9564411360866395


Evaluating: CMGAN_epoch_34_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.350106509999164 csig:  4.590061885483535 cbak:  3.8677834390370984 covl:  4.065717061204892 ssnr:  10.416511135775853 stoi:  0.9558823885360579


Evaluating: CMGAN_epoch_35_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.317629180052905 csig:  4.592248646910262 cbak:  3.8740347759856393 covl:  4.044240069841114 ssnr:  10.749932560880978 stoi:  0.9560404089146146


Evaluating: CMGAN_epoch_36_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3728121997951304 csig:  4.606228968388422 cbak:  3.89743137765516 covl:  4.088635545389324 ssnr:  10.699807820502162 stoi:  0.9559608853820913


Evaluating: CMGAN_epoch_37_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.386354111207342 csig:  4.612248092005061 cbak:  3.892617076246679 covl:  4.0989413465491324 ssnr:  10.531938097281818 stoi:  0.9560658633899713


Evaluating: CMGAN_epoch_38_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.327711338267743 csig:  4.5840207513362055 cbak:  3.869748114043111 covl:  4.052615553024845 ssnr:  10.609003431049642 stoi:  0.9560574193079172


Evaluating: CMGAN_epoch_39_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3983788365877947 csig:  4.605855579128803 cbak:  3.9080304485439528 covl:  4.1051444789028855 ssnr:  10.680842279793666 stoi:  0.955655648073602


Evaluating: CMGAN_epoch_40_0.055
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.373960508738907 csig:  4.6042820647996425 cbak:  3.9005936578828058 covl:  4.0894630752899666 ssnr:  10.745767725993773 stoi:  0.9562815718833725


Evaluating: CMGAN_epoch_4_0.072
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0636772850474108 csig:  4.469796790198921 cbak:  3.5835506133767585 covl:  3.8422256550269935 ssnr:  8.262879128175227 stoi:  0.9483474512337529


Evaluating: CMGAN_epoch_41_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.371589843943281 csig:  4.6058891360879715 cbak:  3.888599737040913 covl:  4.088068069007717 ssnr:  10.576068665787304 stoi:  0.9557149909975569


Evaluating: CMGAN_epoch_42_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.376880053900978 csig:  4.61670938266746 cbak:  3.8945921839582 covl:  4.100292382925177 ssnr:  10.633222943674427 stoi:  0.9561772995601897


Evaluating: CMGAN_epoch_43_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.336878219131127 csig:  4.604024985802105 cbak:  3.8810618854639327 covl:  4.065507923928188 ssnr:  10.714395935572044 stoi:  0.9560442415429083


Evaluating: CMGAN_epoch_44_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.344036039941519 csig:  4.600688521230526 cbak:  3.8865087137457994 covl:  4.069281848550842 ssnr:  10.753247119317413 stoi:  0.9567791015356447


Evaluating: CMGAN_epoch_45_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.329561349547025 csig:  4.579525297485885 cbak:  3.862721622176698 covl:  4.047943094915155 ssnr:  10.496476741781374 stoi:  0.9567272078270305


Evaluating: CMGAN_epoch_46_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.368052942226234 csig:  4.602749412392982 cbak:  3.87849519196371 covl:  4.082873718285738 ssnr:  10.447965656431373 stoi:  0.9559152743850685


Evaluating: CMGAN_epoch_47_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3707344759147144 csig:  4.594385834271602 cbak:  3.895426284801667 covl:  4.079340777854236 ssnr:  10.69510460968737 stoi:  0.9562500306650313


Evaluating: CMGAN_epoch_48_0.055
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.38115628975109 csig:  4.604954004904341 cbak:  3.9044574117761117 covl:  4.092247141884271 ssnr:  10.75612282677561 stoi:  0.9559809096052224


Evaluating: CMGAN_epoch_49_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.377870493577522 csig:  4.613489397627603 cbak:  3.901395917489927 covl:  4.096379220824702 ssnr:  10.728526326726735 stoi:  0.9560327476028768


Evaluating: CMGAN_epoch_50_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3777860709764425 csig:  4.614045091094787 cbak:  3.8970513745251787 covl:  4.097997607325998 ssnr:  10.659486078295322 stoi:  0.9557610086964672


Evaluating: CMGAN_epoch_5_0.069
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1544004153568768 csig:  4.456202728160728 cbak:  3.6663755212287317 covl:  3.8773876890760315 ssnr:  8.74827535912972 stoi:  0.9499133124036859


Evaluating: CMGAN_epoch_51_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.361422580133364 csig:  4.594257061644536 cbak:  3.890980993146979 covl:  4.076086498329677 ssnr:  10.68837321472314 stoi:  0.9565586806067287


Evaluating: CMGAN_epoch_52_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3779725258790174 csig:  4.599792892805184 cbak:  3.897160915040349 covl:  4.088602384777445 ssnr:  10.662371383721226 stoi:  0.9563583930770528


Evaluating: CMGAN_epoch_53_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.352325105262034 csig:  4.593016008153005 cbak:  3.8814133715530277 covl:  4.069000248974366 ssnr:  10.608422260662268 stoi:  0.9567581626688436


Evaluating: CMGAN_epoch_54_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.387124090808109 csig:  4.610178609771553 cbak:  3.9098323696906467 covl:  4.098861050463388 ssnr:  10.794159823635502 stoi:  0.9563563732275575


Evaluating: CMGAN_epoch_55_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3793947348027555 csig:  4.604910923968376 cbak:  3.9039424328392944 covl:  4.0918570263579 ssnr:  10.763272159299348 stoi:  0.9563141860686238


Evaluating: CMGAN_epoch_56_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3743366837790867 csig:  4.6011514457583385 cbak:  3.896824602734169 covl:  4.086563400441151 ssnr:  10.679621422850953 stoi:  0.9561117080050373


Evaluating: CMGAN_epoch_57_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3814133977137724 csig:  4.6168250586852775 cbak:  3.8973671249075528 covl:  4.1007191670664005 ssnr:  10.637616770637157 stoi:  0.9566627247519899


Evaluating: CMGAN_epoch_58_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3653735069973956 csig:  4.612508327757427 cbak:  3.8939519283055932 covl:  4.08720421573492 ssnr:  10.710633097801308 stoi:  0.9565268768315616


Evaluating: CMGAN_epoch_59_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3775437250010016 csig:  4.616779353896482 cbak:  3.8931496908853416 covl:  4.098907871973816 ssnr:  10.605267652115623 stoi:  0.9562679121407041


Evaluating: CMGAN_epoch_6_0.064
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1401241820992776 csig:  4.473669573959843 cbak:  3.7428062911682014 covl:  3.8795817008324227 ssnr:  10.057658882314174 stoi:  0.9503395214782523


Evaluating: CMGAN_epoch_7_0.066
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.207963853495792 csig:  4.529724815948296 cbak:  3.763130832824907 covl:  3.953757456754052 ssnr:  9.864259783951297 stoi:  0.9502651072792134


Evaluating: CMGAN_epoch_8_0.064
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.1899803878323545 csig:  4.479082988991612 cbak:  3.73894908218975 covl:  3.905923199459846 ssnr:  9.641237930929986 stoi:  0.9528081317693665


Evaluating: CMGAN_epoch_9_0.065
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.16095316930882 csig:  4.471965128456365 cbak:  3.737957967306526 covl:  3.8936605049206983 ssnr:  9.804159427593433 stoi:  0.952561960455195


