Starting training:
without SE:
Namespace(batch_size=8, cut_len=32000, data_dir='/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/DEMAND_16KHz', decay_epoch=12, epochs=50, init_lr=0.001, log_interval=500, loss_weights=[0.1, 0.9, 0.2, 0.05], save_model_dir='./saved_models_log/saved_models_20250724_VoiceDEMAND_16khz')
['NVIDIA A100-SXM4-80GB']
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
TSCNet                                             [1, 1, 321, 201]          --
├─DenseEncoder: 1-1                                [1, 64, 321, 101]         580
│    └─Sequential: 2-1                             [1, 64, 321, 201]         --
│    │    └─Conv2d: 3-1                            [1, 64, 321, 201]         256
│    │    └─InstanceNorm2d: 3-2                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-3                             [1, 64, 321, 201]         64
│    └─DilatedDenseNet: 2-2                        [1, 64, 321, 201]         --
│    │    └─ConstantPad2d: 3-4                     [1, 64, 322, 203]         --
│    │    └─Conv2d: 3-5                            [1, 64, 321, 201]         24,640
│    │    └─InstanceNorm2d: 3-6                    [1, 64, 321, 201]         128
│    │    └─PReLU: 3-7                             [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-8                     [1, 128, 323, 203]        --
│    │    └─Conv2d: 3-9                            [1, 64, 321, 201]         49,216
│    │    └─InstanceNorm2d: 3-10                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-11                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-12                    [1, 192, 325, 203]        --
│    │    └─Conv2d: 3-13                           [1, 64, 321, 201]         73,792
│    │    └─InstanceNorm2d: 3-14                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-15                            [1, 64, 321, 201]         64
│    │    └─ConstantPad2d: 3-16                    [1, 256, 329, 203]        --
│    │    └─Conv2d: 3-17                           [1, 64, 321, 201]         98,368
│    │    └─InstanceNorm2d: 3-18                   [1, 64, 321, 201]         128
│    │    └─PReLU: 3-19                            [1, 64, 321, 201]         64
│    └─Sequential: 2-3                             [1, 64, 321, 101]         --
│    │    └─Conv2d: 3-20                           [1, 64, 321, 101]         12,352
│    │    └─InstanceNorm2d: 3-21                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-22                            [1, 64, 321, 101]         64
├─TSCB: 1-2                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-4                         [101, 321, 64]            --
│    │    └─Scale: 3-23                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-24                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-25              [101, 321, 64]            29,376
│    │    └─Scale: 3-26                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-27                        [101, 321, 64]            128
│    └─ConformerBlock: 2-5                         [321, 101, 64]            --
│    │    └─Scale: 3-28                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-29                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-30              [321, 101, 64]            29,376
│    │    └─Scale: 3-31                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-32                        [321, 101, 64]            128
├─TSCB: 1-3                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-6                         [101, 321, 64]            --
│    │    └─Scale: 3-33                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-34                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-35              [101, 321, 64]            29,376
│    │    └─Scale: 3-36                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-37                        [101, 321, 64]            128
│    └─ConformerBlock: 2-7                         [321, 101, 64]            --
│    │    └─Scale: 3-38                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-39                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-40              [321, 101, 64]            29,376
│    │    └─Scale: 3-41                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-42                        [321, 101, 64]            128
├─TSCB: 1-4                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-8                         [101, 321, 64]            --
│    │    └─Scale: 3-43                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-44                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-45              [101, 321, 64]            29,376
│    │    └─Scale: 3-46                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-47                        [101, 321, 64]            128
│    └─ConformerBlock: 2-9                         [321, 101, 64]            --
│    │    └─Scale: 3-48                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-49                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-50              [321, 101, 64]            29,376
│    │    └─Scale: 3-51                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-52                        [321, 101, 64]            128
├─TSCB: 1-5                                        [1, 64, 321, 101]         --
│    └─ConformerBlock: 2-10                        [101, 321, 64]            --
│    │    └─Scale: 3-53                            [101, 321, 64]            33,216
│    │    └─PreNorm: 3-54                          [101, 321, 64]            32,976
│    │    └─ConformerConvModule: 3-55              [101, 321, 64]            29,376
│    │    └─Scale: 3-56                            [101, 321, 64]            33,216
│    │    └─LayerNorm: 3-57                        [101, 321, 64]            128
│    └─ConformerBlock: 2-11                        [321, 101, 64]            --
│    │    └─Scale: 3-58                            [321, 101, 64]            33,216
│    │    └─PreNorm: 3-59                          [321, 101, 64]            32,976
│    │    └─ConformerConvModule: 3-60              [321, 101, 64]            29,376
│    │    └─Scale: 3-61                            [321, 101, 64]            33,216
│    │    └─LayerNorm: 3-62                        [321, 101, 64]            128
├─MaskDecoder: 1-6                                 [1, 1, 321, 201]          580
│    └─DilatedDenseNet: 2-12                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-63                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-64                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-65                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-66                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-67                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-68                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-69                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-70                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-71                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-72                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-73                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-74                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-75                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-76                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-77                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-78                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-13                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-79                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-80                           [1, 128, 321, 101]        24,704
│    └─Conv2d: 2-14                                [1, 1, 321, 201]          129
│    └─InstanceNorm2d: 2-15                        [1, 1, 321, 201]          2
│    └─PReLU: 2-16                                 [1, 1, 321, 201]          1
│    └─Conv2d: 2-17                                [1, 1, 321, 201]          2
│    └─PReLU: 2-18                                 [1, 201, 321]             201
├─ComplexDecoder: 1-7                              [1, 2, 321, 201]          580
│    └─DilatedDenseNet: 2-19                       [1, 64, 321, 101]         --
│    │    └─ConstantPad2d: 3-81                    [1, 64, 322, 103]         --
│    │    └─Conv2d: 3-82                           [1, 64, 321, 101]         24,640
│    │    └─InstanceNorm2d: 3-83                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-84                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-85                    [1, 128, 323, 103]        --
│    │    └─Conv2d: 3-86                           [1, 64, 321, 101]         49,216
│    │    └─InstanceNorm2d: 3-87                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-88                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-89                    [1, 192, 325, 103]        --
│    │    └─Conv2d: 3-90                           [1, 64, 321, 101]         73,792
│    │    └─InstanceNorm2d: 3-91                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-92                            [1, 64, 321, 101]         64
│    │    └─ConstantPad2d: 3-93                    [1, 256, 329, 103]        --
│    │    └─Conv2d: 3-94                           [1, 64, 321, 101]         98,368
│    │    └─InstanceNorm2d: 3-95                   [1, 64, 321, 101]         128
│    │    └─PReLU: 3-96                            [1, 64, 321, 101]         64
│    └─SPConvTranspose2d: 2-20                     [1, 64, 321, 202]         --
│    │    └─ConstantPad2d: 3-97                    [1, 64, 321, 103]         --
│    │    └─Conv2d: 3-98                           [1, 128, 321, 101]        24,704
│    └─InstanceNorm2d: 2-21                        [1, 64, 321, 202]         128
│    └─PReLU: 2-22                                 [1, 64, 321, 202]         64
│    └─Conv2d: 2-23                                [1, 2, 321, 201]          258
====================================================================================================
Total params: 1,836,573
Trainable params: 1,836,573
Non-trainable params: 0
Total mult-adds (G): 41.56
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 4856.40
Params size (MB): 7.34
Estimated Total Size (MB): 4864.25
====================================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Discriminator                            [1, 1]                    --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Conv2d: 2-1                       [1, 16, 100, 160]         512
│    └─InstanceNorm2d: 2-2               [1, 16, 100, 160]         32
│    └─PReLU: 2-3                        [1, 16, 100, 160]         16
│    └─Conv2d: 2-4                       [1, 32, 50, 80]           8,192
│    └─InstanceNorm2d: 2-5               [1, 32, 50, 80]           64
│    └─PReLU: 2-6                        [1, 32, 50, 80]           32
│    └─Conv2d: 2-7                       [1, 64, 25, 40]           32,768
│    └─InstanceNorm2d: 2-8               [1, 64, 25, 40]           128
│    └─PReLU: 2-9                        [1, 64, 25, 40]           64
│    └─Conv2d: 2-10                      [1, 128, 12, 20]          131,072
│    └─InstanceNorm2d: 2-11              [1, 128, 12, 20]          256
│    └─PReLU: 2-12                       [1, 128, 12, 20]          128
│    └─AdaptiveMaxPool2d: 2-13           [1, 128, 1, 1]            --
│    └─Flatten: 2-14                     [1, 128]                  --
│    └─Linear: 2-15                      [1, 64]                   8,256
│    └─Dropout: 2-16                     [1, 64]                   --
│    └─PReLU: 2-17                       [1, 64]                   64
│    └─Linear: 2-18                      [1, 1]                    65
│    └─LearnableSigmoid: 2-19            [1, 1]                    1
==========================================================================================
Total params: 181,650
Trainable params: 181,650
Non-trainable params: 0
Total mult-adds (M): 19.67
==========================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 11.49
Params size (MB): 0.73
Estimated Total Size (MB): 12.73
==========================================================================================
/mnt/iusers01/msc-stu/hum-msc-data-sci-2024-2025/t74061zq/erp/CMGAN_src/data/dataloader.py:52: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")         # in linux
INFO:root:Epoch 0, Step 500, loss: 0.13211607933044434, disc_loss: 0.012734849005937576
INFO:root:Epoch 0, Step 1000, loss: 0.12751972675323486, disc_loss: 0.006835169158875942
INFO:root:Generator loss: 0.08405990432043678, Discriminator loss: 0.0073515837899074685
INFO:root:Epoch 1, Step 500, loss: 0.10354044288396835, disc_loss: 0.0177226010710001
INFO:root:Epoch 1, Step 1000, loss: 0.08611185848712921, disc_loss: 0.014164445921778679
INFO:root:Generator loss: 0.0791278027576729, Discriminator loss: 0.009079693416495201
INFO:root:Epoch 2, Step 500, loss: 0.10343670099973679, disc_loss: 0.007898278534412384
INFO:root:Epoch 2, Step 1000, loss: 0.13508093357086182, disc_loss: 0.002140532713383436
INFO:root:Generator loss: 0.0748650662383987, Discriminator loss: 0.006042415337203053
INFO:root:Epoch 3, Step 500, loss: 0.10912932455539703, disc_loss: 0.005375055130571127
INFO:root:Epoch 3, Step 1000, loss: 0.09119009971618652, disc_loss: 0.0057427119463682175
INFO:root:Generator loss: 0.07205215259229095, Discriminator loss: 0.005397406342276598
INFO:root:Epoch 4, Step 500, loss: 0.12025289237499237, disc_loss: 0.0025468221865594387
INFO:root:Epoch 4, Step 1000, loss: 0.10169462859630585, disc_loss: 0.002086660359054804
INFO:root:Generator loss: 0.07087990847750775, Discriminator loss: 0.007836301727401256
INFO:root:Epoch 5, Step 500, loss: 0.13282549381256104, disc_loss: 0.0013623315608128905
INFO:root:Epoch 5, Step 1000, loss: 0.09396511316299438, disc_loss: 0.002902562264353037
INFO:root:Generator loss: 0.07221788941945845, Discriminator loss: 0.00470915464040127
INFO:root:Epoch 6, Step 500, loss: 0.0759931355714798, disc_loss: 0.0009486419730819762
INFO:root:Epoch 6, Step 1000, loss: 0.11949022114276886, disc_loss: 0.0029642092995345592
INFO:root:Generator loss: 0.0676485697548945, Discriminator loss: 0.007888050154258398
INFO:root:Epoch 7, Step 500, loss: 0.10070616006851196, disc_loss: 0.005150787066668272
INFO:root:Epoch 7, Step 1000, loss: 0.11458608508110046, disc_loss: 0.0016888354439288378
INFO:root:Generator loss: 0.06821246372843251, Discriminator loss: 0.004730406513401461
INFO:root:Epoch 8, Step 500, loss: 0.0899740532040596, disc_loss: 0.0007047820254229009
INFO:root:Epoch 8, Step 1000, loss: 0.09577711671590805, disc_loss: 0.002710678381845355
INFO:root:Generator loss: 0.06679620575702307, Discriminator loss: 0.005378250581397702
INFO:root:Epoch 9, Step 500, loss: 0.10076294839382172, disc_loss: 0.002470426494255662
INFO:root:Epoch 9, Step 1000, loss: 0.09544475376605988, disc_loss: 0.0017954845679923892
INFO:root:Generator loss: 0.06582462462117371, Discriminator loss: 0.0071523096384164125
INFO:root:Epoch 10, Step 500, loss: 0.11548753827810287, disc_loss: 0.0014504470163956285
INFO:root:Epoch 10, Step 1000, loss: 0.0850013941526413, disc_loss: 0.006220696493983269
INFO:root:Generator loss: 0.06488023969588928, Discriminator loss: 0.0056868267988162205
INFO:root:Epoch 11, Step 500, loss: 0.10583338886499405, disc_loss: 0.0022151742596179247
INFO:root:Epoch 11, Step 1000, loss: 0.07069345563650131, disc_loss: 0.0009620465571060777
INFO:root:Generator loss: 0.06275540973665644, Discriminator loss: 0.0049665649548665735
INFO:root:Epoch 12, Step 500, loss: 0.08457229286432266, disc_loss: 0.0012454156531021
INFO:root:Epoch 12, Step 1000, loss: 0.12188215553760529, disc_loss: 0.0006885039620101452
INFO:root:Generator loss: 0.06147465565540258, Discriminator loss: 0.004410938320238396
INFO:root:Epoch 13, Step 500, loss: 0.08602593094110489, disc_loss: 0.003291449975222349
INFO:root:Epoch 13, Step 1000, loss: 0.08354591578245163, disc_loss: 0.0031886782962828875
INFO:root:Generator loss: 0.06026420036999924, Discriminator loss: 0.004095289817767091
INFO:root:Epoch 14, Step 500, loss: 0.09354760497808456, disc_loss: 0.001951380167156458
INFO:root:Epoch 14, Step 1000, loss: 0.06794723123311996, disc_loss: 0.001872390159405768
INFO:root:Generator loss: 0.06007236752261236, Discriminator loss: 0.004879085006287268
INFO:root:Epoch 15, Step 500, loss: 0.059653691947460175, disc_loss: 0.020634301006793976
INFO:root:Epoch 15, Step 1000, loss: 0.07786722481250763, disc_loss: 0.00346450787037611
INFO:root:Generator loss: 0.05869196011748129, Discriminator loss: 0.0031901328535965255
INFO:root:Epoch 16, Step 500, loss: 0.0657806396484375, disc_loss: 0.0038646538741886616
INFO:root:Epoch 16, Step 1000, loss: 0.06785990297794342, disc_loss: 0.004418541211634874
INFO:root:Generator loss: 0.06211951393091563, Discriminator loss: 0.005116191058017278
INFO:root:Epoch 17, Step 500, loss: 0.06325729191303253, disc_loss: 0.0011264726053923368
INFO:root:Epoch 17, Step 1000, loss: 0.09689448028802872, disc_loss: 0.001546044833958149
INFO:root:Generator loss: 0.06020772106294493, Discriminator loss: 0.005773224895853929
INFO:root:Epoch 18, Step 500, loss: 0.09745116531848907, disc_loss: 0.0030539168510586023
INFO:root:Epoch 18, Step 1000, loss: 0.057716935873031616, disc_loss: 0.0023760804906487465
INFO:root:Generator loss: 0.061714333237953556, Discriminator loss: 0.006898414316187043
INFO:root:Epoch 19, Step 500, loss: 0.09475962072610855, disc_loss: 0.002758161863312125
INFO:root:Epoch 19, Step 1000, loss: 0.07731202244758606, disc_loss: 0.000639444449916482
INFO:root:Generator loss: 0.06065424712537562, Discriminator loss: 0.004090380936847475
INFO:root:Epoch 20, Step 500, loss: 0.09625475853681564, disc_loss: 0.0017958558164536953
INFO:root:Epoch 20, Step 1000, loss: 0.09314560890197754, disc_loss: 0.002568830270320177
INFO:root:Generator loss: 0.06050190893770421, Discriminator loss: 0.0049565693191749955
INFO:root:Epoch 21, Step 500, loss: 0.09085646271705627, disc_loss: 0.004444586578756571
INFO:root:Epoch 21, Step 1000, loss: 0.06549598276615143, disc_loss: 0.0014607682824134827
INFO:root:Generator loss: 0.06108391100486505, Discriminator loss: 0.004667585581434818
INFO:root:Epoch 22, Step 500, loss: 0.08200950175523758, disc_loss: 0.0007295426912605762
INFO:root:Epoch 22, Step 1000, loss: 0.06524760276079178, disc_loss: 0.001076127984561026
INFO:root:Generator loss: 0.06130949982885018, Discriminator loss: 0.0048143788883959855
INFO:root:Epoch 23, Step 500, loss: 0.07794313877820969, disc_loss: 0.0023937297519296408
INFO:root:Epoch 23, Step 1000, loss: 0.08502035588026047, disc_loss: 0.0008136885007843375
INFO:root:Generator loss: 0.05667733151501822, Discriminator loss: 0.004939672179425189
INFO:root:Epoch 24, Step 500, loss: 0.09120319783687592, disc_loss: 0.0025336029939353466
INFO:root:Epoch 24, Step 1000, loss: 0.07364889979362488, disc_loss: 0.0019980964716523886
INFO:root:Generator loss: 0.0576643896768394, Discriminator loss: 0.005511441205580746
INFO:root:Epoch 25, Step 500, loss: 0.07795848697423935, disc_loss: 0.0023175659589469433
INFO:root:Epoch 25, Step 1000, loss: 0.06721051037311554, disc_loss: 0.0019127863924950361
INFO:root:Generator loss: 0.05904203732904879, Discriminator loss: 0.004390708121948071
INFO:root:Epoch 26, Step 500, loss: 0.07296962291002274, disc_loss: 0.0008777326438575983
INFO:root:Epoch 26, Step 1000, loss: 0.06817329674959183, disc_loss: 0.0014627462951466441
INFO:root:Generator loss: 0.05692300395768823, Discriminator loss: 0.004468560720357628
INFO:root:Epoch 27, Step 500, loss: 0.06444370001554489, disc_loss: 0.0031094553414732218
INFO:root:Epoch 27, Step 1000, loss: 0.07667101174592972, disc_loss: 0.0010889389086514711
INFO:root:Generator loss: 0.05625020376252897, Discriminator loss: 0.003806584001828473
INFO:root:Epoch 28, Step 500, loss: 0.06320510059595108, disc_loss: 0.002376448828727007
INFO:root:Epoch 28, Step 1000, loss: 0.0816437229514122, disc_loss: 0.0009795724181458354
INFO:root:Generator loss: 0.059119598560252236, Discriminator loss: 0.00390274466091125
INFO:root:Epoch 29, Step 500, loss: 0.06649620085954666, disc_loss: 0.0027443133294582367
INFO:root:Epoch 29, Step 1000, loss: 0.08573168516159058, disc_loss: 0.0018036928959190845
INFO:root:Generator loss: 0.05784706887110923, Discriminator loss: 0.005004677836200023
INFO:root:Epoch 30, Step 500, loss: 0.09545007348060608, disc_loss: 0.0012027454795315862
INFO:root:Epoch 30, Step 1000, loss: 0.056684669107198715, disc_loss: 0.016145136207342148
INFO:root:Generator loss: 0.061542191804902065, Discriminator loss: 0.005889172285164535
INFO:root:Epoch 31, Step 500, loss: 0.06871124356985092, disc_loss: 0.003028642851859331
INFO:root:Epoch 31, Step 1000, loss: 0.066971056163311, disc_loss: 0.0010592365870252252
INFO:root:Generator loss: 0.05765317170654686, Discriminator loss: 0.004311407951002905
INFO:root:Epoch 32, Step 500, loss: 0.07358363270759583, disc_loss: 0.002052419586107135
INFO:root:Epoch 32, Step 1000, loss: 0.08543029427528381, disc_loss: 0.0004296328406780958
INFO:root:Generator loss: 0.05639328395278709, Discriminator loss: 0.0038731969788148367
INFO:root:Epoch 33, Step 500, loss: 0.06985650211572647, disc_loss: 0.0013628883752971888
INFO:root:Epoch 33, Step 1000, loss: 0.06746040284633636, disc_loss: 0.02465970069169998
INFO:root:Generator loss: 0.057282830434806135, Discriminator loss: 0.0033722098784530266
INFO:root:Epoch 34, Step 500, loss: 0.05834094434976578, disc_loss: 0.00015620204794686288
INFO:root:Epoch 34, Step 1000, loss: 0.07282888889312744, disc_loss: 0.002786175347864628
INFO:root:Generator loss: 0.05845463717157401, Discriminator loss: 0.004909061632080691
INFO:root:Epoch 35, Step 500, loss: 0.09039439260959625, disc_loss: 0.0007956770132295787
INFO:root:Epoch 35, Step 1000, loss: 0.05911006033420563, disc_loss: 0.0012579533504322171
INFO:root:Generator loss: 0.059005488144251904, Discriminator loss: 0.005726505992357683
INFO:root:Epoch 36, Step 500, loss: 0.09444435685873032, disc_loss: 0.0011830927105620503
INFO:root:Epoch 36, Step 1000, loss: 0.06062086671590805, disc_loss: 0.0015087136998772621
INFO:root:Generator loss: 0.05808022415753707, Discriminator loss: 0.004613122555259977
INFO:root:Epoch 37, Step 500, loss: 0.07175798714160919, disc_loss: 0.0010700169950723648
INFO:root:Epoch 37, Step 1000, loss: 0.07874828577041626, disc_loss: 0.0008718178141862154
INFO:root:Generator loss: 0.05749502929958325, Discriminator loss: 0.0037972747782828485
INFO:root:Epoch 38, Step 500, loss: 0.07828982174396515, disc_loss: 0.0021423031575977802
INFO:root:Epoch 38, Step 1000, loss: 0.07004017382860184, disc_loss: 0.0028354378882795572
INFO:root:Generator loss: 0.05730640595254389, Discriminator loss: 0.004185773253675948
INFO:root:Epoch 39, Step 500, loss: 0.06737207621335983, disc_loss: 0.00147173460572958
INFO:root:Epoch 39, Step 1000, loss: 0.07610418647527695, disc_loss: 0.0014687541406601667
INFO:root:Generator loss: 0.05682080691155878, Discriminator loss: 0.0040297204823836735
INFO:root:Epoch 40, Step 500, loss: 0.06137852743268013, disc_loss: 0.002531140809878707
INFO:root:Epoch 40, Step 1000, loss: 0.07162263989448547, disc_loss: 0.0009848319459706545
INFO:root:Generator loss: 0.05715842490780701, Discriminator loss: 0.004359538973483157
INFO:root:Epoch 41, Step 500, loss: 0.0858033075928688, disc_loss: 0.001628490281291306
INFO:root:Epoch 41, Step 1000, loss: 0.08752963691949844, disc_loss: 0.0009450460784137249
INFO:root:Generator loss: 0.055873376434867825, Discriminator loss: 0.002944662080268439
INFO:root:Epoch 42, Step 500, loss: 0.06779401749372482, disc_loss: 0.003012369852513075
INFO:root:Epoch 42, Step 1000, loss: 0.0779096931219101, disc_loss: 0.00044311684905551374
INFO:root:Generator loss: 0.0567062684488528, Discriminator loss: 0.0040056107959086165
INFO:root:Epoch 43, Step 500, loss: 0.05311325937509537, disc_loss: 0.000813659920822829
INFO:root:Epoch 43, Step 1000, loss: 0.05659763142466545, disc_loss: 0.002822353271767497
INFO:root:Generator loss: 0.05663727017716297, Discriminator loss: 0.0049717534278085436
INFO:root:Epoch 44, Step 500, loss: 0.07078303396701813, disc_loss: 0.0010231619235128164
INFO:root:Epoch 44, Step 1000, loss: 0.07297950237989426, disc_loss: 0.0009974916465580463
INFO:root:Generator loss: 0.05823695594535291, Discriminator loss: 0.0040666568239933806
INFO:root:Epoch 45, Step 500, loss: 0.07627569884061813, disc_loss: 0.0017830163706094027
INFO:root:Epoch 45, Step 1000, loss: 0.10381438583135605, disc_loss: 0.010700998827815056
INFO:root:Generator loss: 0.05702438465889218, Discriminator loss: 0.004409675633176501
INFO:root:Epoch 46, Step 500, loss: 0.09221653640270233, disc_loss: 0.002101012971252203
INFO:root:Epoch 46, Step 1000, loss: 0.05498102679848671, disc_loss: 0.0006657853373326361
INFO:root:Generator loss: 0.05654127161624362, Discriminator loss: 0.003958990499863257
INFO:root:Epoch 47, Step 500, loss: 0.057242780923843384, disc_loss: 0.0004697504627984017
INFO:root:Epoch 47, Step 1000, loss: 0.07650163024663925, disc_loss: 0.0005904143326915801
INFO:root:Generator loss: 0.056158912847343, Discriminator loss: 0.004140404619285566
INFO:root:Epoch 48, Step 500, loss: 0.08329480141401291, disc_loss: 0.0006750898901373148
INFO:root:Epoch 48, Step 1000, loss: 0.06800805777311325, disc_loss: 0.0016428078524768353
INFO:root:Generator loss: 0.05715585590421575, Discriminator loss: 0.004761713195831777
INFO:root:Epoch 49, Step 500, loss: 0.06947719305753708, disc_loss: 0.008067185059189796
INFO:root:Epoch 49, Step 1000, loss: 0.05120721831917763, disc_loss: 0.0010344622423872352
INFO:root:Generator loss: 0.05637163625469486, Discriminator loss: 0.00420056659421992
Training finished.
Starting batch evaluation...
Evaluating: CMGAN_epoch_0_0.084
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.815117291165787 csig:  4.287441610866564 cbak:  3.5045227313377203 covl:  3.6104709834736646 ssnr:  8.868813353153158 stoi:  0.9385132568936568


Evaluating: CMGAN_epoch_10_0.064
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.174879028380496 csig:  4.443267924365079 cbak:  3.7491856260602496 covl:  3.8838056512629584 ssnr:  9.924027130742127 stoi:  0.9525886630397076


Evaluating: CMGAN_epoch_1_0.079
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  2.908728381673109 csig:  4.346194500937517 cbak:  3.5902589107436946 covl:  3.688238661365731 ssnr:  9.47020379142741 stoi:  0.9391396174331261


Evaluating: CMGAN_epoch_11_0.062
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2272570468847035 csig:  4.527939806859382 cbak:  3.7821359371045125 covl:  3.958719291348539 ssnr:  10.040678088147214 stoi:  0.9529295556181251


Evaluating: CMGAN_epoch_12_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3118346747264122 csig:  4.537201752125833 cbak:  3.828573978032816 covl:  4.008149069391733 ssnr:  10.106001739038144 stoi:  0.9544484689684922


Evaluating: CMGAN_epoch_13_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.295609818934237 csig:  4.541822097810533 cbak:  3.835507059521817 covl:  4.002132244614951 ssnr:  10.350656612066688 stoi:  0.9553427556302753


Evaluating: CMGAN_epoch_14_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3195105789645205 csig:  4.579238501179238 cbak:  3.835974815852961 covl:  4.039739408421179 ssnr:  10.171367634397738 stoi:  0.9558629418320221


Evaluating: CMGAN_epoch_15_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.301615141693828 csig:  4.547797453115817 cbak:  3.845949442186698 covl:  4.0109384772404875 ssnr:  10.453141407036702 stoi:  0.9556132281794942


Evaluating: CMGAN_epoch_16_0.062
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.301036505444536 csig:  4.573680426779025 cbak:  3.796780569685338 covl:  4.0211863849480345 ssnr:  9.739908698043017 stoi:  0.9545158361248057


Evaluating: CMGAN_epoch_17_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.327050567975322 csig:  4.552143240175595 cbak:  3.843778715060514 covl:  4.026039546199619 ssnr:  10.271170057772377 stoi:  0.9542831251575766


Evaluating: CMGAN_epoch_18_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.266227647228148 csig:  4.559175280988329 cbak:  3.7943714965903115 covl:  4.003300449715634 ssnr:  9.931064394583023 stoi:  0.9562233757104617


Evaluating: CMGAN_epoch_19_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2685603380781934 csig:  4.554229439930008 cbak:  3.8121414721082325 covl:  3.9953678697056696 ssnr:  10.225573388949522 stoi:  0.9556386276540432


Evaluating: CMGAN_epoch_20_0.060
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2572388233779703 csig:  4.537462463282312 cbak:  3.807533125645261 covl:  3.982223497943407 ssnr:  10.235116224106534 stoi:  0.9559304938840296


Evaluating: CMGAN_epoch_2_0.074
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.0254608980081614 csig:  4.4338264886586085 cbak:  3.6313292933409342 covl:  3.7975610650522884 ssnr:  9.216635166944931 stoi:  0.9465835178934657


Evaluating: CMGAN_epoch_21_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.292973933868038 csig:  4.524508995839098 cbak:  3.8105112333646995 covl:  3.994562397765728 ssnr:  10.019735352028984 stoi:  0.954707414421092


Evaluating: CMGAN_epoch_22_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3037470444602874 csig:  4.538410503117783 cbak:  3.8239003436429537 covl:  4.005892568538619 ssnr:  10.110703843005943 stoi:  0.9544940484947112


Evaluating: CMGAN_epoch_23_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3536101219434182 csig:  4.586427135378199 cbak:  3.881615089547469 covl:  4.062691653486101 ssnr:  10.614223943660454 stoi:  0.9568039932227466


Evaluating: CMGAN_epoch_24_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.321926088153737 csig:  4.580991413104345 cbak:  3.8468813390247782 covl:  4.039526922965115 ssnr:  10.329197484755968 stoi:  0.956558793300989


Evaluating: CMGAN_epoch_25_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.355735378213299 csig:  4.594534838879095 cbak:  3.8504084389819337 covl:  4.070685600015035 ssnr:  10.156254184805128 stoi:  0.9567852070365563


Evaluating: CMGAN_epoch_26_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3523682596035376 csig:  4.579475411158144 cbak:  3.884197421102063 covl:  4.057292935810891 ssnr:  10.672930249358807 stoi:  0.9563955080060509


Evaluating: CMGAN_epoch_27_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3655854462130557 csig:  4.580440195307558 cbak:  3.8920072086206594 covl:  4.065912852340158 ssnr:  10.689734506395853 stoi:  0.9565442262640687


Evaluating: CMGAN_epoch_28_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.2778709454154504 csig:  4.556507328119593 cbak:  3.831946218675234 covl:  4.0015401165231115 ssnr:  10.421903387615522 stoi:  0.9564974071587188


Evaluating: CMGAN_epoch_29_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.349426740726221 csig:  4.609784584257049 cbak:  3.8700961077514306 covl:  4.077122921943033 ssnr:  10.470870885432923 stoi:  0.9561261232996433


Evaluating: CMGAN_epoch_30_0.061
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.331864631002389 csig:  4.586931476392626 cbak:  3.815705861963263 covl:  4.0474416009089405 ssnr:  9.890789898998918 stoi:  0.9564890849278151


Evaluating: CMGAN_epoch_3_0.072
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.097328088381915 csig:  4.464123872339309 cbak:  3.6926478899502704 covl:  3.8526663560893613 ssnr:  9.635495121419943 stoi:  0.9460150407120421


Evaluating: CMGAN_epoch_31_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.331799082241012 csig:  4.5533400580261825 cbak:  3.865580724568521 covl:  4.033264098151388 ssnr:  10.558462838442605 stoi:  0.9569970867851519


Evaluating: CMGAN_epoch_32_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.341921215641846 csig:  4.581704221188615 cbak:  3.8770288968543425 covl:  4.049569042553598 ssnr:  10.626613441922718 stoi:  0.957470502464215


Evaluating: CMGAN_epoch_33_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3910139401271504 csig:  4.6142765388279585 cbak:  3.8910537071917526 covl:  4.102181437512998 ssnr:  10.479715914798337 stoi:  0.9557690590032134


Evaluating: CMGAN_epoch_34_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3011823577209585 csig:  4.569362765538169 cbak:  3.8413116341370626 covl:  4.021562455545808 ssnr:  10.414142133788049 stoi:  0.9571752376427907


Evaluating: CMGAN_epoch_35_0.059
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.315541846659577 csig:  4.55345202312513 cbak:  3.8286652412561395 covl:  4.0213027540510655 ssnr:  10.145570184304159 stoi:  0.9573768303149627


Evaluating: CMGAN_epoch_36_0.058
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3609983333684865 csig:  4.587457362075999 cbak:  3.8664021884512643 covl:  4.06640893247941 ssnr:  10.388732216044806 stoi:  0.9570168890836688


Evaluating: CMGAN_epoch_37_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3272617340666577 csig:  4.574747509366178 cbak:  3.8677336242940137 covl:  4.0412784600332765 ssnr:  10.61576278609774 stoi:  0.957259764831497


Evaluating: CMGAN_epoch_38_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.379620383810071 csig:  4.603538826266116 cbak:  3.8905213819449593 covl:  4.0886007921183225 ssnr:  10.588984912654412 stoi:  0.956943413281315


Evaluating: CMGAN_epoch_39_0.056
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3740399160142083 csig:  4.6041320953881435 cbak:  3.8893418176377494 covl:  4.084294086401331 ssnr:  10.5954654088766 stoi:  0.9568255182861101


Evaluating: CMGAN_epoch_40_0.057
evaluation.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict((torch.load(model_path)))
pesq:  3.3842069727992548 csig:  4.606854720880078 cbak:  3.891842764665934 covl:  4.093490621036372 ssnr:  10.568078684677506 stoi:  0.9569365356906132

